{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68391f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 13:03:02,915\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-12-03 13:03:07,254 graphviz._tools DEBUG    deprecate positional args: graphviz.backend.piping.pipe(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "2025-12-03 13:03:07,254 graphviz._tools DEBUG    deprecate positional args: graphviz.backend.rendering.render(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "2025-12-03 13:03:07,254 graphviz._tools DEBUG    deprecate positional args: graphviz.backend.unflattening.unflatten(['stagger', 'fanout', 'chain', 'encoding'])\n",
      "2025-12-03 13:03:07,254 graphviz._tools DEBUG    deprecate positional args: graphviz.backend.viewing.view(['quiet'])\n",
      "2025-12-03 13:03:07,254 graphviz._tools DEBUG    deprecate positional args: graphviz.quoting.quote(['is_html_string', 'is_valid_id', 'dot_keywords', 'endswith_odd_number_of_backslashes', 'escape_unescaped_quotes'])\n",
      "2025-12-03 13:03:07,254 graphviz._tools DEBUG    deprecate positional args: graphviz.quoting.a_list(['kwargs', 'attributes'])\n",
      "2025-12-03 13:03:07,254 graphviz._tools DEBUG    deprecate positional args: graphviz.quoting.attr_list(['kwargs', 'attributes'])\n",
      "2025-12-03 13:03:07,254 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.clear(['keep_attrs'])\n",
      "2025-12-03 13:03:07,270 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.__iter__(['subgraph'])\n",
      "2025-12-03 13:03:07,271 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.node(['_attributes'])\n",
      "2025-12-03 13:03:07,271 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.edge(['_attributes'])\n",
      "2025-12-03 13:03:07,271 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.attr(['_attributes'])\n",
      "2025-12-03 13:03:07,271 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.subgraph(['name', 'comment', 'graph_attr', 'node_attr', 'edge_attr', 'body'])\n",
      "2025-12-03 13:03:07,280 graphviz._tools DEBUG    deprecate positional args: graphviz.piping.Pipe._pipe_legacy(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "2025-12-03 13:03:07,287 graphviz._tools DEBUG    deprecate positional args: graphviz.saving.Save.save(['directory'])\n",
      "2025-12-03 13:03:07,288 graphviz._tools DEBUG    deprecate positional args: graphviz.rendering.Render.render(['directory', 'view', 'cleanup', 'format', 'renderer', 'formatter', 'neato_no_op', 'quiet', 'quiet_view'])\n",
      "2025-12-03 13:03:07,288 graphviz._tools DEBUG    deprecate positional args: graphviz.rendering.Render.view(['directory', 'cleanup', 'quiet', 'quiet_view'])\n",
      "2025-12-03 13:03:07,292 graphviz._tools DEBUG    deprecate positional args: graphviz.unflattening.Unflatten.unflatten(['stagger', 'fanout', 'chain'])\n",
      "2025-12-03 13:03:07,292 graphviz._tools DEBUG    deprecate positional args: graphviz.graphs.BaseGraph.__init__(['comment', 'filename', 'directory', 'format', 'engine', 'encoding', 'graph_attr', 'node_attr', 'edge_attr', 'body', 'strict'])\n",
      "2025-12-03 13:03:07,297 graphviz._tools DEBUG    deprecate positional args: graphviz.sources.Source.from_file(['directory', 'format', 'engine', 'encoding', 'renderer', 'formatter'])\n",
      "2025-12-03 13:03:07,299 graphviz._tools DEBUG    deprecate positional args: graphviz.sources.Source.__init__(['filename', 'directory', 'format', 'engine', 'encoding'])\n",
      "2025-12-03 13:03:07,299 graphviz._tools DEBUG    deprecate positional args: graphviz.sources.Source.save(['directory'])\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# ðŸ“¦ IMPORTACIONES\n",
    "# =======================\n",
    "\n",
    "# Built-in\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from typing import List, Tuple, Dict\n",
    "import operator\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# NumPy, Pandas, Matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, roc_auc_score, pairwise_distances\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Flower\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.common import (\n",
    "    Context, NDArrays, Metrics, Scalar,\n",
    "    ndarrays_to_parameters, parameters_to_ndarrays\n",
    ")\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# LORE\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "from lore_sa.rule import Expression, Rule\n",
    "\n",
    "from lore_sa.client_utils import ClientUtilsMixin\n",
    "\n",
    "# Otros\n",
    "from pathlib import Path\n",
    "from filelock import FileLock  # pip install filelock\n",
    "import pandas as pd, os\n",
    "from graphviz import Digraph\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import cProfile, pstats, io\n",
    "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41dd2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# âš™ï¸ VARIABLES GLOBALES\n",
    "# =======================\n",
    "UNIQUE_LABELS = []\n",
    "FEATURES = []\n",
    "\n",
    "NUM_TRAIN_ROUNDS = 2        # rondas donde entrenas la NN\n",
    "NUM_SERVER_ROUNDS = 3       # la Ãºltima solo para explicaciones\n",
    "NUM_CLIENTS = 6\n",
    "SEED = 42\n",
    "\n",
    "NON_IID = True   # o False para los experimentos IID\n",
    "NON_IID_ALPHA = 0.5  # por ejemplo, Dirichlet mÃ¡s sesgado\n",
    "\n",
    "MIN_AVAILABLE_CLIENTS = NUM_CLIENTS\n",
    "fds = None  # Cache del FederatedDataset\n",
    "CAT_ENCODINGS = {}\n",
    "USING_DATASET = None\n",
    "\n",
    "\n",
    "# ==============================================\n",
    "# ðŸ§¹ Borrar TODOS los CSV individuales de clientes\n",
    "# ==============================================\n",
    "\n",
    "csv_dir = Path(\"results\")\n",
    "all_csvs = list(csv_dir.glob(\"*.csv\"))\n",
    "\n",
    "# Solo borrar si hay alguno\n",
    "if all_csvs:\n",
    "    for f in all_csvs:\n",
    "        try:\n",
    "            f.unlink()\n",
    "        except Exception:\n",
    "            pass  # Ignora errores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =======================\n",
    "# ðŸ”§ UTILIDADES MODELO\n",
    "# =======================\n",
    "\n",
    "def get_model_parameters(tree_model, nn_model):\n",
    "    tree_params = [\n",
    "        int(tree_model.get_params()[\"max_depth\"] or -1),\n",
    "        int(tree_model.get_params()[\"min_samples_split\"]),\n",
    "        int(tree_model.get_params()[\"min_samples_leaf\"]),\n",
    "    ]\n",
    "    nn_weights = [v.cpu().detach().numpy() for v in nn_model.state_dict().values()]\n",
    "    return {\n",
    "        \"tree\": tree_params,\n",
    "        \"nn\": nn_weights,\n",
    "    }\n",
    "\n",
    "\n",
    "def set_model_params(tree_model, nn_model, params):\n",
    "    tree_params = params[\"tree\"]\n",
    "    nn_weights = params[\"nn\"]\n",
    "\n",
    "    # Solo si tree_model no es None y tiene set_params\n",
    "    if tree_model is not None and hasattr(tree_model, \"set_params\"):\n",
    "        max_depth = tree_params[0] if tree_params[0] > 0 else None\n",
    "        tree_model.set_params(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=tree_params[1],\n",
    "            min_samples_leaf=tree_params[2],\n",
    "        )\n",
    "\n",
    "    # Actualizar pesos de la red neuronal\n",
    "    state_dict = nn_model.state_dict()\n",
    "    for (key, _), val in zip(state_dict.items(), nn_weights):\n",
    "        state_dict[key] = torch.tensor(val)\n",
    "    nn_model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# ðŸ“¥ CARGAR DATOS\n",
    "# =======================\n",
    "\n",
    "def get_global_onehot_info(flower_dataset_name, class_col):\n",
    "    partitioner = IidPartitioner(num_partitions=1)\n",
    "    fds_tmp = FederatedDataset(dataset=flower_dataset_name, partitioners={\"train\": partitioner})\n",
    "    df = fds_tmp.load_partition(0, \"train\").with_format(\"pandas\")[:]\n",
    "\n",
    "    # Preprocesado estÃ¡ndar\n",
    "    if \"adult_small\" in flower_dataset_name.lower():\n",
    "        drop_cols = ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss']\n",
    "        df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "\n",
    "    elif \"churn\" in flower_dataset_name.lower():\n",
    "        drop_cols = ['customerID', 'TotalCharges']\n",
    "        df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "        df['MonthlyCharges'] = pd.to_numeric(df['MonthlyCharges'], errors='coerce')\n",
    "        df['tenure'] = pd.to_numeric(df['tenure'], errors='coerce')\n",
    "        df['SeniorCitizen'] = df['SeniorCitizen'].map({0: 'No', 1: 'Yes'}).astype(str)\n",
    "        df.dropna(subset=['MonthlyCharges', 'tenure'], inplace=True)\n",
    "    \n",
    "    elif \"breastcancer\" in flower_dataset_name.lower():\n",
    "        # Preprocesado especÃ­fico para el dataset de cÃ¡ncer de mama\n",
    "        df.drop(columns=['id'], inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        if df[col].nunique() < 50:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    cat_features = [col for col in df.select_dtypes(include=\"category\").columns if col != class_col]\n",
    "    num_features = [col for col in df.columns if df[col].dtype.kind in \"fi\" and col != class_col]\n",
    "\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    ohe.fit(df[cat_features])\n",
    "    categories_global = ohe.categories_\n",
    "    onehot_columns = ohe.get_feature_names_out(cat_features).tolist()\n",
    "    return cat_features, num_features, categories_global, onehot_columns\n",
    "\n",
    "\n",
    "\n",
    "def load_data_general(flower_dataset_name: str, class_col: str, partition_id: int, num_partitions: int):\n",
    "    global fds, UNIQUE_LABELS, FEATURES\n",
    "\n",
    "    # Saca info global siempre al principio\n",
    "    cat_features, num_features, categories_global, onehot_columns = get_global_onehot_info(flower_dataset_name, class_col)\n",
    "\n",
    "        # 2) Definir clases globales SOLO UNA VEZ usando TODO el train\n",
    "    if not UNIQUE_LABELS:\n",
    "        partitioner_all = IidPartitioner(num_partitions=1)\n",
    "        fds_all = FederatedDataset(dataset=flower_dataset_name, partitioners={\"train\": partitioner_all})\n",
    "        df_all = fds_all.load_partition(0, \"train\").with_format(\"pandas\")[:]\n",
    "\n",
    "        le_global = LabelEncoder()\n",
    "        le_global.fit(df_all[class_col])\n",
    "        UNIQUE_LABELS[:] = le_global.classes_.tolist()\n",
    "\n",
    "    if fds is None:\n",
    "        if NON_IID:\n",
    "            partitioner = DirichletPartitioner(\n",
    "                num_partitions=num_partitions,\n",
    "                alpha=NON_IID_ALPHA,\n",
    "                partition_by=class_col,   # o \"class\" segÃºn el nombre en el df original\n",
    "            )\n",
    "        else:\n",
    "            partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "\n",
    "        fds = FederatedDataset(\n",
    "            dataset=flower_dataset_name,\n",
    "            partitioners={\"train\": partitioner},\n",
    "        )\n",
    "\n",
    "    dataset = fds.load_partition(partition_id, \"train\").with_format(\"pandas\")[:]\n",
    "\n",
    "\n",
    "    # Preprocesado especÃ­fico por dataset\n",
    "    if \"adult\" in flower_dataset_name.lower():\n",
    "        drop_cols = ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss']\n",
    "        dataset.drop(columns=[col for col in drop_cols if col in dataset.columns], inplace=True)\n",
    "\n",
    "    elif \"churn\" in flower_dataset_name.lower():\n",
    "        drop_cols = ['customerID', 'TotalCharges']\n",
    "        dataset.drop(columns=[col for col in drop_cols if col in dataset.columns], inplace=True)\n",
    "        dataset['MonthlyCharges'] = pd.to_numeric(dataset['MonthlyCharges'], errors='coerce')\n",
    "        dataset['tenure'] = pd.to_numeric(dataset['tenure'], errors='coerce')\n",
    "        dataset['SeniorCitizen'] = dataset['SeniorCitizen'].map({0: 'No', 1: 'Yes'}).astype(str)\n",
    "\n",
    "        dataset.dropna(subset=['MonthlyCharges', 'tenure'], inplace=True)\n",
    "\n",
    "    elif \"breastcancer\" in flower_dataset_name.lower():\n",
    "        # Preprocesado especÃ­fico para el dataset de cÃ¡ncer de mama\n",
    "        dataset.drop(columns=['id'], inplace=True, errors='ignore')\n",
    "\n",
    "    for col in dataset.select_dtypes(include=[\"object\"]).columns:\n",
    "        if dataset[col].nunique() < 50:\n",
    "            dataset[col] = dataset[col].astype(\"category\")\n",
    "\n",
    "    class_original = dataset[class_col].copy()\n",
    "    tabular_dataset = TabularDataset(dataset.copy(), class_name=class_col)\n",
    "    descriptor = tabular_dataset.descriptor\n",
    "\n",
    "    for col, info in descriptor[\"categorical\"].items():\n",
    "        if \"distinct_values\" not in info or not info[\"distinct_values\"]:\n",
    "            info[\"distinct_values\"] = list(dataset[col].dropna().unique())\n",
    "\n",
    "    # 4) AQUÃ: NUNCA hacer fit por particiÃ³n, solo usar las clases globales\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.classes_ = np.array(UNIQUE_LABELS)\n",
    "    dataset[class_col] = label_encoder.transform(dataset[class_col])\n",
    "    dataset.rename(columns={class_col: \"class\"}, inplace=True)\n",
    "    y = dataset[\"class\"].reset_index(drop=True).to_numpy()\n",
    "\n",
    "    numeric_features = list(descriptor[\"numeric\"].keys())\n",
    "    categorical_features = list(descriptor[\"categorical\"].keys())\n",
    "    FEATURES[:] = numeric_features + categorical_features\n",
    "\n",
    "    numeric_indices = list(range(len(numeric_features)))\n",
    "    categorical_indices = list(range(len(numeric_features), len(FEATURES)))\n",
    "\n",
    "    X_array = dataset[FEATURES].to_numpy()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", \"passthrough\", numeric_indices),\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\", categories=categories_global), categorical_indices)\n",
    "    ])\n",
    "    X_encoded = preprocessor.fit_transform(X_array)\n",
    "\n",
    "    # ReconstrucciÃ³n del DataFrame\n",
    "    num_out = X_encoded[:, :len(numeric_features)]\n",
    "    cat_out = X_encoded[:, len(numeric_features):]\n",
    "    if categorical_features:\n",
    "        cat_names = preprocessor.named_transformers_[\"cat\"].get_feature_names_out(categorical_features)\n",
    "    else:\n",
    "        cat_names = []\n",
    "\n",
    "    num_names = numeric_features\n",
    "\n",
    "    X_df = pd.DataFrame(num_out, columns=num_names)\n",
    "    if len(cat_names) > 0:\n",
    "        X_cat_df = pd.DataFrame(cat_out, columns=cat_names)\n",
    "        X_full = pd.concat([X_df.reset_index(drop=True), X_cat_df.reset_index(drop=True)], axis=1)\n",
    "        for col in onehot_columns:\n",
    "            if col not in X_cat_df.columns:\n",
    "                X_full[col] = 0\n",
    "    else:\n",
    "        X_full = X_df\n",
    "\n",
    "    # Rellenar columnas onehot que falten y ordenar\n",
    "    final_columns = num_names + list(cat_names)\n",
    "    X_full = X_full[final_columns]\n",
    "    FEATURES[:] = final_columns\n",
    "\n",
    "    split_idx = int(0.7 * len(X_full))\n",
    "\n",
    "        # --- Â¡Construye el descriptor global! ---\n",
    "    descriptor_global = descriptor.copy()\n",
    "    for i, col in enumerate(cat_features):\n",
    "        if col in descriptor_global[\"categorical\"]:\n",
    "            descriptor_global[\"categorical\"][col][\"distinct_values\"] = list(categories_global[i])\n",
    "\n",
    "    encoder = ColumnTransformerEnc(descriptor_global)\n",
    "\n",
    "\n",
    "    return (\n",
    "        X_full.iloc[:split_idx].to_numpy(), y[:split_idx],\n",
    "        X_full.iloc[split_idx:].to_numpy(), y[split_idx:],\n",
    "        tabular_dataset, final_columns, label_encoder,\n",
    "        preprocessor.named_transformers_[\"num\"], numeric_features, encoder, preprocessor\n",
    "    )\n",
    "\n",
    "# =======================\n",
    "\n",
    "\n",
    "# Los resultados de las mÃ©tricas no son muy buenos aqui\n",
    "# DATASET_NAME = \"pablopalacios23/adult\"\n",
    "# CLASS_COLUMN = \"class\"\n",
    "\n",
    "\n",
    "\n",
    "# DATASET_NAME = \"pablopalacios23/churn\"\n",
    "# CLASS_COLUMN = \"Churn\" \n",
    "\n",
    "\n",
    "\n",
    "# DATASET_NAME = \"pablopalacios23/HeartDisease\"\n",
    "# CLASS_COLUMN = \"HeartDisease\" \n",
    "\n",
    "\n",
    "\n",
    "DATASET_NAME = \"pablopalacios23/breastcancer\"\n",
    "CLASS_COLUMN = \"diagnosis\" \n",
    "\n",
    "\n",
    "\n",
    "# DATASET_NAME = \"pablopalacios23/Diabetes\"\n",
    "# CLASS_COLUMN = \"Outcome\" \n",
    "\n",
    "\n",
    " \n",
    "# =======================\n",
    "\n",
    "\n",
    "# load_data_general(DATASET_NAME, CLASS_COLUMN, partition_id=0, num_partitions=NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c49bf6",
   "metadata": {},
   "source": [
    "### HOLDOUT DEL SERVIDOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f28fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 13:03:07,354 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-12-03 13:03:07,506 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/main/README.md HTTP/11\" 404 0\n",
      "2025-12-03 13:03:07,622 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer HTTP/11\" 200 615\n",
      "2025-12-03 13:03:07,755 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/breastcancer.py HTTP/11\" 404 0\n",
      "2025-12-03 13:03:07,755 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-12-03 13:03:08,122 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/pablopalacios23/breastcancer/pablopalacios23/breastcancer.py HTTP/11\" 404 0\n",
      "2025-12-03 13:03:08,240 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/README.md HTTP/11\" 404 0\n",
      "2025-12-03 13:03:08,374 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/revision/d21fb27c44731c56662f52e0f762dcc070083b0e HTTP/11\" 200 615\n",
      "2025-12-03 13:03:08,522 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-12-03 13:03:08,524 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-12-03 13:03:08,874 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=pablopalacios23/breastcancer HTTP/11\" 200 None\n",
      "2025-12-03 13:03:09,008 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/revision/d21fb27c44731c56662f52e0f762dcc070083b0e HTTP/11\" 200 615\n",
      "2025-12-03 13:03:09,158 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/tree/d21fb27c44731c56662f52e0f762dcc070083b0e?recursive=False&expand=False HTTP/11\" 200 207\n",
      "2025-12-03 13:03:09,277 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/tree/d21fb27c44731c56662f52e0f762dcc070083b0e/data?recursive=False&expand=False HTTP/11\" 404 79\n",
      "2025-12-03 13:03:09,408 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-12-03 13:03:09,558 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/revision/d21fb27c44731c56662f52e0f762dcc070083b0e HTTP/11\" 200 615\n",
      "2025-12-03 13:03:09,875 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-12-03 13:03:09,891 filelock     DEBUG    Attempting to acquire lock 2357500311696 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:09,893 filelock     DEBUG    Lock 2357500311696 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:09,895 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___breastcancer/default/0.0.0/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_info.json\n",
      "2025-12-03 13:03:09,895 filelock     DEBUG    Attempting to release lock 2357500311696 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:09,895 filelock     DEBUG    Lock 2357500311696 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:09,958 filelock     DEBUG    Attempting to acquire lock 2357501106880 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:09,959 filelock     DEBUG    Lock 2357501106880 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:09,960 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___breastcancer/default/0.0.0/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_info.json\n",
      "2025-12-03 13:03:09,962 filelock     DEBUG    Attempting to release lock 2357501106880 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:09,962 filelock     DEBUG    Lock 2357501106880 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:10,174 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/main/README.md HTTP/11\" 404 0\n",
      "2025-12-03 13:03:10,461 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer HTTP/11\" 200 615\n",
      "2025-12-03 13:03:10,577 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/breastcancer.py HTTP/11\" 404 0\n",
      "2025-12-03 13:03:10,693 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/pablopalacios23/breastcancer/pablopalacios23/breastcancer.py HTTP/11\" 404 0\n",
      "2025-12-03 13:03:10,845 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/README.md HTTP/11\" 404 0\n",
      "2025-12-03 13:03:10,976 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-12-03 13:03:11,348 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=pablopalacios23/breastcancer HTTP/11\" 200 None\n",
      "2025-12-03 13:03:11,483 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/tree/d21fb27c44731c56662f52e0f762dcc070083b0e/data?recursive=False&expand=False HTTP/11\" 404 79\n",
      "2025-12-03 13:03:11,579 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-12-03 13:03:11,744 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/revision/d21fb27c44731c56662f52e0f762dcc070083b0e HTTP/11\" 200 615\n",
      "2025-12-03 13:03:11,880 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-12-03 13:03:11,880 filelock     DEBUG    Attempting to acquire lock 2357502718128 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:11,880 filelock     DEBUG    Lock 2357502718128 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:11,880 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___breastcancer/default/0.0.0/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_info.json\n",
      "2025-12-03 13:03:11,880 filelock     DEBUG    Attempting to release lock 2357502718128 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:11,880 filelock     DEBUG    Lock 2357502718128 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:11,880 filelock     DEBUG    Attempting to acquire lock 2356871157408 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:11,880 filelock     DEBUG    Lock 2356871157408 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:11,880 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___breastcancer/default/0.0.0/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_info.json\n",
      "2025-12-03 13:03:11,880 filelock     DEBUG    Attempting to release lock 2356871157408 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:11,896 filelock     DEBUG    Lock 2356871157408 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:12,044 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/main/README.md HTTP/11\" 404 0\n",
      "2025-12-03 13:03:12,180 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer HTTP/11\" 200 615\n",
      "2025-12-03 13:03:12,297 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/breastcancer.py HTTP/11\" 404 0\n",
      "2025-12-03 13:03:12,412 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/pablopalacios23/breastcancer/pablopalacios23/breastcancer.py HTTP/11\" 404 0\n",
      "2025-12-03 13:03:12,544 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/README.md HTTP/11\" 404 0\n",
      "2025-12-03 13:03:12,677 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-12-03 13:03:12,813 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=pablopalacios23/breastcancer HTTP/11\" 200 None\n",
      "2025-12-03 13:03:12,962 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/tree/d21fb27c44731c56662f52e0f762dcc070083b0e/data?recursive=False&expand=False HTTP/11\" 404 79\n",
      "2025-12-03 13:03:13,061 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-12-03 13:03:13,231 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/breastcancer/revision/d21fb27c44731c56662f52e0f762dcc070083b0e HTTP/11\" 200 615\n",
      "2025-12-03 13:03:13,363 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/breastcancer/resolve/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-12-03 13:03:13,363 filelock     DEBUG    Attempting to acquire lock 2357508638192 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:13,378 filelock     DEBUG    Lock 2357508638192 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:13,378 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___breastcancer/default/0.0.0/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_info.json\n",
      "2025-12-03 13:03:13,378 filelock     DEBUG    Attempting to release lock 2357508638192 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:13,378 filelock     DEBUG    Lock 2357508638192 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___breastcancer_default_0.0.0_d21fb27c44731c56662f52e0f762dcc070083b0e.lock\n",
      "2025-12-03 13:03:13,378 filelock     DEBUG    Attempting to acquire lock 2357502709248 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:13,378 filelock     DEBUG    Lock 2357502709248 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:13,378 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___breastcancer/default/0.0.0/d21fb27c44731c56662f52e0f762dcc070083b0e/dataset_info.json\n",
      "2025-12-03 13:03:13,378 filelock     DEBUG    Attempting to release lock 2357502709248 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n",
      "2025-12-03 13:03:13,378 filelock     DEBUG    Lock 2357502709248 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___breastcancer\\default\\0.0.0\\d21fb27c44731c56662f52e0f762dcc070083b0e_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ X_train (primeras filas):\n",
      "       0      1       2       3        4        5         6         7   \\\n",
      "0   20.48  21.46  132.50  1306.0  0.08355  0.08348  0.090420  0.060220   \n",
      "1   15.75  19.22  107.10   758.6  0.12430  0.23640  0.291400  0.124200   \n",
      "2   12.77  22.47   81.72   506.3  0.09055  0.05761  0.047110  0.027040   \n",
      "3   17.20  24.52  114.20   929.4  0.10710  0.18300  0.169200  0.079440   \n",
      "4   16.74  21.59  110.10   869.5  0.09610  0.13360  0.134800  0.060180   \n",
      "5   14.40  26.99   92.25   646.1  0.06995  0.05223  0.034760  0.017370   \n",
      "6   11.60  12.84   74.34   412.6  0.08983  0.07525  0.041960  0.033500   \n",
      "7   14.90  22.53  102.10   685.0  0.09947  0.22250  0.273300  0.097110   \n",
      "8   17.35  23.06  111.00   933.1  0.08662  0.06290  0.028910  0.028370   \n",
      "9   15.28  22.41   98.92   710.6  0.09057  0.10520  0.053750  0.032630   \n",
      "10  10.44  15.46   66.62   329.6  0.10530  0.07722  0.006643  0.012160   \n",
      "11  10.71  20.39   69.50   344.9  0.10820  0.12890  0.084480  0.028670   \n",
      "12  21.61  22.28  144.40  1407.0  0.11670  0.20870  0.281000  0.156200   \n",
      "13  17.42  25.56  114.50   948.0  0.10060  0.11460  0.168200  0.065970   \n",
      "14  11.68  16.17   75.49   420.5  0.11280  0.09263  0.042790  0.031320   \n",
      "15  17.75  28.03  117.30   981.6  0.09997  0.13140  0.169800  0.082930   \n",
      "16  13.11  22.54   87.02   529.4  0.10020  0.14830  0.087050  0.051020   \n",
      "17  20.64  17.35  134.80  1335.0  0.09446  0.10760  0.152700  0.089410   \n",
      "18  15.46  11.89  102.50   736.9  0.12570  0.15550  0.203200  0.109700   \n",
      "19  13.82  24.49   92.33   595.9  0.11620  0.16810  0.135700  0.067590   \n",
      "20  13.05  18.59   85.09   512.0  0.10820  0.13040  0.096030  0.056030   \n",
      "21  13.17  18.66   85.98   534.6  0.11580  0.12310  0.122600  0.073400   \n",
      "22  21.71  17.25  140.90  1546.0  0.09384  0.08562  0.116800  0.084650   \n",
      "23  15.37  22.76  100.20   728.2  0.09200  0.10360  0.112200  0.074830   \n",
      "24  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.300100  0.147100   \n",
      "25  23.27  22.04  152.10  1686.0  0.08439  0.11450  0.132400  0.097020   \n",
      "26  17.99  20.66  117.80   991.7  0.10360  0.13040  0.120100  0.088240   \n",
      "27  11.08  18.83   73.30   361.6  0.12160  0.21540  0.168900  0.063670   \n",
      "28  12.16  18.03   78.29   455.3  0.09087  0.07838  0.029160  0.015270   \n",
      "29  19.40  23.50  129.10  1155.0  0.10270  0.15580  0.204900  0.088860   \n",
      "30  13.61  24.98   88.05   582.7  0.09488  0.08511  0.086250  0.044890   \n",
      "31  18.03  16.85  117.50   990.0  0.08947  0.12320  0.109000  0.062540   \n",
      "32  19.40  18.18  127.20  1145.0  0.10370  0.14420  0.162600  0.094640   \n",
      "33  11.32  27.08   71.76   395.7  0.06883  0.03813  0.016330  0.003125   \n",
      "34  12.34  26.86   81.15   477.4  0.10340  0.13530  0.108500  0.045620   \n",
      "35  15.46  19.48  101.70   748.9  0.10920  0.12230  0.146600  0.080870   \n",
      "36  15.05  19.07   97.26   701.9  0.09215  0.08597  0.074860  0.043350   \n",
      "37  15.53  33.56  103.70   744.9  0.10630  0.16390  0.175100  0.083990   \n",
      "38  13.43  19.63   85.84   565.4  0.09048  0.06288  0.058580  0.034380   \n",
      "39  13.81  23.75   91.56   597.8  0.13230  0.17680  0.155800  0.091760   \n",
      "40  15.46  23.95  103.80   731.3  0.11830  0.18700  0.203000  0.085200   \n",
      "41  20.16  19.66  131.10  1274.0  0.08020  0.08564  0.115500  0.077260   \n",
      "42  11.93  10.91   76.14   442.7  0.08872  0.05242  0.026060  0.017960   \n",
      "43  13.69  16.07   87.84   579.1  0.08302  0.06374  0.025560  0.020310   \n",
      "44  20.31  27.06  132.90  1288.0  0.10000  0.10880  0.151900  0.093330   \n",
      "45  11.90  14.65   78.11   432.8  0.11520  0.12960  0.037100  0.030030   \n",
      "46  18.22  18.70  120.30  1033.0  0.11480  0.14850  0.177200  0.106000   \n",
      "47  20.44  21.78  133.80  1293.0  0.09150  0.11310  0.097990  0.077850   \n",
      "48  14.25  21.72   93.63   633.0  0.09823  0.10980  0.131900  0.055980   \n",
      "49  18.63  25.11  124.80  1088.0  0.10640  0.18870  0.231900  0.124400   \n",
      "50  10.48  19.86   66.72   337.7  0.10700  0.05971  0.048310  0.030700   \n",
      "51   9.00  14.40   56.36   246.3  0.07005  0.03116  0.003681  0.003472   \n",
      "52  11.52  18.75   73.34   409.0  0.09524  0.05473  0.030360  0.022780   \n",
      "53  16.16  21.54  106.20   809.8  0.10080  0.12840  0.104300  0.056130   \n",
      "\n",
      "        8        9   ...      20     21      22      23       24       25  \\\n",
      "0   0.1467  0.05177  ...  24.220  26.17  161.70  1750.0  0.12280  0.23110   \n",
      "1   0.2375  0.07603  ...  17.360  24.17  119.40   915.3  0.15500  0.50460   \n",
      "2   0.1585  0.06065  ...  14.490  33.37   92.04   653.6  0.14190  0.15230   \n",
      "3   0.1927  0.06487  ...  23.320  33.82  151.60  1681.0  0.15850  0.73940   \n",
      "4   0.1896  0.05656  ...  20.010  29.02  133.50  1229.0  0.15630  0.38350   \n",
      "5   0.1707  0.05433  ...  15.400  31.98  100.40   734.6  0.10170  0.14600   \n",
      "6   0.1620  0.06582  ...  13.060  17.16   82.96   512.5  0.14310  0.18510   \n",
      "7   0.2041  0.06898  ...  16.350  27.57  125.40   832.7  0.14190  0.70900   \n",
      "8   0.1564  0.05307  ...  19.850  31.47  128.20  1218.0  0.12400  0.14860   \n",
      "9   0.1727  0.06317  ...  17.800  28.03  113.80   973.1  0.13010  0.32990   \n",
      "10  0.1788  0.06450  ...  11.520  19.80   73.47   395.4  0.13410  0.11530   \n",
      "11  0.1668  0.06862  ...  11.690  25.21   76.51   410.4  0.13350  0.25500   \n",
      "12  0.2162  0.06606  ...  26.230  28.74  172.00  2081.0  0.15020  0.57170   \n",
      "13  0.1308  0.05866  ...  18.070  28.07  120.40  1021.0  0.12430  0.17930   \n",
      "14  0.1853  0.06401  ...  13.320  21.59   86.57   549.8  0.15260  0.14770   \n",
      "15  0.1713  0.05916  ...  21.530  38.54  145.40  1437.0  0.14010  0.37620   \n",
      "16  0.1850  0.07310  ...  14.550  29.16   99.48   639.3  0.13490  0.44020   \n",
      "17  0.1571  0.05478  ...  25.370  23.17  166.80  1946.0  0.15620  0.30550   \n",
      "18  0.1966  0.07069  ...  18.790  17.04  125.00  1102.0  0.15310  0.35830   \n",
      "19  0.2275  0.07237  ...  16.010  32.94  106.00   788.0  0.17940  0.39660   \n",
      "20  0.2035  0.06501  ...  14.190  24.85   94.22   591.2  0.13430  0.26580   \n",
      "21  0.2128  0.06777  ...  15.670  27.95  102.80   759.4  0.17860  0.41660   \n",
      "22  0.1717  0.05054  ...  30.750  26.44  199.50  3143.0  0.13630  0.16280   \n",
      "23  0.1717  0.06097  ...  16.430  25.84  107.50   830.9  0.12570  0.19970   \n",
      "24  0.2419  0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560   \n",
      "25  0.1801  0.05553  ...  28.010  28.22  184.20  2403.0  0.12280  0.35830   \n",
      "26  0.1992  0.06069  ...  21.080  25.41  138.10  1349.0  0.14820  0.37350   \n",
      "27  0.2196  0.07950  ...  13.240  32.82   91.76   508.1  0.21840  0.93790   \n",
      "28  0.1464  0.06284  ...  13.340  27.87   88.83   547.4  0.12080  0.22790   \n",
      "29  0.1978  0.06000  ...  21.650  30.53  144.90  1417.0  0.14630  0.29680   \n",
      "30  0.1609  0.05871  ...  16.990  35.27  108.60   906.5  0.12650  0.19430   \n",
      "31  0.1720  0.05780  ...  20.380  22.02  133.30  1292.0  0.12630  0.26660   \n",
      "32  0.1893  0.05892  ...  23.790  28.65  152.40  1628.0  0.15180  0.37490   \n",
      "33  0.1869  0.05628  ...  12.080  33.75   79.82   452.3  0.09203  0.14320   \n",
      "34  0.1943  0.06937  ...  15.650  39.34  101.70   768.9  0.17850  0.47060   \n",
      "35  0.1931  0.05796  ...  19.260  26.00  124.90  1156.0  0.15460  0.23940   \n",
      "36  0.1561  0.05915  ...  17.580  28.06  113.80   967.0  0.12460  0.21010   \n",
      "37  0.2091  0.06650  ...  18.490  49.54  126.30  1035.0  0.18830  0.55640   \n",
      "38  0.1598  0.05671  ...  17.980  29.87  116.60   993.6  0.14010  0.15460   \n",
      "39  0.2251  0.07421  ...  19.200  41.85  128.50  1153.0  0.22260  0.52090   \n",
      "40  0.1807  0.07083  ...  17.110  36.33  117.70   909.4  0.17320  0.49670   \n",
      "41  0.1928  0.05096  ...  23.060  23.03  150.20  1657.0  0.10540  0.15370   \n",
      "42  0.1601  0.05541  ...  13.800  20.14   87.64   589.5  0.13740  0.15750   \n",
      "43  0.1872  0.05669  ...  14.840  20.21   99.16   670.6  0.11050  0.20960   \n",
      "44  0.1814  0.05572  ...  24.330  39.16  162.30  1844.0  0.15220  0.29450   \n",
      "45  0.1995  0.07839  ...  13.150  16.51   86.26   509.6  0.14240  0.25170   \n",
      "46  0.2092  0.06310  ...  20.600  24.13  135.10  1321.0  0.12800  0.22970   \n",
      "47  0.1618  0.05557  ...  24.310  26.37  161.20  1780.0  0.13270  0.23760   \n",
      "48  0.1885  0.06125  ...  15.890  30.36  116.20   799.6  0.14460  0.42380   \n",
      "49  0.2183  0.06197  ...  23.150  34.01  160.50  1670.0  0.14910  0.42570   \n",
      "50  0.1737  0.06440  ...  11.480  29.46   73.68   402.8  0.15150  0.10260   \n",
      "51  0.1788  0.06833  ...   9.699  20.07   60.90   285.5  0.09861  0.05232   \n",
      "52  0.1920  0.05907  ...  12.840  22.47   81.81   506.2  0.12490  0.08720   \n",
      "53  0.2160  0.05891  ...  19.470  31.68  129.70  1175.0  0.13950  0.30550   \n",
      "\n",
      "         26       27      28       29  \n",
      "0   0.31580  0.14450  0.2238  0.07127  \n",
      "1   0.68720  0.21350  0.4245  0.10500  \n",
      "2   0.21770  0.09331  0.2829  0.08067  \n",
      "3   0.65660  0.18990  0.3313  0.13390  \n",
      "4   0.54090  0.18130  0.4863  0.08633  \n",
      "5   0.14720  0.05563  0.2345  0.06464  \n",
      "6   0.19220  0.08449  0.2772  0.08756  \n",
      "7   0.90190  0.24750  0.2866  0.11550  \n",
      "8   0.12110  0.08235  0.2452  0.06515  \n",
      "9   0.36300  0.12260  0.3175  0.09772  \n",
      "10  0.02639  0.04464  0.2615  0.08269  \n",
      "11  0.25340  0.08600  0.2605  0.08701  \n",
      "12  0.70530  0.24220  0.3828  0.10070  \n",
      "13  0.28030  0.10990  0.1603  0.06818  \n",
      "14  0.14900  0.09815  0.2804  0.08024  \n",
      "15  0.63990  0.19700  0.2972  0.09075  \n",
      "16  0.31620  0.11260  0.4128  0.10760  \n",
      "17  0.41590  0.21120  0.2689  0.07055  \n",
      "18  0.58300  0.18270  0.3216  0.10100  \n",
      "19  0.33810  0.15210  0.3651  0.11830  \n",
      "20  0.25730  0.12580  0.3113  0.08317  \n",
      "21  0.50060  0.20880  0.3900  0.11790  \n",
      "22  0.28610  0.18200  0.2510  0.06494  \n",
      "23  0.28460  0.14760  0.2556  0.06828  \n",
      "24  0.71190  0.26540  0.4601  0.11890  \n",
      "25  0.39480  0.23460  0.3589  0.09187  \n",
      "26  0.33010  0.19740  0.3060  0.08503  \n",
      "27  0.84020  0.25240  0.4154  0.14030  \n",
      "28  0.16200  0.05690  0.2406  0.07729  \n",
      "29  0.34580  0.15640  0.2920  0.07614  \n",
      "30  0.31690  0.11840  0.2651  0.07397  \n",
      "31  0.42900  0.15350  0.2842  0.08225  \n",
      "32  0.43160  0.22520  0.3590  0.07787  \n",
      "33  0.10890  0.02083  0.2849  0.07087  \n",
      "34  0.44250  0.14590  0.3215  0.12050  \n",
      "35  0.37910  0.15140  0.2837  0.08019  \n",
      "36  0.28660  0.11200  0.2282  0.06954  \n",
      "37  0.57030  0.20140  0.3512  0.12040  \n",
      "38  0.26440  0.11600  0.2884  0.07371  \n",
      "39  0.46460  0.20130  0.4432  0.10860  \n",
      "40  0.59110  0.21630  0.3013  0.10670  \n",
      "41  0.26060  0.14250  0.3055  0.05933  \n",
      "42  0.15140  0.06876  0.2460  0.07262  \n",
      "43  0.13460  0.06987  0.3323  0.07701  \n",
      "44  0.37880  0.16970  0.3151  0.07999  \n",
      "45  0.09420  0.06042  0.2727  0.10360  \n",
      "46  0.26230  0.13250  0.3021  0.07987  \n",
      "47  0.27020  0.17650  0.2609  0.06735  \n",
      "48  0.51860  0.14470  0.3591  0.10140  \n",
      "49  0.61330  0.18480  0.3444  0.09782  \n",
      "50  0.11810  0.06736  0.2883  0.07748  \n",
      "51  0.01472  0.01389  0.2991  0.07804  \n",
      "52  0.09076  0.06316  0.3306  0.07036  \n",
      "53  0.29920  0.13120  0.3480  0.07619  \n",
      "\n",
      "[54 rows x 30 columns]\n",
      "\n",
      "ðŸŽ¯ y_train (primeros valores):\n",
      "[1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1]\n",
      "\n",
      "ðŸ“¦ X_test (primeras filas):\n",
      "        0      1       2       3        4        5        6        7       8   \\\n",
      "0   17.290  22.13  114.40   947.8  0.08999  0.12730  0.09697  0.07507  0.2108   \n",
      "1   17.470  24.68  116.10   984.6  0.10490  0.16030  0.21590  0.10430  0.1538   \n",
      "2   18.010  20.56  118.40  1007.0  0.10010  0.12890  0.11700  0.07762  0.2116   \n",
      "3   22.270  19.67  152.80  1509.0  0.13260  0.27680  0.42640  0.18230  0.2556   \n",
      "4   11.060  17.12   71.25   366.5  0.11940  0.10710  0.04063  0.04268  0.1954   \n",
      "5   17.300  17.08  113.00   928.2  0.10080  0.10410  0.12660  0.08353  0.1813   \n",
      "6   13.170  21.81   85.42   531.5  0.09714  0.10470  0.08259  0.05252  0.1746   \n",
      "7   19.270  26.47  127.90  1162.0  0.09401  0.17190  0.16570  0.07593  0.1853   \n",
      "8   14.950  17.57   96.85   678.1  0.11670  0.13050  0.15390  0.08624  0.1957   \n",
      "9   18.650  17.60  123.70  1076.0  0.10990  0.16860  0.19740  0.10090  0.1907   \n",
      "10  17.680  20.74  117.40   963.7  0.11150  0.16650  0.18550  0.10540  0.1971   \n",
      "11  17.570  15.05  115.00   955.1  0.09847  0.11570  0.09875  0.07953  0.1739   \n",
      "12  14.420  16.54   94.15   641.2  0.09751  0.11390  0.08007  0.04223  0.1912   \n",
      "13  11.740  14.02   74.24   427.3  0.07813  0.04340  0.02245  0.02763  0.2101   \n",
      "14  12.360  18.54   79.01   466.7  0.08477  0.06815  0.02643  0.01921  0.1602   \n",
      "15  18.050  16.15  120.20  1006.0  0.10650  0.21460  0.16840  0.10800  0.2152   \n",
      "16  13.440  21.58   86.18   563.0  0.08162  0.06031  0.03110  0.02031  0.1784   \n",
      "17  15.500  21.08  102.90   803.1  0.11200  0.15710  0.15220  0.08481  0.2085   \n",
      "18  20.130  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
      "19  19.160  26.60  126.20  1138.0  0.10200  0.14530  0.19210  0.09664  0.1902   \n",
      "20  12.420  15.04   78.61   476.5  0.07926  0.03393  0.01053  0.01108  0.1546   \n",
      "21  13.270  17.02   84.55   546.4  0.08445  0.04994  0.03554  0.02456  0.1496   \n",
      "22   8.219  20.70   53.27   203.9  0.09405  0.13050  0.13210  0.02168  0.2222   \n",
      "23  19.100  26.29  129.10  1132.0  0.12150  0.17910  0.19370  0.14690  0.1634   \n",
      "\n",
      "         9   ...      20     21      22      23      24       25       26  \\\n",
      "0   0.05464  ...  20.390  27.24  137.90  1295.0  0.1134  0.28670  0.22980   \n",
      "1   0.06365  ...  23.140  32.33  155.30  1660.0  0.1376  0.38300  0.48900   \n",
      "2   0.06077  ...  21.530  26.06  143.40  1426.0  0.1309  0.23270  0.25440   \n",
      "3   0.07039  ...  28.400  28.01  206.80  2360.0  0.1701  0.69970  0.96080   \n",
      "4   0.07976  ...  11.690  20.74   76.08   411.1  0.1662  0.20310  0.12560   \n",
      "5   0.05613  ...  19.850  25.09  130.90  1222.0  0.1416  0.24050  0.33780   \n",
      "6   0.06177  ...  16.230  29.89  105.50   740.7  0.1503  0.39040  0.37280   \n",
      "7   0.06261  ...  24.150  30.90  161.40  1813.0  0.1509  0.65900  0.60910   \n",
      "8   0.06216  ...  18.550  21.43  121.40   971.4  0.1411  0.21640  0.33550   \n",
      "9   0.06049  ...  22.820  21.32  150.60  1567.0  0.1679  0.50900  0.73450   \n",
      "10  0.06166  ...  20.470  25.11  132.90  1302.0  0.1418  0.34980  0.35830   \n",
      "11  0.06149  ...  20.010  19.52  134.90  1227.0  0.1255  0.28120  0.24890   \n",
      "12  0.06412  ...  16.670  21.51  111.40   862.1  0.1294  0.33710  0.37550   \n",
      "13  0.06113  ...  13.310  18.26   84.70   533.7  0.1036  0.08500  0.06735   \n",
      "14  0.06066  ...  13.290  27.49   85.56   544.1  0.1184  0.19630  0.19370   \n",
      "15  0.06673  ...  22.390  18.91  150.10  1610.0  0.1478  0.56340  0.37860   \n",
      "16  0.05587  ...  15.930  30.25  102.50   787.9  0.1094  0.20430  0.20850   \n",
      "17  0.06864  ...  23.170  27.65  157.10  1748.0  0.1517  0.40020  0.42110   \n",
      "18  0.05533  ...  23.690  38.25  155.00  1731.0  0.1166  0.19220  0.32150   \n",
      "19  0.06220  ...  23.720  35.90  159.80  1724.0  0.1782  0.38410  0.57540   \n",
      "20  0.05754  ...  13.200  20.37   83.85   543.4  0.1037  0.07776  0.06243   \n",
      "21  0.05674  ...  15.140  23.60   98.84   708.8  0.1276  0.13110  0.17860   \n",
      "22  0.08261  ...   9.092  29.72   58.08   249.8  0.1630  0.43100  0.53810   \n",
      "23  0.07224  ...  20.330  32.72  141.30  1298.0  0.1392  0.28170  0.24320   \n",
      "\n",
      "         27      28       29  \n",
      "0   0.15280  0.3067  0.07484  \n",
      "1   0.17210  0.2160  0.09300  \n",
      "2   0.14890  0.3251  0.07625  \n",
      "3   0.29100  0.4055  0.09789  \n",
      "4   0.09514  0.2780  0.11680  \n",
      "5   0.18570  0.3138  0.08113  \n",
      "6   0.16070  0.3693  0.09618  \n",
      "7   0.17850  0.3672  0.11230  \n",
      "8   0.16670  0.3414  0.07147  \n",
      "9   0.23780  0.3799  0.09185  \n",
      "10  0.15150  0.2463  0.07738  \n",
      "11  0.14560  0.2756  0.07919  \n",
      "12  0.14140  0.3053  0.08764  \n",
      "13  0.08290  0.3101  0.06688  \n",
      "14  0.08442  0.2983  0.07185  \n",
      "15  0.21020  0.3751  0.11080  \n",
      "16  0.11120  0.2994  0.07146  \n",
      "17  0.21340  0.3003  0.10480  \n",
      "18  0.16280  0.2572  0.06637  \n",
      "19  0.18720  0.3258  0.09720  \n",
      "20  0.04052  0.2901  0.06783  \n",
      "21  0.09678  0.2506  0.07623  \n",
      "22  0.07879  0.3322  0.14860  \n",
      "23  0.18410  0.2311  0.09203  \n",
      "\n",
      "[24 rows x 30 columns]\n",
      "\n",
      "ðŸŽ¯ y_test (primeros valores):\n",
      "[1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1]\n",
      "['radiusMEAN', 'textureMEAN', 'perimeterMEAN', 'areaMEAN', 'smoothnessMEAN', 'compactnessMEAN', 'concavityMEAN', 'concave pointsMEAN', 'symmetryMEAN', 'fractaldimensionMEAN', 'radiusSE', 'textureSE', 'perimeterSE', 'areaSE', 'smoothnessSE', 'compactnessSE', 'concavitySE', 'concave pointsSE', 'symmetrySE', 'fractalDimensionSE', 'radiusWORST', 'textureWORST', 'perimeterWORST', 'areaWORST', 'smoothnessWORST', 'compactnessWORST', 'concavityWORST', 'concavePointsWORST', 'symmetryWORST', 'fractalDimensionWORST']\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor = load_data_general(\n",
    "    DATASET_NAME, CLASS_COLUMN, partition_id=0, num_partitions=NUM_CLIENTS\n",
    ")\n",
    "\n",
    "# Mostrar 5 primeros valores\n",
    "print(\"\\nðŸ“¦ X_train (primeras filas):\")\n",
    "print(pd.DataFrame(X_train))\n",
    "\n",
    "print(\"\\nðŸŽ¯ y_train (primeros valores):\")\n",
    "print(y_train)\n",
    "\n",
    "print(\"\\nðŸ“¦ X_test (primeras filas):\")\n",
    "print(pd.DataFrame(X_test))\n",
    "\n",
    "print(\"\\nðŸŽ¯ y_test (primeros valores):\")\n",
    "print(y_test)\n",
    "\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346e6dc",
   "metadata": {},
   "source": [
    "# Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab462923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# ðŸŒ¼ CLIENTE FLOWER\n",
    "# ==========================\n",
    "import operator\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from flwr.client import NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.common import parameters_to_ndarrays\n",
    "\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.rule import Expression, Rule\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "class TorchNNWrapper:\n",
    "    def __init__(self, model, num_idx, mean, scale):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.num_idx = np.asarray(num_idx, dtype=int)\n",
    "        self.mean = np.asarray(mean, dtype=np.float32)\n",
    "        self.scale = np.asarray(scale, dtype=np.float32)\n",
    "        self.scale_safe = np.where(self.scale == 0, 1.0, self.scale)\n",
    "\n",
    "    def _scale_internally(self, X):\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        Xs = X.copy()\n",
    "        # soporta [n, d] o [d]\n",
    "        if Xs.ndim == 1:\n",
    "            Xs = Xs[None, :]\n",
    "        Xs[:, self.num_idx] = (Xs[:, self.num_idx] - self.mean) / self.scale_safe\n",
    "        return Xs\n",
    "\n",
    "    def predict(self, X):\n",
    "        Xs = self._scale_internally(X)\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(Xs, dtype=torch.float32)\n",
    "            logits = self.model(X_tensor)\n",
    "            return logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        Xs = self._scale_internally(X)\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(Xs, dtype=torch.float32)\n",
    "            logits = self.model(X_tensor)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            return probs.cpu().numpy()\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_dim = max(8, input_dim * 2)  # algo proporcional\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "        \n",
    "\n",
    "class FlowerClient(NumPyClient, ClientUtilsMixin):\n",
    "    def __init__(self, tree_model, nn_model, X_train, y_train, X_test, y_test, X_train_nn, X_test_nn, scaler_nn_mean, scaler_nn_scale, num_idx, dataset, client_id, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor):\n",
    "        self.tree_model = tree_model\n",
    "        self.nn_model = nn_model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.X_train_nn = X_train_nn\n",
    "        self.X_test_nn  = X_test_nn\n",
    "        self.scaler_nn_mean = np.asarray(scaler_nn_mean, dtype=np.float32)\n",
    "        self.scaler_nn_scale = np.where(np.asarray(scaler_nn_scale, np.float32)==0, 1.0, np.asarray(scaler_nn_scale, np.float32))\n",
    "        self.num_idx = np.asarray(num_idx, dtype=int)\n",
    "        self.dataset = dataset\n",
    "        self.client_id = client_id\n",
    "        self.feature_names = feature_names\n",
    "        self.label_encoder = label_encoder\n",
    "        self.scaler = scaler\n",
    "        self.numeric_features = numeric_features\n",
    "        self.encoder = encoder\n",
    "        self.unique_labels = label_encoder.classes_.tolist()\n",
    "        self.y_train_nn = y_train.astype(np.int64)\n",
    "        self.y_test_nn = y_test.astype(np.int64)\n",
    "        self.received_supertree = None\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def _train_nn(self, epochs=10, lr=1e-3):\n",
    "        self.nn_model.train()\n",
    "        optimizer = torch.optim.Adam(self.nn_model.parameters(), lr=lr)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        X_tensor = torch.tensor(self.X_train_nn, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(self.y_train_nn, dtype=torch.long)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.nn_model(X_tensor)\n",
    "            loss = loss_fn(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"[CLIENTE {self.client_id}] âœ… Red neuronal entrenada\")\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_model_params(self.tree_model, self.nn_model, {\"tree\": [\n",
    "            self.tree_model.get_params()[\"max_depth\"],\n",
    "            self.tree_model.get_params()[\"min_samples_split\"],\n",
    "            self.tree_model.get_params()[\"min_samples_leaf\"],\n",
    "        ], \"nn\": parameters})\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        if round_number <= NUM_TRAIN_ROUNDS:\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "            self._train_nn()\n",
    "\n",
    "\n",
    "        nn_weights = get_model_parameters(self.tree_model, self.nn_model)[\"nn\"]\n",
    "        return nn_weights, len(self.X_train), {}\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "\n",
    "\n",
    "        set_model_params(self.tree_model, self.nn_model, {\"tree\": [\n",
    "            self.tree_model.get_params()[\"max_depth\"],\n",
    "            self.tree_model.get_params()[\"min_samples_split\"],\n",
    "            self.tree_model.get_params()[\"min_samples_leaf\"],\n",
    "        ], \"nn\": parameters})\n",
    "\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        explain_only = config.get(\"explain_only\", False)\n",
    "\n",
    "        if \"supertree\" in config:\n",
    "            try:\n",
    "                print(\"Recibiendo supertree....\")\n",
    "                supertree_dict = json.loads(config[\"supertree\"])\n",
    "\n",
    "                self.received_supertree = SuperTree.convert_SuperNode_to_Node(SuperTree.SuperNode.from_dict(supertree_dict))\n",
    "                self.global_mapping = json.loads(config[\"global_mapping\"])\n",
    "                self.feature_names = json.loads(config[\"feature_names\"])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[CLIENTE {self.client_id}] âŒ Error al recibir SuperTree: {e}\")\n",
    "\n",
    "\n",
    "            # ðŸ”¹ CASO 1: rondas de entrenamiento (1..NUM_TRAIN_ROUNDS)\n",
    "        if not explain_only:\n",
    "\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "            supertree = SuperTree()\n",
    "            root_node = supertree.rec_buildTree(self.tree_model, list(range(self.X_train.shape[1])), len(self.unique_labels))\n",
    "        \n",
    "            root_node = supertree.prune_redundant_leaves_local(root_node)\n",
    "\n",
    "\n",
    "            self._save_local_tree(root_node, round_number, FEATURES, self.numeric_features,\n",
    "                                scaler=None, unique_labels=UNIQUE_LABELS, encoder=self.encoder)\n",
    "            tree_json = json.dumps([root_node.to_dict()])\n",
    "\n",
    "            # En rondas de entrenamiento NO explicas todo el test (si no quieres)\n",
    "            if self.received_supertree is not None and round_number == NUM_TRAIN_ROUNDS:\n",
    "                pass\n",
    "\n",
    "            return 0.0, len(self.X_test), {\n",
    "                f\"tree_ensemble_{self.client_id}\": tree_json,\n",
    "                f\"encoded_feature_names_{self.client_id}\": json.dumps(FEATURES),\n",
    "                f\"numeric_features_{self.client_id}\": json.dumps(self.numeric_features),\n",
    "                f\"unique_labels_{self.client_id}\": json.dumps(self.unique_labels),\n",
    "                f\"distinct_values_{self.client_id}\": json.dumps(self.encoder.dataset_descriptor[\"categorical\"])\n",
    "            }\n",
    "\n",
    "         # ðŸ”¹ CASO 2: ronda final (solo explicaciÃ³n con Supertree final)\n",
    "        else:\n",
    "            print(f\"[CLIENTE {self.client_id}] ðŸ” Ronda final: solo explicaciones\")\n",
    "            # aquÃ­ NO entrenamos self.tree_model ni mandamos tree_ensemble_*\n",
    "\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "            # Usamos el SuperTree final recibido + LORE + mergedTree\n",
    "            if self.received_supertree is not None:\n",
    "                \n",
    "                self.explain_all_test_instances(config)\n",
    "                # self.explain_all_test_instances(config, only_idx=0)\n",
    "\n",
    "            # Puedes devolver mÃ©tricas dummy o medias de lo que has calculado en explain_all_test_instances\n",
    "            return 0.0, len(self.X_test), {}\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def _explain_one_instance(self, num_row, config, save_trees=False):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        import numpy as np\n",
    "        \n",
    "\n",
    "        # Wrapper que escala SOLO para la NN (espacio NN)\n",
    "        nn_wrapper = TorchNNWrapper(\n",
    "            self.nn_model,\n",
    "            num_idx=self.num_idx,\n",
    "            mean=self.scaler_nn_mean,\n",
    "            scale=self.scaler_nn_scale,\n",
    "        )\n",
    "\n",
    "        # 1. Visualizar instancia escalada y decodificada usando el encoder/preprocessor ORIGINAL\n",
    "        \n",
    "        decoded = self.decode_onehot_instance(\n",
    "            self.X_test[num_row],\n",
    "            self.numeric_features,\n",
    "            self.encoder,\n",
    "            None,                 # <-- sin scaler (en crudo)\n",
    "            self.feature_names\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        # AsegÃºrate de que X_test[num_row] es un numpy array del shape correcto (1, n_features)\n",
    "        row = np.asarray(self.X_test[num_row], dtype=np.float32)\n",
    "        probs = nn_wrapper.predict_proba(row[None, :])\n",
    "        pred_class_idx = int(probs.argmax(axis=1)[0])\n",
    "        pred_class = self.label_encoder.inverse_transform([pred_class_idx])[0]\n",
    "\n",
    "        # 2. Construir DataFrame para LORE (si es necesario, solo para TabularDataset)\n",
    "\n",
    "        local_df = pd.DataFrame(self.X_train, columns=self.feature_names).astype(np.float32)\n",
    "        local_df[\"class\"] = self.label_encoder.inverse_transform(self.y_train_nn)\n",
    "        local_tabular_dataset = TabularDataset(local_df, class_name=\"class\")\n",
    "\n",
    "\n",
    "        # Explicabilidad local y la vecindad es generada del train (local_tabular_dataset)\n",
    "        bbox = sklearn_classifier_bbox.sklearnBBox(nn_wrapper)\n",
    "        lore_vecindad = TabularGeneticGeneratorLore(bbox, local_tabular_dataset)\n",
    "\n",
    "\n",
    "        # ExplicaciÃ³n LORE\n",
    "        x_instance = pd.Series(self.X_test[num_row], index=self.feature_names)\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "\n",
    "        # print(\"Instancia a explicar (decodificada):\")\n",
    "        # print(x_instance)\n",
    "\n",
    "        # t0 = time.perf_counter()\n",
    "        explanation = lore_vecindad.explain_instance(x_instance, merge=True, num_classes=len(UNIQUE_LABELS), feature_names= self.feature_names, categorical_features=list(self.global_mapping.keys()), global_mapping=self.global_mapping, UNIQUE_LABELS=UNIQUE_LABELS,\n",
    "                                                    client_id=self.client_id, round_number=round_number)\n",
    "\n",
    "        lore_tree = explanation[\"merged_tree\"]\n",
    "        \n",
    "        if save_trees:\n",
    "            self.save_lore_tree_image(lore_tree.root,round_number,self.feature_names,self.numeric_features,UNIQUE_LABELS,self.encoder,folder=\"LoreTree\")\n",
    "\n",
    "        merged_tree = SuperTree()\n",
    "        merged_tree.mergeDecisionTrees(\n",
    "            roots=[lore_tree.root, self.received_supertree],\n",
    "            num_classes=len(self.unique_labels),\n",
    "            feature_names=self.feature_names,\n",
    "            categorical_features=list(self.global_mapping.keys()), \n",
    "            global_mapping=self.global_mapping\n",
    "        )\n",
    "        \n",
    "        merged_tree.prune_redundant_leaves_full()\n",
    "\n",
    "\n",
    "        if save_trees:\n",
    "            self.save_mergedTree_plot(root_node=merged_tree.root,round_number=round_number,feature_names=self.feature_names,class_names=self.unique_labels,numeric_features=self.numeric_features,scaler=None, global_mapping=self.global_mapping,folder=\"MergedTree\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # ========================================================================================================================================================================================================\n",
    "        # CREACIÃ“N DE ÃRBOL LOCAL SOBRE Z ETIQUETADO POR EL ÃRBOL LOCAL y el SUPERTREE, PARA LUEGO UNIRLO AL LORE TREE\n",
    "        # ========================================================================================================================================================================================================\n",
    "\n",
    "\n",
    "        Z = explanation[\"neighborhood_Z\"] # instancias del vecindario sintÃ©tico generado alrededor del punto a explicar.\n",
    "        y_bb = explanation[\"neighborhood_Yb\"] # predicciones del modelo BBOX (red neuronal) sobre Z (el vecindario).\n",
    "\n",
    "        y_surrogate_preds = explanation[\"surrogate_preds\"]  # predicciones del modelo interpretable (arbol - LORE Tree) sobre Z (el vecindario).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Convertir Z en DataFrame legible\n",
    "        dfZ = pd.DataFrame(Z, columns=self.feature_names)\n",
    "                \n",
    "        y_local_Z = self.tree_model.predict(Z)\n",
    "        y_local_supertree_Z = self.received_supertree.predict(Z)\n",
    "\n",
    "\n",
    "\n",
    "        # Ãrboles entrenados sobre la vecindad Z etiquetada por el Ã¡rbol local y el SuperTree\n",
    "        local_local_clf = DecisionTreeClassifier(\n",
    "            max_depth=self.tree_model.get_params()[\"max_depth\"],\n",
    "            min_samples_split=self.tree_model.get_params()[\"min_samples_split\"],\n",
    "            min_samples_leaf=self.tree_model.get_params()[\"min_samples_leaf\"],\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        local_supertree_clf = DecisionTreeClassifier(\n",
    "            max_depth=self.tree_model.get_params()[\"max_depth\"],\n",
    "            min_samples_split=self.tree_model.get_params()[\"min_samples_split\"],\n",
    "            min_samples_leaf=self.tree_model.get_params()[\"min_samples_leaf\"],\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        local_local_clf.fit(Z, y_local_Z)\n",
    "        local_supertree_clf.fit(Z, y_local_supertree_Z)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Pasarlo a SuperTree.Node para poder hacer merge\n",
    "        st_local_local = SuperTree()\n",
    "        root_local_local = st_local_local.rec_buildTree(\n",
    "            local_local_clf,\n",
    "            list(range(Z.shape[1])),\n",
    "            len(self.unique_labels),\n",
    "        )\n",
    "\n",
    "        st_local_supertree = SuperTree()\n",
    "        root_local_supertree = st_local_supertree.rec_buildTree(\n",
    "            local_supertree_clf,\n",
    "            list(range(Z.shape[1])),\n",
    "            len(self.unique_labels),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        root_local_local = st_local_local.prune_redundant_leaves_local(root_local_local)\n",
    "        root_local_supertree = st_local_supertree.prune_redundant_leaves_local(root_local_supertree)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        local_local_tree = SuperTree()\n",
    "        local_local_tree.mergeDecisionTrees(\n",
    "            roots=[lore_tree.root, root_local_local],\n",
    "            num_classes=len(self.unique_labels),\n",
    "            feature_names=self.feature_names,\n",
    "            categorical_features=list(self.global_mapping.keys()),\n",
    "            global_mapping=self.global_mapping,\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "        local_super_tree = SuperTree()\n",
    "        local_super_tree.mergeDecisionTrees(\n",
    "            roots=[lore_tree.root, root_local_local, root_local_supertree],\n",
    "            num_classes=len(self.unique_labels),\n",
    "            feature_names=self.feature_names,\n",
    "            categorical_features=list(self.global_mapping.keys()),\n",
    "            global_mapping=self.global_mapping,\n",
    "        )\n",
    "\n",
    "        local_local_tree.prune_redundant_leaves_full()\n",
    "        local_super_tree.prune_redundant_leaves_full()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        tree_str = self.tree_to_str(merged_tree.root,self.feature_names,numeric_features=self.numeric_features,scaler=None, global_mapping=self.global_mapping,unique_labels=self.unique_labels)\n",
    "        lore_tree_str = self.tree_to_str(lore_tree.root, self.feature_names, numeric_features=self.numeric_features,scaler=None,global_mapping=self.global_mapping,unique_labels=self.unique_labels)\n",
    "        supertree_str = self.tree_to_str(self.received_supertree, self.feature_names, numeric_features=self.numeric_features,scaler=None,global_mapping=self.global_mapping,unique_labels=self.unique_labels)\n",
    "        local_local_tree_str = self.tree_to_str(local_local_tree.root,self.feature_names,numeric_features=self.numeric_features,scaler=None, global_mapping=self.global_mapping,unique_labels=self.unique_labels)\n",
    "        local_super_tree_str = self.tree_to_str(local_super_tree.root,self.feature_names,numeric_features=self.numeric_features,scaler=None, global_mapping=self.global_mapping,unique_labels=self.unique_labels)\n",
    "        tree_str_localZ = self.tree_to_str(root_local_local, self.feature_names, numeric_features=self.numeric_features,scaler=None,global_mapping=self.global_mapping,unique_labels=self.unique_labels)\n",
    "        tree_str_superZ = self.tree_to_str(root_local_supertree,self.feature_names,numeric_features=self.numeric_features,scaler=None,global_mapping=self.global_mapping,unique_labels=self.unique_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        rules = self.extract_rules_from_str(tree_str, target_class_label=pred_class)\n",
    "        rules_lore = self.extract_rules_from_str(lore_tree_str, target_class_label=pred_class)\n",
    "        rules_supertree = self.extract_rules_from_str(supertree_str, target_class_label=pred_class)\n",
    "        rules_local_local = self.extract_rules_from_str(local_local_tree_str, target_class_label=pred_class)\n",
    "        rules_local_super = self.extract_rules_from_str(local_super_tree_str, target_class_label=pred_class)\n",
    "        rules_localZ = self.extract_rules_from_str(tree_str_localZ, target_class_label=pred_class)\n",
    "        rules_superZ = self.extract_rules_from_str(tree_str_superZ, target_class_label=pred_class)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        def cumple_regla(instancia, regla):\n",
    "            for cond in regla:\n",
    "                if \"âˆ§\" in cond:\n",
    "                    # Maneja condiciones tipo intervalo: 'age > 44.33 âˆ§ â‰¤ 48.50'\n",
    "                    import re\n",
    "                    # Busca: variable, operador1, valor1, operador2, valor2\n",
    "                    m = re.match(r'(.+?)([><]=?|â‰¤|â‰¥)\\s*([-\\d\\.]+)\\s*âˆ§\\s*([><]=?|â‰¤|â‰¥)\\s*([-\\d\\.]+)', cond)\n",
    "                    if m:\n",
    "                        var = m.group(1).strip()\n",
    "                        op1, val1 = m.group(2), float(m.group(3))\n",
    "                        op2, val2 = m.group(4), float(m.group(5))\n",
    "                        v = instancia[var]\n",
    "                        # EvalÃºa las dos condiciones del intervalo\n",
    "                        if not (\n",
    "                            eval(f\"v {op1.replace('â‰¤','<=').replace('â‰¥','>=')} {val1}\") and\n",
    "                            eval(f\"v {op2.replace('â‰¤','<=').replace('â‰¥','>=')} {val2}\")\n",
    "                        ):\n",
    "                            return False\n",
    "                        continue  # sigue al siguiente cond\n",
    "                # ... resto de tu cÃ³digo tal cual ...\n",
    "                if \"â‰¤\" in cond:\n",
    "                    var, val = cond.split(\"â‰¤\")\n",
    "                    var = var.strip()\n",
    "                    val = float(val.strip())\n",
    "                    if instancia[var] > val:\n",
    "                        return False\n",
    "                elif \">=\" in cond or \"â‰¥\" in cond:\n",
    "                    var, val = cond.replace(\"â‰¥\", \">=\").split(\">=\")\n",
    "                    var = var.strip()\n",
    "                    val = float(val.strip())\n",
    "                    if instancia[var] < val:\n",
    "                        return False\n",
    "                elif \">\" in cond:\n",
    "                    var, val = cond.split(\">\")\n",
    "                    var = var.strip()\n",
    "                    val = float(val.strip())\n",
    "                    if instancia[var] <= val:\n",
    "                        return False\n",
    "                elif \"<\" in cond:\n",
    "                    var, val = cond.split(\"<\")\n",
    "                    var = var.strip()\n",
    "                    val = float(val.strip())\n",
    "                    if instancia[var] >= val:\n",
    "                        return False\n",
    "                elif \"â‰ \" in cond:\n",
    "                    var, val = cond.split(\"â‰ \")\n",
    "                    var = var.strip()\n",
    "                    val = val.strip().replace('\"', \"\")\n",
    "                    if instancia[var] == val:\n",
    "                        return False\n",
    "                elif \"=\" in cond:\n",
    "                    var, val = cond.split(\"=\")\n",
    "                    var = var.strip()\n",
    "                    val = val.strip().replace('\"', \"\")\n",
    "                    if instancia[var] != val:\n",
    "                        return False\n",
    "            return True\n",
    "\n",
    "        # Buscar la regla factual (la que cubre la instancia)\n",
    "        regla_factual = None\n",
    "        for regla in rules:\n",
    "            if cumple_regla(decoded, regla):\n",
    "                regla_factual = regla\n",
    "                break\n",
    "        \n",
    "        regla_factual_lore = None\n",
    "        for r in rules_lore:\n",
    "            if cumple_regla(decoded, r):\n",
    "                regla_factual_lore = r\n",
    "                break\n",
    "\n",
    "        regla_factual_supertree = None\n",
    "        for r in rules_supertree:\n",
    "            if cumple_regla(decoded, r):\n",
    "                regla_factual_supertree = r\n",
    "                break\n",
    "\n",
    "        regla_factual_local_local = None\n",
    "        for r in rules_local_local:\n",
    "            if cumple_regla(decoded, r):\n",
    "                regla_factual_local_local = r\n",
    "                break\n",
    "        \n",
    "        regla_factual_local_super = None\n",
    "        for r in rules_local_super: \n",
    "            if cumple_regla(decoded, r):\n",
    "                regla_factual_local_super = r\n",
    "                break\n",
    "        \n",
    "        regla_factual_localZ = None\n",
    "        for r in rules_localZ:\n",
    "            if cumple_regla(decoded, r):\n",
    "                regla_factual_localZ = r\n",
    "                break\n",
    "        \n",
    "        regla_factual_superZ = None\n",
    "        for r in rules_superZ:\n",
    "            if cumple_regla(decoded, r):\n",
    "                regla_factual_superZ = r\n",
    "                break\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Extraer 1 contrafactual por cada clase distinta a la predicha\n",
    "        cf_rules_por_clase = {}\n",
    "        for clase in self.unique_labels:\n",
    "            if clase != pred_class:\n",
    "                rules_clase = self.extract_rules_from_str(tree_str, target_class_label=clase)\n",
    "                if rules_clase:\n",
    "                    # Elige la mÃ¡s sencilla (menos condiciones)\n",
    "                    cf_rules_por_clase[clase] = min(rules_clase, key=len)\n",
    "\n",
    "\n",
    "\n",
    "        # Extraer 1 contrafactual tipo LORE por cada clase distinta a la predicha\n",
    "        cf_rules_LORE_por_clase = {}\n",
    "        for clase in self.unique_labels:\n",
    "            if clase != pred_class:\n",
    "                rules_clase = self.extract_rules_from_str(lore_tree_str, target_class_label=clase)\n",
    "                if rules_clase:\n",
    "                    # Elige la mÃ¡s sencilla (menos condiciones)\n",
    "                    cf_rules_LORE_por_clase[clase] = min(rules_clase, key=len)\n",
    "\n",
    "\n",
    "        cf_rules_Supertree_por_clase = {}\n",
    "        for clase in self.unique_labels:\n",
    "            if clase != pred_class:\n",
    "                rules_clase = self.extract_rules_from_str(supertree_str, target_class_label=clase)\n",
    "                if rules_clase:\n",
    "                    # Elige la mÃ¡s sencilla (menos condiciones)\n",
    "                    cf_rules_Supertree_por_clase[clase] = min(rules_clase, key=len)\n",
    "\n",
    "\n",
    "\n",
    "        cf_rules_local_local_por_clase = {}\n",
    "        for clase in self.unique_labels:\n",
    "            if clase != pred_class:\n",
    "                rules_clase = self.extract_rules_from_str(local_local_tree_str, target_class_label=clase)\n",
    "                if rules_clase:\n",
    "                    # Elige la mÃ¡s sencilla (menos condiciones)\n",
    "                    cf_rules_local_local_por_clase[clase] = min(rules_clase, key=len)\n",
    "\n",
    "\n",
    "\n",
    "        cf_rules_local_super_por_clase = {}\n",
    "        for clase in self.unique_labels:\n",
    "            if clase != pred_class:\n",
    "                rules_clase = self.extract_rules_from_str(local_super_tree_str, target_class_label=clase)\n",
    "                if rules_clase:\n",
    "                    # Elige la mÃ¡s sencilla (menos condiciones)\n",
    "                    cf_rules_local_super_por_clase[clase] = min(rules_clase, key=len)\n",
    "\n",
    "\n",
    "\n",
    "        cf_rules_localZ_por_clase = {}\n",
    "        for clase in self.unique_labels:\n",
    "            if clase != pred_class:\n",
    "                rules_clase = self.extract_rules_from_str(tree_str_localZ, target_class_label=clase)\n",
    "                if rules_clase:\n",
    "                    # Elige la mÃ¡s sencilla (menos condiciones)\n",
    "                    cf_rules_localZ_por_clase[clase] = min(rules_clase, key=len)\n",
    "\n",
    "\n",
    "\n",
    "        cf_rules_superZ_por_clase = {}\n",
    "        for clase in self.unique_labels:\n",
    "            if clase != pred_class:\n",
    "                rules_clase = self.extract_rules_from_str(tree_str_superZ, target_class_label=clase)\n",
    "                if rules_clase:\n",
    "                    # Elige la mÃ¡s sencilla (menos condiciones)\n",
    "                    cf_rules_superZ_por_clase[clase] = min(rules_clase, key=len)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # ========================================================================================================================================================================================================\n",
    "        # ðŸ“ MÃ‰TRICAS DE EXPLICABILIDAD LOCAL (vecindario Z)\n",
    "        # \n",
    "        # Silhouette:  Distancia media entre x y las instancias de su misma clase en el vecindario (Z+)\n",
    "        # ========================================================================================================================================================================================================\n",
    "        mask_same_class = (y_bb == pred_class_idx)\n",
    "        mask_diff_class = (y_bb != pred_class_idx)\n",
    "\n",
    "        Z_plus = dfZ[mask_same_class]\n",
    "        Z_minus = dfZ[mask_diff_class]\n",
    "\n",
    "        x = self.X_test[num_row]\n",
    "\n",
    "        a = pairwise_distances([x], Z_plus).mean() if len(Z_plus) > 0 else 0.0\n",
    "        b = pairwise_distances([x], Z_minus).mean() if len(Z_minus) > 0 else 0.0\n",
    "\n",
    "        silhouette = 0.0\n",
    "        if (a + b) > 0:\n",
    "            silhouette = (b - a) / max(a, b)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # ==================================================================================================================\n",
    "        # MÃ‰TRICAS DE COMPARATIVA DE PRECISION DE LOS ÃRBOLES CON EL TEST (QUE TAN BUENOS SON LOS ARBOLES QUE HEMOS GENERADO)\n",
    "        # ==================================================================================================================\n",
    "\n",
    "        y_true = self.y_test\n",
    "\n",
    "        # Predicciones\n",
    "        y_pred_lore = lore_tree.root.predict(self.X_test)\n",
    "        y_pred_merged = merged_tree.root.predict(self.X_test)\n",
    "        y_pred_super = self.received_supertree.predict(self.X_test)\n",
    "        y_pred_local_local = local_local_tree.root.predict(self.X_test)\n",
    "        y_pred_local_super = local_super_tree.root.predict(self.X_test)\n",
    "\n",
    "\n",
    "        y_pred_localZ_tree  = root_local_local.predict(self.X_test)        # Z etiquetada por local\n",
    "        y_pred_superZ_tree  = root_local_supertree.predict(self.X_test)    # Z etiquetada por supertree\n",
    "\n",
    "        # Accuracy\n",
    "        acc_lore = accuracy_score(y_true, y_pred_lore)\n",
    "        acc_merged = accuracy_score(y_true, y_pred_merged)\n",
    "        acc_super = accuracy_score(y_true, y_pred_super)\n",
    "        acc_local_local = accuracy_score(y_true, y_pred_local_local)\n",
    "        acc_local_super = accuracy_score(y_true, y_pred_local_super)\n",
    "        acc_localZ_tree_TEST  = accuracy_score(y_true, y_pred_localZ_tree)\n",
    "        acc_superZ_tree_TEST  = accuracy_score(y_true, y_pred_superZ_tree)\n",
    "\n",
    "\n",
    "        # Precision, Recall, F1\n",
    "        prec_lore = precision_score(y_true, y_pred_lore, average=\"weighted\")\n",
    "        rec_lore  = recall_score(y_true, y_pred_lore, average=\"weighted\")\n",
    "        f1_lore   = f1_score(y_true, y_pred_lore, average=\"weighted\")\n",
    "\n",
    "        prec_merged = precision_score(y_true, y_pred_merged, average=\"weighted\")\n",
    "        rec_merged  = recall_score(y_true, y_pred_merged, average=\"weighted\")\n",
    "        f1_merged   = f1_score(y_true, y_pred_merged, average=\"weighted\")\n",
    "\n",
    "        prec_super = precision_score(y_true, y_pred_super, average=\"weighted\")\n",
    "        rec_super  = recall_score(y_true, y_pred_super, average=\"weighted\")\n",
    "        f1_super   = f1_score(y_true, y_pred_super, average=\"weighted\")\n",
    "\n",
    "        prec_local_local = precision_score(y_true, y_pred_local_local, average=\"weighted\")\n",
    "        rec_local_local  = recall_score(y_true, y_pred_local_local, average=\"weighted\")\n",
    "        f1_local_local   = f1_score(y_true, y_pred_local_local, average=\"weighted\")\n",
    "\n",
    "        prec_local_super = precision_score(y_true, y_pred_local_super, average=\"weighted\")\n",
    "        rec_local_super  = recall_score(y_true, y_pred_local_super, average=\"weighted\")\n",
    "        f1_local_super   = f1_score(y_true, y_pred_local_super, average=\"weighted\")\n",
    "\n",
    "        prec_localZ_tree_TEST = precision_score(y_true, y_pred_localZ_tree, average=\"weighted\")\n",
    "        rec_localZ_tree_TEST  = recall_score(y_true, y_pred_localZ_tree, average=\"weighted\")\n",
    "        f1_localZ_tree_TEST   = f1_score(y_true, y_pred_localZ_tree, average=\"weighted\")\n",
    "\n",
    "        prec_superZ_tree_TEST = precision_score(y_true, y_pred_superZ_tree, average=\"weighted\")\n",
    "        rec_superZ_tree_TEST  = recall_score(y_true, y_pred_superZ_tree, average=\"weighted\")\n",
    "        f1_superZ_tree_TEST   = f1_score(y_true, y_pred_superZ_tree, average=\"weighted\")\n",
    "\n",
    "        # ===================================================\n",
    "        # MÃ‰TRICAS EN LA VECINDAD Z (QuÃ© tal imitan al BBOX)\n",
    "        # ===================================================\n",
    "\n",
    "        \n",
    "        # Predicciones de los Ã¡rboles sobre el vecindario Z\n",
    "        y_pred_lore_Z   = lore_tree.root.predict(Z)\n",
    "        y_pred_merged_Z = merged_tree.root.predict(Z)\n",
    "        y_pred_super_Z  = self.received_supertree.predict(Z)\n",
    "        y_pred_local_local_Z = local_local_tree.root.predict(Z)\n",
    "        y_pred_local_super_Z = local_super_tree.root.predict(Z)\n",
    "\n",
    "        # Local solo (Z) y SuperTree solo (Z)\n",
    "        y_pred_localZ_Z  = self.tree_model.predict(Z)           # Local solo (Z)\n",
    "        y_pred_superZ_Z  = root_local_supertree.predict(Z)      # SuperTree solo (Z)\n",
    "\n",
    "\n",
    "\n",
    "        # y_bb son las \"verdades\" en la vecindad (lo que dice el BBOX)\n",
    "        acc_lore_Z   = accuracy_score(y_bb, y_pred_lore_Z)\n",
    "        acc_merged_Z = accuracy_score(y_bb, y_pred_merged_Z)\n",
    "        acc_super_Z  = accuracy_score(y_bb, y_pred_super_Z)\n",
    "        acc_local_local_Z = accuracy_score(y_bb, y_pred_local_local_Z)\n",
    "        acc_local_super_Z = accuracy_score(y_bb, y_pred_local_super_Z)\n",
    "        acc_local_Z       = accuracy_score(y_bb, y_pred_localZ_Z)     # LocalZ_Z\n",
    "        acc_superZ_Z      = accuracy_score(y_bb, y_pred_superZ_Z)     # SuperZ_Z\n",
    "\n",
    "        prec_lore_Z        = precision_score(y_bb, y_pred_lore_Z,        average=\"weighted\")\n",
    "        prec_merged_Z      = precision_score(y_bb, y_pred_merged_Z,      average=\"weighted\")\n",
    "        prec_super_Z       = precision_score(y_bb, y_pred_super_Z,       average=\"weighted\")\n",
    "        prec_local_local_Z = precision_score(y_bb, y_pred_local_local_Z, average=\"weighted\")\n",
    "        prec_local_super_Z = precision_score(y_bb, y_pred_local_super_Z, average=\"weighted\")\n",
    "        prec_local_Z       = precision_score(y_bb, y_pred_localZ_Z,      average=\"weighted\")\n",
    "        prec_superZ_Z      = precision_score(y_bb, y_pred_superZ_Z,      average=\"weighted\")\n",
    "\n",
    "\n",
    "        rec_lore_Z        = recall_score(y_bb, y_pred_lore_Z,        average=\"weighted\")\n",
    "        rec_merged_Z      = recall_score(y_bb, y_pred_merged_Z,      average=\"weighted\")\n",
    "        rec_super_Z       = recall_score(y_bb, y_pred_super_Z,       average=\"weighted\")\n",
    "        rec_local_local_Z = recall_score(y_bb, y_pred_local_local_Z, average=\"weighted\")\n",
    "        rec_local_super_Z = recall_score(y_bb, y_pred_local_super_Z, average=\"weighted\")\n",
    "        rec_local_Z       = recall_score(y_bb, y_pred_localZ_Z,      average=\"weighted\")\n",
    "        rec_superZ_Z      = recall_score(y_bb, y_pred_superZ_Z,      average=\"weighted\")\n",
    "\n",
    "\n",
    "        f1_lore_Z        = f1_score(y_bb, y_pred_lore_Z,        average=\"weighted\")\n",
    "        f1_merged_Z      = f1_score(y_bb, y_pred_merged_Z,      average=\"weighted\")\n",
    "        f1_super_Z       = f1_score(y_bb, y_pred_super_Z,       average=\"weighted\")\n",
    "        f1_local_local_Z = f1_score(y_bb, y_pred_local_local_Z, average=\"weighted\")\n",
    "        f1_local_super_Z = f1_score(y_bb, y_pred_local_super_Z, average=\"weighted\")\n",
    "        f1_local_Z       = f1_score(y_bb, y_pred_localZ_Z,      average=\"weighted\")\n",
    "        f1_superZ_Z      = f1_score(y_bb, y_pred_superZ_Z,      average=\"weighted\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ============================================================================================================\n",
    "        # ðŸŒ COVERAGE / FIDELITY / SUPPORT (REGLAS FACTUALES, VERSIÃ“N GLOBAL)\n",
    "        # ============================================================================================================\n",
    "        # AquÃ­ trabajamos en TODO el conjunto de test X_test.\n",
    "        #\n",
    "        # Objetivo: para cada regla factual (del LORE tree, Merged tree y Supertree) calcular:\n",
    "        #\n",
    "        #   - coverage_factual:\n",
    "        #       De todas las instancias del test, Â¿cuÃ¡ntas cumplen la regla?\n",
    "        #\n",
    "        #   - fidelity_factual (Q_fidelity del paper, Eq. (3)):\n",
    "        #       entre las instancias que cumplen la regla, quÃ© proporciÃ³n el BBOX las clasifica como la clase c.\n",
    "        #\n",
    "        #           Q_fidelity(E) = | { x âˆˆ cover(E) : M(x) = c } | / | cover(E) |\n",
    "        #\n",
    "        #   - support_factual:\n",
    "        #       TamaÃ±o del cover(E), es decir, cuÃ¡ntas instancias de X_test satisfacen la regla.\n",
    "        #\n",
    "        # Nota:\n",
    "        #   - X_test_decoded: X_test decodificado a espacio legible (variables originales).\n",
    "        #   - y_bb_test: predicciones del BBOX (red neuronal) sobre TODO X_test.\n",
    "        #   - c_idx: Ã­ndice de la clase predicha por el BBOX para la instancia concreta que estamos explicando.\n",
    "        #            Es la clase asociada a la regla factual.\n",
    "        # ============================================================================================================\n",
    "\n",
    "        # --- Predicciones del BBOX en TODO el test (M(x)) ---\n",
    "        y_bb_test = nn_wrapper.predict(self.X_test)\n",
    "\n",
    "\n",
    "        cf_rules_por_clase_simplify = self._simplify_rules_by_class(cf_rules_por_clase, mode='loose')\n",
    "        cf_rules_LORE_por_clase_simplify = self._simplify_rules_by_class(cf_rules_LORE_por_clase, mode='loose')\n",
    "        cf_rules_Supertree_por_clase_simplify = self._simplify_rules_by_class(cf_rules_Supertree_por_clase, mode='loose')\n",
    "        cf_rules_local_local_por_clase_simplify = self._simplify_rules_by_class(cf_rules_local_local_por_clase, mode='loose')\n",
    "        cf_rules_local_super_por_clase_simplify = self._simplify_rules_by_class(cf_rules_local_super_por_clase, mode='loose')\n",
    "        cf_rules_localZ_por_clase_simplify = self._simplify_rules_by_class(cf_rules_localZ_por_clase, mode='loose')\n",
    "        cf_rules_superZ_por_clase_simplify = self._simplify_rules_by_class(cf_rules_superZ_por_clase, mode='loose')\n",
    "        \n",
    "\n",
    "        regla_factual_simplify = None\n",
    "        regla_factual_LORE_simplify = None\n",
    "        regla_factual_Supertree_simplify = None\n",
    "        regla_factual_local_local_simplify = None\n",
    "        regla_factual_local_super_simplify = None\n",
    "        regla_factual_localZ_simplify = None\n",
    "        regla_factual_superZ_simplify = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- Decodificar TODO X_test al espacio legible ---\n",
    "        Xtest_df = pd.DataFrame(self.X_test, columns=self.feature_names)\n",
    "        Xtest_decoded = Xtest_df.apply(\n",
    "            lambda r: self.decode_onehot_instance(\n",
    "                r.values, self.numeric_features, self.encoder, self.scaler, self.feature_names\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        c_idx = pred_class_idx                       # clase de la regla (c)\n",
    "\n",
    "        def coverage_fidelity_support(regla):\n",
    "            if not regla:\n",
    "                return 0.0, 0.0   # coverage, fidelity\n",
    "\n",
    "            mask_cover = Xtest_decoded.apply(\n",
    "                lambda r: cumple_regla(r, regla), axis=1\n",
    "            ).values\n",
    "            cover_count = int(mask_cover.sum())\n",
    "\n",
    "            n = len(Xtest_decoded)\n",
    "            cov = (cover_count / n) if n > 0 else 0.0\n",
    "\n",
    "            if cover_count > 0:\n",
    "                fid = float((y_bb_test[mask_cover] == c_idx).mean())\n",
    "            else:\n",
    "                fid = 0.0\n",
    "\n",
    "            return cov, fid\n",
    "        \n",
    "\n",
    "        # ---- Regla factual de cada Ã¡rbol ----\n",
    "        coverage_merged,        fidelity_merged  = coverage_fidelity_support(regla_factual)\n",
    "        coverage_lore,          fidelity_lore= coverage_fidelity_support(regla_factual_lore)\n",
    "        coverage_supertree,     fidelity_super= coverage_fidelity_support(regla_factual_supertree)\n",
    "        coverage_local_local,   fidelity_local_local= coverage_fidelity_support(regla_factual_local_local)\n",
    "        coverage_local_super,   fidelity_local_super= coverage_fidelity_support(regla_factual_local_super)\n",
    "        coverage_localZ,        fidelity_localZ= coverage_fidelity_support(regla_factual_localZ)\n",
    "        coverage_superZ,        fidelity_superZ= coverage_fidelity_support(regla_factual_superZ)\n",
    "\n",
    "        # ---- VersiÃ³n simplificada solo para imprimir / complejidad ----\n",
    "        if regla_factual:\n",
    "            regla_factual_simplify = self._simplify_rule(regla_factual, mode='loose')\n",
    "\n",
    "        if regla_factual_lore:\n",
    "            regla_factual_LORE_simplify = self._simplify_rule(regla_factual_lore, mode='loose')\n",
    "\n",
    "        if regla_factual_supertree:\n",
    "            regla_factual_Supertree_simplify = self._simplify_rule(regla_factual_supertree, mode='loose')\n",
    "\n",
    "        if regla_factual_local_local:\n",
    "            regla_factual_local_local_simplify = self._simplify_rule(regla_factual_local_local, mode='loose')\n",
    "\n",
    "        if regla_factual_local_super:\n",
    "            regla_factual_local_super_simplify = self._simplify_rule(regla_factual_local_super, mode='loose')\n",
    "\n",
    "        if regla_factual_localZ:\n",
    "            regla_factual_localZ_simplify = self._simplify_rule(regla_factual_localZ, mode='loose')\n",
    "            \n",
    "        if regla_factual_superZ:\n",
    "            regla_factual_superZ_simplify = self._simplify_rule(regla_factual_superZ, mode='loose')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # =======================\n",
    "        # VersiÃ³n vecindario (Z)\n",
    "        # =======================\n",
    "\n",
    "\n",
    "        # Decodificamos Z a espacio legible, igual que hiciste con X_test\n",
    "        dfZ_decoded = dfZ.apply(\n",
    "            lambda r: self.decode_onehot_instance(\n",
    "                r.values,\n",
    "                self.numeric_features,\n",
    "                self.encoder,\n",
    "                self.scaler,          # o None, igual que en X_test_decoded si lo estÃ¡s usando asÃ­\n",
    "                self.feature_names\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        def coverage_fidelity_support_neigh(regla):\n",
    "            if not regla:\n",
    "                return 0.0, 0.0   # coverage, fidelity\n",
    "\n",
    "            mask_cover_Z = dfZ_decoded.apply(\n",
    "                lambda r: cumple_regla(r, regla), axis=1\n",
    "            ).values\n",
    "\n",
    "            cover_count_Z = int(mask_cover_Z.sum())\n",
    "            nZ = len(dfZ_decoded)\n",
    "\n",
    "            cov_Z = (cover_count_Z / nZ) if nZ > 0 else 0.0\n",
    "\n",
    "            if cover_count_Z > 0:\n",
    "                fid_Z = float((y_bb[mask_cover_Z] == c_idx).mean())\n",
    "            else:\n",
    "                fid_Z = 0.0\n",
    "\n",
    "            return cov_Z, fid_Z\n",
    "        \n",
    "        # ---- VersiÃ³n vecindario (LOCAL) ----\n",
    "        coverage_merged_Z,          fidelity_merged_Z= coverage_fidelity_support_neigh(regla_factual)\n",
    "        coverage_lore_Z,            fidelity_lore_Z= coverage_fidelity_support_neigh(regla_factual_lore)\n",
    "        coverage_super_Z,           fidelity_super_Z= coverage_fidelity_support_neigh(regla_factual_supertree)\n",
    "        coverage_local_local_Z,     fidelity_local_local_Z= coverage_fidelity_support_neigh(regla_factual_local_local)\n",
    "        coverage_local_super_Z,     fidelity_local_super_Z= coverage_fidelity_support_neigh(regla_factual_local_super)\n",
    "        coverage_localZ_Z,          fidelity_localZ_Z= coverage_fidelity_support_neigh(regla_factual_localZ)\n",
    "        coverage_superZ_Z,          fidelity_superZ_Z= coverage_fidelity_support_neigh(regla_factual_superZ)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        # ======================================== HIT ============================================================================        \n",
    "        # BBOX predice una clase para tu instancia ð‘¥, por ejemplo \"No\".\n",
    "\n",
    "        # extract_rules_from_str(..., target_class_label=pred_class) te devuelve solo las reglas de esa clase \"No\" en el surrogate.\n",
    "\n",
    "        # Si alguna de esas reglas cubre x â†’\n",
    "\n",
    "        # Existe regla factual âœ…\n",
    "        # Esa regla ya es de la misma clase que el BBOX âœ…\n",
    "        # Entonces HIT = 1.\n",
    "\n",
    "        # Si ninguna regla de esa clase cubre x â†’ HIT = 0.\n",
    "        # ===========================================================================================================================\n",
    "\n",
    "        hit_merged = int(regla_factual is not None)              # factual del merged\n",
    "        hit_lore   = int(regla_factual_lore is not None)         # factual del LORE\n",
    "        hit_supertree = int(regla_factual_supertree is not None) # factual del supertree\n",
    "        hit_lore_local_local = int(regla_factual_local_local is not None) # factual del local_local\n",
    "        hit_lore_local_super = int(regla_factual_local_super is not None) # factual del local_super\n",
    "        hit_localZ = int(regla_factual_localZ is not None)       # factual del localZ\n",
    "        hit_superZ = int(regla_factual_superZ is not None)       # factual\n",
    "\n",
    "\n",
    "        # ============================================================================================\n",
    "        # Metricas de los Ã¡rboles\n",
    "        # ============================================================================================\n",
    "\n",
    "        depth_merged_edges = self.tree_depth_edges(merged_tree.root)\n",
    "        nodes_merged = self.count_nodes(merged_tree.root)\n",
    "        leaves_merged = self.count_leaves(merged_tree.root)\n",
    "\n",
    "        depth_lore_edges = self.tree_depth_edges(lore_tree.root)\n",
    "        nodes_lore = self.count_nodes(lore_tree.root)\n",
    "        leaves_lore = self.count_leaves(lore_tree.root)\n",
    "\n",
    "        depth_supertree_edges = self.tree_depth_edges(self.received_supertree)\n",
    "        nodes_supertree = self.count_nodes(self.received_supertree)\n",
    "        leaves_supertree = self.count_leaves(self.received_supertree)\n",
    "\n",
    "        depth_lore_edges_local_local = self.tree_depth_edges(local_local_tree.root)\n",
    "        nodes_lore_local_local = self.count_nodes(local_local_tree.root)\n",
    "        leaves_lore_local_local = self.count_leaves(local_local_tree.root)\n",
    "\n",
    "        depth_lore_edges_local_super = self.tree_depth_edges(local_super_tree.root)\n",
    "        nodes_lore_local_super = self.count_nodes(local_super_tree.root)\n",
    "        leaves_lore_local_super = self.count_leaves(local_super_tree.root)\n",
    "\n",
    "        depth_localZ_edges = self.tree_depth_edges(root_local_local)\n",
    "        nodes_localZ = self.count_nodes(root_local_local)\n",
    "        leaves_localZ = self.count_leaves(root_local_local)\n",
    "\n",
    "        depth_superZ_edges = self.tree_depth_edges(root_local_supertree)\n",
    "        nodes_superZ = self.count_nodes(root_local_supertree)\n",
    "        leaves_superZ = self.count_leaves(root_local_supertree)\n",
    "\n",
    "        # ============================================================================================================================================\n",
    "        # Complejidad de las reglas (nÃºmero de condiciones)\n",
    "        # ============================================================================================================================================\n",
    "\n",
    "        def rule_complexity(regla):\n",
    "            return len(regla) if regla else 0\n",
    "        \n",
    "        comp_factual_merged_simpl = rule_complexity(regla_factual_simplify)\n",
    "        comp_cf_merged_simpl = {cl: rule_complexity(r) for cl, r in cf_rules_por_clase_simplify.items()}\n",
    "\n",
    "        comp_factual_lore_simpl = rule_complexity(regla_factual_LORE_simplify)\n",
    "        comp_cf_lore_simpl = {cl: rule_complexity(r) for cl, r in cf_rules_LORE_por_clase_simplify.items()}\n",
    "\n",
    "        comp_factual_supertree_simpl = rule_complexity(regla_factual_Supertree_simplify)\n",
    "        comp_cf_supertree_simpl = {cl: rule_complexity(r) for cl, r in cf_rules_Supertree_por_clase_simplify.items()}\n",
    "\n",
    "        comp_factual_local_local_simpl = rule_complexity(regla_factual_local_local_simplify)\n",
    "        comp_cf_local_local_simpl = {cl: rule_complexity(r) for cl, r in cf_rules_local_local_por_clase_simplify.items()}\n",
    "\n",
    "        comp_factual_local_super_simpl = rule_complexity(regla_factual_local_super_simplify)\n",
    "        comp_cf_local_super_simpl = {cl: rule_complexity(r) for cl, r in cf_rules_local_super_por_clase_simplify.items()}\n",
    "\n",
    "        comp_factual_localZ_simpl = rule_complexity(regla_factual_localZ_simplify)\n",
    "        comp_cf_localZ_simpl = {cl: rule_complexity(r) for cl, r in cf_rules_localZ_por_clase_simplify.items()}\n",
    "\n",
    "        comp_factual_superZ_simpl = rule_complexity(regla_factual_superZ_simplify)\n",
    "        comp_cf_superZ_simpl = {cl: rule_complexity(r) for cl, r in cf_rules_superZ_por_clase_simplify.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ============================================================================================================================================\n",
    "\n",
    "        # Coverage: Â¿QuÃ© proporciÃ³n del dataset satisface este contrafactual? \n",
    "        # Es decir, cuÃ¡ntas instancias â€œquedan explicadasâ€ por este contrafactual.\n",
    "\n",
    "        # Support: Â¿CuÃ¡ntas instancias satisfacen este contrafactual?\n",
    "\n",
    "        # ============================================================================================================================================\n",
    "\n",
    "\n",
    "        def compute_cf_coverage(rules_dict):\n",
    "            coverage_cf  = {}\n",
    "            support_cf   = {}\n",
    "            precision_cf = {}\n",
    "\n",
    "            n = len(Xtest_decoded)   # tamaÃ±o del test\n",
    "\n",
    "            for clase, regla_cf in rules_dict.items():\n",
    "\n",
    "                if regla_cf:\n",
    "                    # cover(E): instancias que cumplen la regla contrafactual\n",
    "                    mask_cf_test = Xtest_decoded.apply(\n",
    "                        lambda r: cumple_regla(r, regla_cf), axis=1\n",
    "                    ).values\n",
    "\n",
    "                    sup = int(mask_cf_test.sum())      # |cover(E)|\n",
    "                    cov = sup / n if n > 0 else 0.0    # coverage global\n",
    "\n",
    "                    if sup > 0:\n",
    "                        # fidelidad en TEST: de las que cumplen el CF,\n",
    "                        # cuÃ¡ntas el BBOX las clasifica como la clase del CF\n",
    "                        clase_idx = self.label_encoder.transform([clase])[0]\n",
    "                        prec = float((y_bb_test[mask_cf_test] == clase_idx).mean())\n",
    "                    else:\n",
    "                        prec = 0.0\n",
    "                else:\n",
    "                    sup, cov, prec = 0, 0.0, 0.0\n",
    "\n",
    "                coverage_cf[clase]  = cov\n",
    "                precision_cf[clase] = prec\n",
    "\n",
    "            return coverage_cf, precision_cf\n",
    "\n",
    "\n",
    "        # --- Merged / LORE / Supertree ---\n",
    "        coverage_cf_merged,        precision_cf_merged    = compute_cf_coverage(cf_rules_por_clase_simplify)\n",
    "        coverage_cf_lore,          precision_cf_lore      = compute_cf_coverage(cf_rules_LORE_por_clase_simplify)\n",
    "        coverage_cf_supertree,     precision_cf_supertree = compute_cf_coverage(cf_rules_Supertree_por_clase_simplify)\n",
    "        coverage_cf_local_local,   precision_cf_local_local = compute_cf_coverage(cf_rules_local_local_por_clase_simplify)\n",
    "        coverage_cf_local_super,   precision_cf_local_super = compute_cf_coverage(cf_rules_local_super_por_clase_simplify)\n",
    "        coverage_cf_localZ,        precision_cf_localZ    = compute_cf_coverage(cf_rules_localZ_por_clase_simplify)\n",
    "        coverage_cf_superZ,        precision_cf_superZ    = compute_cf_coverage(cf_rules_superZ_por_clase_simplify)\n",
    "\n",
    "\n",
    "\n",
    "        # ============================================================================\n",
    "        # Contrafactuales: coverage / support tambiÃ©n en el VECINDARIO (Z)\n",
    "        # ============================================================================\n",
    "\n",
    "        def compute_cf_coverage_neigh(rules_dict):\n",
    "            coverage_cf_Z  = {}\n",
    "            support_cf_Z   = {}\n",
    "            precision_cf_Z = {}\n",
    "\n",
    "            nZ = len(dfZ_decoded)   # tamaÃ±o del vecindario\n",
    "\n",
    "            for clase, regla_cf in rules_dict.items():\n",
    "                if regla_cf:\n",
    "                    # cover(E) âˆ© Z: instancias del vecindario que cumplen la regla CF\n",
    "                    mask_cf_Z = dfZ_decoded.apply(\n",
    "                        lambda r: cumple_regla(r, regla_cf), axis=1\n",
    "                    ).values\n",
    "\n",
    "                    supZ = int(mask_cf_Z.sum())              # |cover(E) âˆ© Z|\n",
    "                    covZ = supZ / nZ if nZ > 0 else 0.0      # coverage local\n",
    "\n",
    "                    if supZ > 0:\n",
    "                        # fidelidad local: de las que cumplen el CF,\n",
    "                        # cuÃ¡ntas el BBOX las clasifica como la clase del CF\n",
    "                        clase_idx = self.label_encoder.transform([clase])[0]\n",
    "                        precZ = float((y_bb[mask_cf_Z] == clase_idx).mean())\n",
    "                    else:\n",
    "                        precZ = 0.0\n",
    "                else:\n",
    "                    supZ, covZ, precZ = 0, 0.0, 0.0\n",
    "\n",
    "                coverage_cf_Z[clase]  = covZ\n",
    "                precision_cf_Z[clase] = precZ\n",
    "\n",
    "            return coverage_cf_Z, precision_cf_Z\n",
    "        \n",
    "        # --- Merged / LORE / Supertree (LOCAL, vecindario Z) ---\n",
    "        coverage_cf_merged_Z,        precision_cf_merged_Z    = compute_cf_coverage_neigh(cf_rules_por_clase_simplify)\n",
    "        coverage_cf_lore_Z,          precision_cf_lore_Z      = compute_cf_coverage_neigh(cf_rules_LORE_por_clase_simplify)\n",
    "        coverage_cf_supertree_Z,     precision_cf_supertree_Z = compute_cf_coverage_neigh(cf_rules_Supertree_por_clase_simplify)\n",
    "        coverage_cf_local_local_Z,   precision_cf_local_local_Z = compute_cf_coverage_neigh(cf_rules_local_local_por_clase_simplify)\n",
    "        coverage_cf_local_super_Z,   precision_cf_local_super_Z = compute_cf_coverage_neigh(cf_rules_local_super_por_clase_simplify)\n",
    "        coverage_cf_localZ_Z,        precision_cf_localZ_Z = compute_cf_coverage_neigh(cf_rules_localZ_por_clase_simplify)\n",
    "        coverage_cf_superZ_Z,        precision_cf_superZ_Z = compute_cf_coverage_neigh(cf_rules_superZ_por_clase_simplify)\n",
    "\n",
    "\n",
    "        # ================= CSV por cliente =================\n",
    "        row = {\n",
    "            \"round\": int(round_number),\n",
    "            \"dataset\": DATASET_NAME,\n",
    "            \"client_id\": int(self.client_id),\n",
    "            \"bbox_pred_class\": str(pred_class),\n",
    "\n",
    "            # Vecindario\n",
    "            \"silhouette\": float(silhouette),\n",
    "\n",
    "            # ================= MÃ©tricas de como de buenos son los Ã¡rboles =================\n",
    "            \"acc_lore\": float(acc_lore),\n",
    "            \"acc_merged\": float(acc_merged),\n",
    "            \"acc_super\": float(acc_super),\n",
    "            \"acc_local_local\": float(acc_local_local),\n",
    "            \"acc_local_super\": float(acc_local_super),\n",
    "            \"acc_localZ_tree_TEST\": float(acc_localZ_tree_TEST),\n",
    "            \"acc_superZ_tree_TEST\": float(acc_superZ_tree_TEST),\n",
    "\n",
    "            \"prec_lore\": float(prec_lore),\n",
    "            \"prec_merged\": float(prec_merged),\n",
    "            \"prec_super\": float(prec_super),\n",
    "            \"prec_local_local\": float(prec_local_local),\n",
    "            \"prec_local_super\": float(prec_local_super),\n",
    "            \"prec_localZ_tree_TEST\": float(prec_localZ_tree_TEST),\n",
    "            \"prec_superZ_tree_TEST\": float(prec_superZ_tree_TEST),\n",
    "\n",
    "            \"rec_lore\": float(rec_lore),\n",
    "            \"rec_merged\": float(rec_merged),\n",
    "            \"rec_super\": float(rec_super),\n",
    "            \"rec_local_local\": float(rec_local_local),\n",
    "            \"rec_local_super\": float(rec_local_super),\n",
    "            \"rec_localZ_tree_TEST\": float(rec_localZ_tree_TEST),\n",
    "            \"rec_superZ_tree_TEST\": float(rec_superZ_tree_TEST),\n",
    "\n",
    "            \"f1_lore\": float(f1_lore),\n",
    "            \"f1_merged\": float(f1_merged),\n",
    "            \"f1_super\": float(f1_super),\n",
    "            \"f1_local_local\": float(f1_local_local),\n",
    "            \"f1_local_super\": float(f1_local_super),\n",
    "            \"f1_localZ_tree_TEST\": float(f1_localZ_tree_TEST),\n",
    "            \"f1_superZ_tree_TEST\": float(f1_superZ_tree_TEST),\n",
    "\n",
    "            # ======= Calidad Ã¡rboles en la vecindad Z =======\n",
    "            \"acc_lore_Z\": float(acc_lore_Z),\n",
    "            \"acc_merged_Z\": float(acc_merged_Z),\n",
    "            \"acc_super_Z\": float(acc_super_Z),\n",
    "            \"acc_local_local_Z\": float(acc_local_local_Z),\n",
    "            \"acc_local_super_Z\": float(acc_local_super_Z),\n",
    "            \"acc_localZ_Z\": float(acc_local_Z),\n",
    "            \"acc_superZ_Z\": float(acc_superZ_Z),\n",
    "\n",
    "            \"prec_lore_Z\": float(prec_lore_Z),\n",
    "            \"prec_merged_Z\": float(prec_merged_Z),\n",
    "            \"prec_super_Z\": float(prec_super_Z),\n",
    "            \"prec_local_local_Z\": float(prec_local_local_Z),\n",
    "            \"prec_local_super_Z\": float(prec_local_super_Z),\n",
    "            \"prec_localZ_Z\": float(prec_local_Z),\n",
    "            \"prec_superZ_Z\": float(prec_superZ_Z),\n",
    "\n",
    "            \"rec_lore_Z\": float(rec_lore_Z),\n",
    "            \"rec_merged_Z\": float(rec_merged_Z),\n",
    "            \"rec_super_Z\": float(rec_super_Z),\n",
    "            \"rec_local_local_Z\": float(rec_local_local_Z),\n",
    "            \"rec_local_super_Z\": float(rec_local_super_Z),\n",
    "            \"rec_localZ_Z\": float(rec_local_Z),\n",
    "            \"rec_superZ_Z\": float(rec_superZ_Z),\n",
    "\n",
    "            \"f1_lore_Z\": float(f1_lore_Z),\n",
    "            \"f1_merged_Z\": float(f1_merged_Z),\n",
    "            \"f1_super_Z\": float(f1_super_Z),\n",
    "            \"f1_local_local_Z\": float(f1_local_local_Z),\n",
    "            \"f1_local_super_Z\": float(f1_local_super_Z),\n",
    "            \"f1_localZ_Z\": float(f1_local_Z),\n",
    "            \"f1_superZ_Z\": float(f1_superZ_Z),\n",
    "\n",
    "            # ================= MÃ©tricas de explicabilidad del factual ==================\n",
    "            \"coverage_factual_merged\": self._to_float(coverage_merged),\n",
    "            \"fidelity_factual_merged\": self._to_float(fidelity_merged),\n",
    "            \"hit_factual_merged\": int(hit_merged),\n",
    "            \"complexity_factual_merged\": int(comp_factual_merged_simpl),\n",
    "\n",
    "            \"coverage_factual_lore\": self._to_float(coverage_lore),\n",
    "            \"fidelity_factual_lore\": self._to_float(fidelity_lore),\n",
    "            \"hit_factual_lore\": int(hit_lore),\n",
    "            \"complexity_factual_lore\": int(comp_factual_lore_simpl),\n",
    "\n",
    "            \"coverage_factual_super\": self._to_float(coverage_supertree),\n",
    "            \"fidelity_factual_super\": self._to_float(fidelity_super),\n",
    "            \"hit_factual_super\": int(hit_supertree),\n",
    "            \"complexity_factual_super\": int(comp_factual_supertree_simpl),\n",
    "\n",
    "            \"coverage_factual_local_local\": self._to_float(coverage_local_local),\n",
    "            \"fidelity_factual_local_local\": self._to_float(fidelity_local_local),\n",
    "            \"hit_factual_local_local\": int(hit_lore_local_local),\n",
    "            \"complexity_factual_local_local\": int(comp_factual_local_local_simpl),\n",
    "\n",
    "            \"coverage_factual_local_super\": self._to_float(coverage_local_super),\n",
    "            \"fidelity_factual_local_super\": self._to_float(fidelity_local_super),\n",
    "            \"hit_factual_local_super\": int(hit_lore_local_super),\n",
    "            \"complexity_factual_local_super\": int(comp_factual_local_super_simpl),\n",
    "\n",
    "            \"coverage_factual_localZ\": self._to_float(coverage_localZ),\n",
    "            \"fidelity_factual_localZ\": self._to_float(fidelity_localZ),\n",
    "            \"hit_factual_localZ\": int(hit_localZ),\n",
    "            \"complexity_factual_localZ\": int(comp_factual_localZ_simpl),\n",
    "\n",
    "            \"coverage_factual_superZ\": self._to_float(coverage_superZ),\n",
    "            \"fidelity_factual_superZ\": self._to_float(fidelity_superZ),\n",
    "            \"hit_factual_superZ\": int(hit_superZ),\n",
    "            \"complexity_factual_superZ\": int(comp_factual_superZ_simpl),\n",
    "\n",
    "            # ======= Factual LOCAL (vecindad) =======\n",
    "            \"coverage_factual_merged_Z\": self._to_float(coverage_merged_Z),\n",
    "            \"fidelity_factual_merged_Z\": self._to_float(fidelity_merged_Z),\n",
    "\n",
    "            \"coverage_factual_lore_Z\": self._to_float(coverage_lore_Z),\n",
    "            \"fidelity_factual_lore_Z\": self._to_float(fidelity_lore_Z),\n",
    "\n",
    "            \"coverage_factual_super_Z\": self._to_float(coverage_super_Z),\n",
    "            \"fidelity_factual_super_Z\": self._to_float(fidelity_super_Z),\n",
    "\n",
    "            \"coverage_factual_local_local_Z\": self._to_float(coverage_local_local_Z),\n",
    "            \"fidelity_factual_local_local_Z\": self._to_float(fidelity_local_local_Z),\n",
    "\n",
    "            \"coverage_factual_local_super_Z\": self._to_float(coverage_local_super_Z),\n",
    "            \"fidelity_factual_local_super_Z\": self._to_float(fidelity_local_super_Z),\n",
    "\n",
    "            \"coverage_factual_localZ_Z\": self._to_float(coverage_localZ_Z),\n",
    "            \"fidelity_factual_localZ_Z\": self._to_float(fidelity_localZ_Z),\n",
    "\n",
    "            \"coverage_factual_superZ_Z\": self._to_float(coverage_superZ_Z),\n",
    "            \"fidelity_factual_superZ_Z\": self._to_float(fidelity_superZ_Z),\n",
    "\n",
    "            # ================= Estructura =================\n",
    "            \"depth_edges_merged\": int(depth_merged_edges),\n",
    "            \"nodes_merged\": int(nodes_merged),\n",
    "            \"leaves_merged\": int(leaves_merged),\n",
    "\n",
    "            \"depth_edges_lore\": int(depth_lore_edges),\n",
    "            \"nodes_lore\": int(nodes_lore),\n",
    "            \"leaves_lore\": int(leaves_lore),\n",
    "\n",
    "            \"depth_edges_super\": int(depth_supertree_edges),\n",
    "            \"nodes_super\": int(nodes_supertree),\n",
    "            \"leaves_super\": int(leaves_supertree),\n",
    "\n",
    "            \"depth_edges_local_local\": int(depth_lore_edges_local_local),\n",
    "            \"nodes_local_local\": int(nodes_lore_local_local),\n",
    "            \"leaves_local_local\": int(leaves_lore_local_local),\n",
    "\n",
    "            \"depth_edges_local_super\": int(depth_lore_edges_local_super),\n",
    "            \"nodes_local_super\": int(nodes_lore_local_super),\n",
    "            \"leaves_local_super\": int(leaves_lore_local_super),\n",
    "            \"depth_edges_localZ\": int(depth_localZ_edges),\n",
    "            \"nodes_localZ\": int(nodes_localZ),\n",
    "            \"leaves_localZ\": int(leaves_localZ),\n",
    "\n",
    "            \"depth_edges_superZ\": int(depth_superZ_edges),\n",
    "            \"nodes_superZ\": int(nodes_superZ),\n",
    "            \"leaves_superZ\": int(leaves_superZ),\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # (Opcional) MÃ©tricas contrafactuales por clase en columnas â€œanchasâ€\n",
    "        for cl in sorted(coverage_cf_merged.keys()):\n",
    "            row[f\"cf_cov_merged_{cl}_TEST\"]  = self._to_float(coverage_cf_merged.get(cl))\n",
    "            row[f\"cf_comp_merged_{cl}_TEST\"] = int(comp_cf_merged_simpl.get(cl) or 0)\n",
    "            row[f\"cf_prec_merged_{cl}_TEST\"] = self._to_float(precision_cf_merged.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_lore.keys()):\n",
    "            row[f\"cf_cov_lore_{cl}_TEST\"]  = self._to_float(coverage_cf_lore.get(cl))\n",
    "            row[f\"cf_comp_lore_{cl}_TEST\"] = int(comp_cf_lore_simpl.get(cl) or 0)\n",
    "            row[f\"cf_prec_lore_{cl}_TEST\"] = self._to_float(precision_cf_lore.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_supertree.keys()):\n",
    "            row[f\"cf_cov_super_{cl}_TEST\"]  = self._to_float(coverage_cf_supertree.get(cl))\n",
    "            row[f\"cf_comp_super_{cl}_TEST\"] = int(comp_cf_supertree_simpl.get(cl) or 0)\n",
    "            row[f\"cf_prec_super_{cl}_TEST\"] = self._to_float(precision_cf_supertree.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_local_local.keys()):\n",
    "            row[f\"cf_cov_local_local_{cl}_TEST\"]  = self._to_float(coverage_cf_local_local.get(cl))\n",
    "            row[f\"cf_comp_local_local_{cl}_TEST\"] = int(comp_cf_local_local_simpl.get(cl) or 0)\n",
    "            row[f\"cf_prec_local_local_{cl}_TEST\"] = self._to_float(precision_cf_local_local.get(cl))\n",
    "        \n",
    "        for cl in sorted(coverage_cf_local_super.keys()):\n",
    "            row[f\"cf_cov_local_super_{cl}_TEST\"]  = self._to_float(coverage_cf_local_super.get(cl))\n",
    "            row[f\"cf_comp_local_super_{cl}_TEST\"] = int(comp_cf_local_super_simpl.get(cl) or 0)\n",
    "            row[f\"cf_prec_local_super_{cl}_TEST\"] = self._to_float(precision_cf_local_super.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_localZ.keys()):\n",
    "            row[f\"cf_cov_localZ_{cl}_TEST\"]  = self._to_float(coverage_cf_localZ.get(cl))\n",
    "            row[f\"cf_comp_localZ_{cl}_TEST\"] = int(comp_cf_localZ_simpl.get(cl) or 0)\n",
    "            row[f\"cf_prec_localZ_{cl}_TEST\"] = self._to_float(precision_cf_localZ.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_superZ.keys()):\n",
    "            row[f\"cf_cov_superZ_{cl}_TEST\"]  = self._to_float(coverage_cf_superZ.get(cl))\n",
    "            row[f\"cf_comp_superZ_{cl}_TEST\"] = int(comp_cf_superZ_simpl.get(cl) or 0)\n",
    "            row[f\"cf_prec_superZ_{cl}_TEST\"] = self._to_float(precision_cf_superZ.get(cl))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- Contrafactuales en VECINDARIO (Z) ---\n",
    "        for cl in sorted(coverage_cf_merged_Z.keys()):\n",
    "            row[f\"cf_cov_merged_{cl}_Z\"]   = self._to_float(coverage_cf_merged_Z.get(cl))\n",
    "            row[f\"cf_prec_merged_{cl}_Z\"]  = self._to_float(precision_cf_merged_Z.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_lore_Z.keys()):\n",
    "            row[f\"cf_cov_lore_{cl}_Z\"]   = self._to_float(coverage_cf_lore_Z.get(cl))\n",
    "            row[f\"cf_prec_lore_{cl}_Z\"]  = self._to_float(precision_cf_lore_Z.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_supertree_Z.keys()):\n",
    "            row[f\"cf_cov_super_{cl}_Z\"]   = self._to_float(coverage_cf_supertree_Z.get(cl))\n",
    "            row[f\"cf_prec_super_{cl}_Z\"]  = self._to_float(precision_cf_supertree_Z.get(cl))\n",
    "        \n",
    "        for cl in sorted(coverage_cf_local_local_Z.keys()):\n",
    "            row[f\"cf_cov_local_local_{cl}_Z\"]   = self._to_float(coverage_cf_local_local_Z.get(cl))\n",
    "            row[f\"cf_prec_local_local_{cl}_Z\"]  = self._to_float(precision_cf_local_local_Z.get(cl))\n",
    "        \n",
    "        for cl in sorted(coverage_cf_local_super_Z.keys()):\n",
    "            row[f\"cf_cov_local_super_{cl}_Z\"]   = self._to_float(coverage_cf_local_super_Z.get(cl))\n",
    "            row[f\"cf_prec_local_super_{cl}_Z\"]  = self._to_float(precision_cf_local_super_Z.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_localZ_Z.keys()):\n",
    "            row[f\"cf_cov_localZ_{cl}_Z\"]   = self._to_float(coverage_cf_localZ_Z.get(cl))\n",
    "            row[f\"cf_prec_localZ_{cl}_Z\"]  = self._to_float(precision_cf_localZ_Z.get(cl))\n",
    "\n",
    "        for cl in sorted(coverage_cf_superZ_Z.keys()):\n",
    "            row[f\"cf_cov_superZ_{cl}_Z\"]   = self._to_float(coverage_cf_superZ_Z.get(cl))\n",
    "            row[f\"cf_prec_superZ_{cl}_Z\"]  = self._to_float(precision_cf_superZ_Z.get(cl))\n",
    "\n",
    "        # Guardar\n",
    "        self._append_client_csv(row, filename=\"Balanced\")\n",
    "\n",
    "        return row\n",
    "\n",
    "    # ======================================================================\n",
    "    # Bucle sobre todo el test\n",
    "    # ======================================================================\n",
    "    def explain_all_test_instances(self, config, only_idx=None):\n",
    "        results = []\n",
    "\n",
    "        # Si only_idx es None â†’ explicamos TODO el test\n",
    "        # Si only_idx es un entero â†’ explicamos solo esa instancia\n",
    "        if only_idx is None:\n",
    "            indices = range(len(self.X_test))\n",
    "            desc_text = f\"Cliente {self.client_id} explicando test completo\"\n",
    "            save_trees_flag = False      \n",
    "\n",
    "        else:\n",
    "            indices = [only_idx]\n",
    "            desc_text = f\"Cliente {self.client_id} explicando instancia {only_idx}\"\n",
    "            save_trees_flag = True\n",
    "\n",
    "\n",
    "        for i in tqdm(indices, desc=desc_text):\n",
    "            try:\n",
    "\n",
    "                row = self._explain_one_instance(i, config, save_trees=save_trees_flag)\n",
    "                results.append(row)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[Cliente {self.client_id}] âš ï¸ Error en instancia {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        mean_metrics = df.mean(numeric_only=True)\n",
    "        mean_metrics.to_csv(f\"results/metrics_cliente_{self.client_id}_balanced_mean.csv\")\n",
    "\n",
    "        return df\n",
    "\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    dataset_name = DATASET_NAME \n",
    "    class_col = CLASS_COLUMN \n",
    "\n",
    "\n",
    "    (X_train, y_train,X_test, y_test,dataset, feature_names,label_encoder, scaler,numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=NUM_CLIENTS)\n",
    "\n",
    "    tree_model = DecisionTreeClassifier(max_depth=3, min_samples_split=2, random_state=42)\n",
    "\n",
    "    num_idx = list(range(len(numeric_features)))\n",
    "\n",
    "    scaler_nn = StandardScaler().fit(X_train[:, num_idx])\n",
    "\n",
    "    def scale_for_nn(X):\n",
    "        Xs = X.copy().astype(np.float32)\n",
    "        Xs[:, num_idx] = scaler_nn.transform(Xs[:, num_idx])\n",
    "        return Xs\n",
    "    \n",
    "    X_train_nn = scale_for_nn(X_train)\n",
    "    X_test_nn  = scale_for_nn(X_test)\n",
    "\n",
    "    # âœ… SIEMPRE MISMO NÃšMERO DE CLASES GLOBAL\n",
    "    n_clases_global = len(UNIQUE_LABELS)  # o len(label_encoder.classes_)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = n_clases_global\n",
    "\n",
    "    nn_model = Net(input_dim, output_dim)\n",
    "    return FlowerClient(tree_model=tree_model, \n",
    "                        nn_model=nn_model,\n",
    "                        X_train=X_train,\n",
    "                        y_train=y_train,\n",
    "                        X_test=X_test,\n",
    "                        y_test=y_test,\n",
    "                        X_train_nn=X_train_nn, \n",
    "                        X_test_nn=X_test_nn,\n",
    "                        dataset=dataset,\n",
    "                        client_id=partition_id + 1,\n",
    "                        feature_names=feature_names,\n",
    "                        label_encoder=label_encoder,\n",
    "                        scaler=scaler,\n",
    "                        numeric_features=numeric_features,\n",
    "                        encoder=encoder,\n",
    "                        preprocessor=preprocessor,         \n",
    "                        scaler_nn_mean=scaler_nn.mean_,  \n",
    "                        scaler_nn_scale=scaler_nn.scale_,\n",
    "                        num_idx=num_idx).to_client()\n",
    "\n",
    "client_app = ClientApp(client_fn=client_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c927a9",
   "metadata": {},
   "source": [
    "# Servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6042e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ðŸ“¦ IMPORTACIONES NECESARIAS\n",
    "# ============================\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from flwr.common import Context, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "from graphviz import Digraph\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# ============================\n",
    "# âš™ï¸ CONFIGURACIÃ“N GLOBAL\n",
    "# ============================\n",
    "# MIN_AVAILABLE_CLIENTS = 4\n",
    "# NUM_SERVER_ROUNDS = 2\n",
    "\n",
    "FEATURES = []  # se rellenan dinÃ¡micamente\n",
    "UNIQUE_LABELS = []\n",
    "LATEST_SUPERTREE_JSON = None\n",
    "GLOBAL_MAPPING_JSON = None\n",
    "FEATURE_NAMES_JSON = None\n",
    "GLOBAL_SCALER_JSON = None\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ðŸ§  UTILIDADES MODELO\n",
    "# ============================\n",
    "def create_model(input_dim, output_dim):\n",
    "    from __main__ import Net  # necesario si Net estÃ¡ en misma libreta\n",
    "    return Net(input_dim, output_dim)\n",
    "\n",
    "\n",
    "def get_model_parameters(tree_model, nn_model):\n",
    "    tree_params = [-1, 2, 1]\n",
    "    nn_weights = [v.cpu().detach().numpy() for v in nn_model.state_dict().values()]\n",
    "    return {\n",
    "        \"tree\": tree_params,\n",
    "        \"nn\": nn_weights,\n",
    "    }\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Dict[str, Scalar]:\n",
    "    sums: Dict[str, float] = {}\n",
    "    counts: Dict[str, int] = {}\n",
    "\n",
    "    for n, met in metrics:\n",
    "        for k, v in met.items():\n",
    "            if isinstance(v, (float, int)):\n",
    "                sums[k] = sums.get(k, 0.0) + n * float(v)\n",
    "                counts[k] = counts.get(k, 0) + n\n",
    "\n",
    "    return {k: sums[k] / counts[k] for k in sums}\n",
    "\n",
    "# ============================\n",
    "# ðŸš€ SERVIDOR FLOWER\n",
    "# ============================\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    global FEATURES, UNIQUE_LABELS\n",
    "\n",
    "    # Justo antes de llamar a create_model\n",
    "    if not FEATURES or not UNIQUE_LABELS:\n",
    "        \n",
    "        load_data_general(DATASET_NAME, CLASS_COLUMN, partition_id=0, num_partitions=NUM_CLIENTS)\n",
    "\n",
    "\n",
    "    FEATURES = FEATURES or [\"feat_0\", \"feat_1\"]  # fallback por si no se cargÃ³ antes\n",
    "    UNIQUE_LABELS = UNIQUE_LABELS or [\"Class_0\", \"Class_1\"]\n",
    "\n",
    "\n",
    "    model = create_model(len(FEATURES), len(UNIQUE_LABELS))\n",
    "    initial_params = ndarrays_to_parameters(get_model_parameters(None, model)[\"nn\"])\n",
    "\n",
    "    strategy = FedAvg(\n",
    "        min_available_clients=MIN_AVAILABLE_CLIENTS,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        initial_parameters=initial_params,\n",
    "    )\n",
    "\n",
    "    strategy.configure_fit = _inject_round(strategy.configure_fit)\n",
    "    strategy.configure_evaluate = _inject_round(strategy.configure_evaluate)\n",
    "    original_aggregate = strategy.aggregate_evaluate\n",
    "\n",
    "    def custom_aggregate_evaluate(server_round, results, failures):\n",
    "        global LATEST_SUPERTREE_JSON, GLOBAL_MAPPING_JSON, FEATURE_NAMES_JSON\n",
    "        aggregated_metrics = original_aggregate(server_round, results, failures)\n",
    "\n",
    "        # ============================\n",
    "        # ðŸ”¹ Ronda final: NO fusionar nada\n",
    "        # ============================\n",
    "        if server_round > NUM_TRAIN_ROUNDS:\n",
    "            return aggregated_metrics\n",
    "\n",
    "        try:\n",
    "            print(f\"\\n[SERVIDOR] ðŸŒ² Generando SuperTree - Ronda {server_round}\")\n",
    "            from collections import defaultdict\n",
    "\n",
    "            tree_nodes = []\n",
    "            all_distincts = defaultdict(set)\n",
    "            client_encoders = {}\n",
    "\n",
    "            feature_names = None\n",
    "            numeric_features = None\n",
    "            class_names = None\n",
    "\n",
    "            # 1) recolectar mapeos categÃ³ricos y metadatos\n",
    "            for (_, evaluate_res) in results:\n",
    "                metrics = evaluate_res.metrics\n",
    "                # distinct_values_* para global_mapping\n",
    "                for k, v in metrics.items():\n",
    "                    if k.startswith(\"distinct_values_\"):\n",
    "                        cid = k.split(\"_\")[-1]\n",
    "                        enc = json.loads(v)\n",
    "                        client_encoders[cid] = enc\n",
    "                        for feat, d in enc.items():\n",
    "                            all_distincts[feat].update(d[\"distinct_values\"])\n",
    "\n",
    "            global_mapping = {feat: sorted(list(vals)) for feat, vals in all_distincts.items()}\n",
    "\n",
    "            # 2) recolectar Ã¡rboles y demÃ¡s metadatos por cliente\n",
    "            for (_, evaluate_res) in results:\n",
    "                metrics = evaluate_res.metrics\n",
    "                for k, v in metrics.items():\n",
    "                    if k.startswith(\"tree_ensemble_\"):\n",
    "                        cid = k.split(\"_\")[-1]\n",
    "                        trees_list = json.loads(v)\n",
    "\n",
    "                        # lee estos una sola vez (son iguales por cliente)\n",
    "                        if feature_names is None and f\"encoded_feature_names_{cid}\" in metrics:\n",
    "                            feature_names = json.loads(metrics[f\"encoded_feature_names_{cid}\"])\n",
    "                        if numeric_features is None and f\"numeric_features_{cid}\" in metrics:\n",
    "                            numeric_features = json.loads(metrics[f\"numeric_features_{cid}\"])\n",
    "                        if class_names is None and f\"unique_labels_{cid}\" in metrics:\n",
    "                            class_names = json.loads(metrics[f\"unique_labels_{cid}\"])\n",
    "\n",
    "                        for tdict in trees_list:\n",
    "                            root = SuperTree.Node.from_dict(tdict)\n",
    "                            tree_nodes.append(root)\n",
    "\n",
    "            if not tree_nodes:\n",
    "                return aggregated_metrics\n",
    "\n",
    "            # 3) fusionar\n",
    "            st = SuperTree()\n",
    "            st.mergeDecisionTrees(\n",
    "                roots=tree_nodes,\n",
    "                num_classes=len(class_names),\n",
    "                feature_names=feature_names,\n",
    "                categorical_features=list(global_mapping.keys()),\n",
    "                global_mapping=global_mapping,\n",
    "            )\n",
    "\n",
    "            # print(\"\\n[SERVIDOR] SuperTree unpruned:\")\n",
    "            # print(st)\n",
    "            # print(\"\\n\")\n",
    "\n",
    "            # print(\"\\n[SERVIDOR] SuperTree prune_redundant_leaves_full:\")\n",
    "            st.prune_redundant_leaves_full()\n",
    "            # print(st)\n",
    "            # print(\"\\n\")\n",
    "\n",
    "\n",
    "            # print(\"\\n[SERVIDOR] SuperTree merge_equal_class_leaves:\")\n",
    "            # st.merge_equal_class_leaves()\n",
    "\n",
    "            # print(supertree)\n",
    "            # print(\"\\n\")\n",
    "            \n",
    "            # print(\"\\n\")\n",
    "\n",
    "            # 4) guardar/emitir\n",
    "            save_supertree_plot(\n",
    "                root_node=st.root,\n",
    "                round_number=server_round,\n",
    "                feature_names=feature_names,\n",
    "                class_names=class_names,\n",
    "                numeric_features=numeric_features,\n",
    "                global_mapping=global_mapping,   # sin scaler\n",
    "            )\n",
    "\n",
    "            LATEST_SUPERTREE_JSON = json.dumps(st.root.to_dict())\n",
    "            GLOBAL_MAPPING_JSON = json.dumps(global_mapping)\n",
    "            FEATURE_NAMES_JSON = json.dumps(feature_names)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SERVIDOR] âŒ Error en SuperTree: {e}\")\n",
    "\n",
    "        return aggregated_metrics\n",
    "\n",
    "\n",
    "    strategy.aggregate_evaluate = custom_aggregate_evaluate\n",
    "    return ServerAppComponents(strategy=strategy, config=ServerConfig(num_rounds=NUM_SERVER_ROUNDS))\n",
    "\n",
    "# ============================\n",
    "# ðŸ§© FUNCIONES AUXILIARES\n",
    "# ============================\n",
    "def _inject_round(original_fn):\n",
    "    def wrapper(server_round, parameters, client_manager):\n",
    "        global LATEST_SUPERTREE_JSON, GLOBAL_MAPPING_JSON, FEATURE_NAMES_JSON\n",
    "        instructions = original_fn(server_round, parameters, client_manager)\n",
    "        for _, ins in instructions:\n",
    "            ins.config[\"server_round\"] = server_round\n",
    "\n",
    "            # Siempre mandamos el Ãºltimo SuperTree disponible\n",
    "            if LATEST_SUPERTREE_JSON:\n",
    "                ins.config[\"supertree\"] = LATEST_SUPERTREE_JSON\n",
    "                ins.config[\"global_mapping\"] = GLOBAL_MAPPING_JSON\n",
    "                ins.config[\"feature_names\"] = FEATURE_NAMES_JSON\n",
    "\n",
    "            # Ronda final: modo solo explicaciÃ³n\n",
    "            if server_round == NUM_SERVER_ROUNDS:\n",
    "                ins.config[\"explain_only\"] = True\n",
    "        return instructions\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "\n",
    "def print_supertree_legible_fusionado(\n",
    "    node,\n",
    "    feature_names,\n",
    "    class_names,\n",
    "    numeric_features,\n",
    "    scaler,  # dict con mean y std\n",
    "    global_mapping,\n",
    "    depth=0\n",
    "):\n",
    "    import numpy as np\n",
    "    indent = \"|   \" * depth\n",
    "    if node is None:\n",
    "        print(f\"{indent}[Nodo None]\")\n",
    "        return\n",
    "\n",
    "    if getattr(node, \"is_leaf\", False):\n",
    "        class_idx = int(np.argmax(node.labels))\n",
    "        print(f\"{indent}class: {class_names[class_idx]} (pred: {node.labels})\")\n",
    "        return\n",
    "\n",
    "    feat_idx = node.feat\n",
    "    feat_name = feature_names[feat_idx]\n",
    "    intervals = node.intervals\n",
    "    children = node.children\n",
    "\n",
    "    # ====== NUMÃ‰RICA ======\n",
    "    if feat_name in numeric_features:\n",
    "        bounds = [-np.inf] + list(intervals)\n",
    "        while len(bounds) < len(children) + 1:\n",
    "            bounds.append(np.inf)\n",
    "\n",
    "        for i, child in enumerate(children):\n",
    "            left = bounds[i]\n",
    "            right = bounds[i + 1]\n",
    "            left_real  = left\n",
    "            right_real = right\n",
    "\n",
    "            if i == 0:\n",
    "                cond = f\"{feat_name} â‰¤ {right_real:.2f}\"\n",
    "            elif i == len(children) - 1:\n",
    "                cond = f\"{feat_name} > {left_real:.2f}\"\n",
    "            else:\n",
    "                cond = f\"{feat_name} âˆˆ ({left_real:.2f}, {right_real:.2f}]\"\n",
    "            print(f\"{indent}{cond}\")\n",
    "            print_supertree_legible_fusionado(\n",
    "                child, feature_names, class_names, numeric_features,\n",
    "                scaler=None,  # ya no se usa\n",
    "                global_mapping=global_mapping, depth=depth + 1\n",
    "            )\n",
    "\n",
    "    # ====== CATEGÃ“RICA ONEHOT ======\n",
    "    elif \"=\" in feat_name or \"_\" in feat_name:\n",
    "        # Soporta 'var=valor' o 'var_valor'\n",
    "        if \"=\" in feat_name:\n",
    "            var, val = feat_name.split(\"=\", 1)\n",
    "        else:\n",
    "            var, val = feat_name.split(\"_\", 1)\n",
    "        var = var.strip()\n",
    "        val = val.strip()\n",
    "\n",
    "        if len(children) != 2:\n",
    "            print(f\"[ERROR] Nodo OneHot {feat_name} tiene {len(children)} hijos, esperado 2.\")\n",
    "\n",
    "        # Primero !=, luego ==\n",
    "        conds = [\n",
    "            f'{var} != \"{val}\"',\n",
    "            f'{var} == \"{val}\"'\n",
    "        ]\n",
    "        for i, child in enumerate(children):\n",
    "            print(f\"{indent}{conds[i]}\")\n",
    "            print_supertree_legible_fusionado(\n",
    "                child, feature_names, class_names, numeric_features, scaler, global_mapping, depth + 1\n",
    "            )\n",
    "\n",
    "    # ====== CATEGÃ“RICA ORDINAL ======\n",
    "    elif global_mapping and feat_name in global_mapping:\n",
    "        vals_cat = global_mapping[feat_name]\n",
    "        # Primero !=, luego ==\n",
    "        for i, child in enumerate(children):\n",
    "            try:\n",
    "                val_idx = node.intervals[i] if hasattr(node, \"intervals\") and i < len(node.intervals) else int(getattr(node, \"thresh\", 0))\n",
    "                val = vals_cat[val_idx] if val_idx < len(vals_cat) else f\"desconocido({val_idx})\"\n",
    "            except Exception as e:\n",
    "                print(f\"[DEPURACIÃ“N] Error interpretando categÃ³rica: {e}\")\n",
    "                val = \"?\"\n",
    "            cond = f'{feat_name} != \"{val}\"' if i == 0 else f'{feat_name} == \"{val}\"'\n",
    "            print(f\"{indent}{cond}\")\n",
    "            print_supertree_legible_fusionado(\n",
    "                child, feature_names, class_names, numeric_features, scaler, global_mapping, depth + 1\n",
    "            )\n",
    "\n",
    "    # ====== TIPO DESCONOCIDO ======\n",
    "    else:\n",
    "        print(f\"{indent}{feat_name} [tipo desconocido]\")\n",
    "        print(f\"    [DEPURACIÃ“N] Nombres de features: {feature_names}\")\n",
    "        print(f\"    [DEPURACIÃ“N] Nombres numÃ©ricas: {numeric_features}\")\n",
    "        print(f\"    [DEPURACIÃ“N] global_mapping: {list(global_mapping.keys()) if global_mapping else None}\")\n",
    "        print(f\"    [DEPURACIÃ“N] children: {len(children)}\")\n",
    "        for child in children:\n",
    "            print_supertree_legible_fusionado(\n",
    "                child, feature_names, class_names, numeric_features, scaler, global_mapping, depth + 1\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "def save_supertree_plot(\n",
    "    root_node,\n",
    "    round_number,\n",
    "    feature_names,\n",
    "    class_names,\n",
    "    numeric_features,\n",
    "    global_mapping,\n",
    "    folder=\"Supertree\",\n",
    "):\n",
    "    from graphviz import Digraph\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def add_node(node, parent=None, edge_label=\"\"):\n",
    "        curr = str(node_id[0]); node_id[0] += 1\n",
    "\n",
    "        # etiqueta\n",
    "        if node.is_leaf:\n",
    "            class_index = int(np.argmax(node.labels))\n",
    "            label = f\"class: {class_names[class_index]}\\n{node.labels}\"\n",
    "        else:\n",
    "            fname = feature_names[node.feat]\n",
    "            label = fname.split(\"_\", 1)[0] if \"_\" in fname else fname\n",
    "\n",
    "        dot.node(curr, label)\n",
    "        if parent: dot.edge(parent, curr, label=edge_label)\n",
    "\n",
    "        if not node.is_leaf:\n",
    "            fname = feature_names[node.feat]\n",
    "            # OneHot\n",
    "            if \"_\" in fname:\n",
    "                _, val = fname.split(\"_\", 1)\n",
    "                add_node(node.children[0], curr, f'â‰  \"{val.strip()}\"')\n",
    "                add_node(node.children[1], curr, f'= \"{val.strip()}\"')\n",
    "            # NumÃ©rica\n",
    "            elif fname in numeric_features:\n",
    "                thr = node.intervals[0] if node.intervals else node.thresh\n",
    "                add_node(node.children[0], curr, f\"â‰¤ {thr:.2f}\")\n",
    "                add_node(node.children[1], curr, f\"> {thr:.2f}\")\n",
    "            # CategÃ³rica ordinal\n",
    "            elif fname in global_mapping:\n",
    "                vals = global_mapping[fname]\n",
    "                val = vals[node.intervals[0]] if node.intervals else \"?\"\n",
    "                add_node(node.children[0], curr, f'= \"{val}\"')\n",
    "                add_node(node.children[1], curr, f'â‰  \"{val}\"')\n",
    "            else:\n",
    "                for ch in node.children:\n",
    "                    add_node(ch, curr, \"?\")\n",
    "\n",
    "    folder_path = f\"Ronda_{round_number}/{folder}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    filename = f\"{folder_path}/supertree_ronda_{round_number}\"\n",
    "    add_node(root_node)\n",
    "    dot.render(filename, format=\"pdf\", cleanup=True)\n",
    "    return f\"{filename}.pdf\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ðŸ”§ INICIALIZAR SERVER APP\n",
    "# ============================\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d278d1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 13:03:18,360\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-12-03 13:03:21,791 flwr         DEBUG    Asyncio event loop already running.\n",
      ":job_id:01000000\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":job_id:01000000\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 4] âœ… Red neuronal entrenada\n",
      "[CLIENTE 1] âœ… Red neuronal entrenada\n",
      "[CLIENTE 2] âœ… Red neuronal entrenada\n",
      "[CLIENTE 5] âœ… Red neuronal entrenada\n",
      "[CLIENTE 3] âœ… Red neuronal entrenada\n",
      "[CLIENTE 6] âœ… Red neuronal entrenada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SERVIDOR] ðŸŒ² Generando SuperTree - Ronda 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 1] âœ… Red neuronal entrenada\n",
      "[CLIENTE 3] âœ… Red neuronal entrenada\n",
      "[CLIENTE 2] âœ… Red neuronal entrenada\n",
      "[CLIENTE 6] âœ… Red neuronal entrenada\n",
      "[CLIENTE 4] âœ… Red neuronal entrenada\n",
      "[CLIENTE 5] âœ… Red neuronal entrenada\n",
      "Recibiendo supertree....\n",
      "Recibiendo supertree....\n",
      "Recibiendo supertree....\n",
      "Recibiendo supertree....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recibiendo supertree....\n",
      "Recibiendo supertree....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SERVIDOR] ðŸŒ² Generando SuperTree - Ronda 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recibiendo supertree....Recibiendo supertree....\n",
      "[CLIENTE 2] ðŸ” Ronda final: solo explicaciones\n",
      "\n",
      "[CLIENTE 1] ðŸ” Ronda final: solo explicaciones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cliente 1 explicando test completo:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recibiendo supertree....\n",
      "[CLIENTE 4] ðŸ” Ronda final: solo explicaciones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recibiendo supertree....\n",
      "[CLIENTE 3] ðŸ” Ronda final: solo explicaciones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recibiendo supertree....\n",
      "[CLIENTE 5] ðŸ” Ronda final: solo explicaciones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recibiendo supertree....\n",
      "[CLIENTE 6] ðŸ” Ronda final: solo explicaciones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:   4%|â–         | 1/24 [00:16<06:08, 16.01s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:   8%|â–Š         | 2/24 [00:31<05:39, 15.43s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Cliente 1 explicando test completo:  12%|â–ˆâ–Ž        | 3/24 [00:47<05:35, 15.96s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  17%|â–ˆâ–‹        | 4/24 [01:05<05:30, 16.53s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  21%|â–ˆâ–ˆ        | 5/24 [01:21<05:16, 16.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  25%|â–ˆâ–ˆâ–Œ       | 6/24 [01:37<04:56, 16.45s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  29%|â–ˆâ–ˆâ–‰       | 7/24 [01:53<04:36, 16.26s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 8/24 [02:10<04:20, 16.29s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [02:26<04:06, 16.44s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [02:42<03:44, 16.06s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [02:57<03:26, 15.88s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [03:14<03:12, 16.03s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [03:30<02:58, 16.23s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Cliente 1 explicando test completo:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [03:47<02:44, 16.50s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Cliente 1 explicando test completo:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15/24 [04:04<02:29, 16.56s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Cliente 6 explicando test completo: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [04:18<00:00, 16.13s/it]\n",
      "\n",
      "\n",
      "Cliente 3 explicando test completo: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [04:19<00:00, 15.29s/it]\n",
      "Cliente 1 explicando test completo:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [04:21<02:14, 16.77s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 1 explicando test completo:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [04:32<01:43, 14.81s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 1 explicando test completo:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [04:44<01:24, 14.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 1 explicando test completo:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [04:58<01:10, 14.19s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 1 explicando test completo:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 20/24 [05:15<00:59, 14.86s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 1 explicando test completo:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [05:30<00:45, 15.10s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 1 explicando test completo:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [05:45<00:30, 15.01s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 1 explicando test completo:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [06:02<00:15, 15.58s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 1 explicando test completo: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [06:17<00:00, 15.71s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Cliente 4 explicando test completo: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [07:11<00:00, 15.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Cliente 2 explicando test completo: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [07:30<00:00, 13.64s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Cliente 5 explicando test completo: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [08:44<00:00,  9.19s/it]\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 541.13s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.0\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n"
     ]
    }
   ],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "import logging\n",
    "import warnings\n",
    "import ray\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger(\"filelock\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"ray\").setLevel(logging.WARNING)\n",
    "logging.getLogger('graphviz').setLevel(logging.WARNING)\n",
    "logging.getLogger().setLevel(logging.WARNING)  # O ERROR para ocultar aÃºn mÃ¡s\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"fsspec\").setLevel(logging.WARNING)\n",
    "# logging.getLogger(\"flwr\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()  # Apagar cualquier sesiÃ³n previa de Ray\n",
    "ray.init(local_mode=True)  # Desactiva multiprocessing, usa un solo proceso principal\n",
    "\n",
    "backend_config = {\"num_cpus\": 1}\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ab03c",
   "metadata": {},
   "source": [
    "### BALANCED METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a663325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voy a usar estos ficheros:\n",
      "  - metrics_cliente_1_balanced_mean.csv\n",
      "  - metrics_cliente_2_balanced_mean.csv\n",
      "  - metrics_cliente_3_balanced_mean.csv\n",
      "  - metrics_cliente_4_balanced_mean.csv\n",
      "  - metrics_cliente_5_balanced_mean.csv\n",
      "  - metrics_cliente_6_balanced_mean.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_localZ_Z</td>\n",
       "      <td>0.532395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_localZ_tree_TEST</td>\n",
       "      <td>0.740183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acc_local_local</td>\n",
       "      <td>0.662468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acc_local_local_Z</td>\n",
       "      <td>0.629874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acc_local_super</td>\n",
       "      <td>0.736078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acc_local_super_Z</td>\n",
       "      <td>0.631055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acc_lore</td>\n",
       "      <td>0.519941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acc_lore_Z</td>\n",
       "      <td>0.984313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acc_merged</td>\n",
       "      <td>0.700466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acc_merged_Z</td>\n",
       "      <td>0.628698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acc_super</td>\n",
       "      <td>0.833965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acc_superZ_Z</td>\n",
       "      <td>0.530157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acc_superZ_tree_TEST</td>\n",
       "      <td>0.734027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>acc_super_Z</td>\n",
       "      <td>0.530293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>client_id</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>complexity_factual_localZ</td>\n",
       "      <td>0.510016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>complexity_factual_local_local</td>\n",
       "      <td>0.819722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>complexity_factual_local_super</td>\n",
       "      <td>1.325838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>complexity_factual_lore</td>\n",
       "      <td>1.395667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>complexity_factual_merged</td>\n",
       "      <td>1.875772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>complexity_factual_super</td>\n",
       "      <td>1.203033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>complexity_factual_superZ</td>\n",
       "      <td>0.568716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>coverage_factual_localZ</td>\n",
       "      <td>0.298846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>coverage_factual_localZ_Z</td>\n",
       "      <td>0.394367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>coverage_factual_local_local</td>\n",
       "      <td>0.243066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>coverage_factual_local_local_Z</td>\n",
       "      <td>0.245519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>coverage_factual_local_super</td>\n",
       "      <td>0.317095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>coverage_factual_local_super_Z</td>\n",
       "      <td>0.375458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>coverage_factual_lore</td>\n",
       "      <td>0.450806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>coverage_factual_lore_Z</td>\n",
       "      <td>0.442278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            metric      mean\n",
       "0                     acc_localZ_Z  0.532395\n",
       "1             acc_localZ_tree_TEST  0.740183\n",
       "2                  acc_local_local  0.662468\n",
       "3                acc_local_local_Z  0.629874\n",
       "4                  acc_local_super  0.736078\n",
       "5                acc_local_super_Z  0.631055\n",
       "6                         acc_lore  0.519941\n",
       "7                       acc_lore_Z  0.984313\n",
       "8                       acc_merged  0.700466\n",
       "9                     acc_merged_Z  0.628698\n",
       "10                       acc_super  0.833965\n",
       "11                    acc_superZ_Z  0.530157\n",
       "12            acc_superZ_tree_TEST  0.734027\n",
       "13                     acc_super_Z  0.530293\n",
       "14                       client_id  3.500000\n",
       "15       complexity_factual_localZ  0.510016\n",
       "16  complexity_factual_local_local  0.819722\n",
       "17  complexity_factual_local_super  1.325838\n",
       "18         complexity_factual_lore  1.395667\n",
       "19       complexity_factual_merged  1.875772\n",
       "20        complexity_factual_super  1.203033\n",
       "21       complexity_factual_superZ  0.568716\n",
       "22         coverage_factual_localZ  0.298846\n",
       "23       coverage_factual_localZ_Z  0.394367\n",
       "24    coverage_factual_local_local  0.243066\n",
       "25  coverage_factual_local_local_Z  0.245519\n",
       "26    coverage_factual_local_super  0.317095\n",
       "27  coverage_factual_local_super_Z  0.375458\n",
       "28           coverage_factual_lore  0.450806\n",
       "29         coverage_factual_lore_Z  0.442278"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Promedios globales guardados en: results\\metrics_Balanced_global.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ðŸ“Š Promedio global a partir de los *balanced_mean*\n",
    "# ==========================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "csv_dir = Path(\"results\")\n",
    "\n",
    "files = sorted(csv_dir.glob(\"metrics_cliente_*_balanced_mean.csv\"))\n",
    "print(\"Voy a usar estos ficheros:\")\n",
    "for f in files:\n",
    "    print(\"  -\", f.name)\n",
    "\n",
    "# Leer cada fichero y dejar columnas [metric, value_clienteX]\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)          # aquÃ­ sÃ­ usamos la cabecera \",0\"\n",
    "    # df.columns suele ser algo como [\"Unnamed: 0\", \"0\"]\n",
    "    df = df.rename(columns={df.columns[0]: \"metric\", df.columns[1]: f\"value_{f.stem}\"})\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "# Unir por nombre de mÃ©trica (outer join para no perder nada)\n",
    "merged = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged = merged.merge(df, on=\"metric\", how=\"outer\")\n",
    "\n",
    "# Calcular la media entre clientes (macro-media)\n",
    "value_cols = [c for c in merged.columns if c.startswith(\"value_\")]\n",
    "merged[\"mean\"] = merged[value_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "means_df = merged[[\"metric\", \"mean\"]].copy()\n",
    "\n",
    "# ==========================================\n",
    "# ðŸ“‰ Colapsar clases B/M en mÃ©tricas CF (TEST y Z)\n",
    "# ==========================================\n",
    "\n",
    "collapse_patterns = {\n",
    "    # --------- TEST ----------\n",
    "    \"cf_cov_merged_TEST\":   r\"^cf_cov_merged_[^_]+_TEST$\",\n",
    "    \"cf_comp_merged_TEST\":  r\"^cf_comp_merged_[^_]+_TEST$\",\n",
    "    \"cf_prec_merged_TEST\": r\"^cf_prec_merged_[^_]+_TEST$\",\n",
    "\n",
    "    \"cf_cov_lore_TEST\":     r\"^cf_cov_lore_[^_]+_TEST$\",\n",
    "    \"cf_comp_lore_TEST\":    r\"^cf_comp_lore_[^_]+_TEST$\",\n",
    "    \"cf_prec_lore_TEST\":   r\"^cf_prec_lore_[^_]+_TEST$\",\n",
    "\n",
    "    \"cf_cov_super_TEST\":    r\"^cf_cov_super_[^_]+_TEST$\",\n",
    "    \"cf_comp_super_TEST\":   r\"^cf_comp_super_[^_]+_TEST$\",\n",
    "    \"cf_prec_super_TEST\":  r\"^cf_prec_super_[^_]+_TEST$\",\n",
    "\n",
    "    \"cf_cov_local_local_TEST\":   r\"^cf_cov_local_local_[^_]+_TEST$\",\n",
    "    \"cf_comp_local_local_TEST\":  r\"^cf_comp_local_local_[^_]+_TEST$\",\n",
    "    \"cf_prec_local_local_TEST\":  r\"^cf_prec_local_local_[^_]+_TEST$\",\n",
    "\n",
    "    \"cf_cov_local_super_TEST\":   r\"^cf_cov_local_super_[^_]+_TEST$\",\n",
    "    \"cf_comp_local_super_TEST\":  r\"^cf_comp_local_super_[^_]+_TEST$\",\n",
    "    \"cf_prec_local_super_TEST\":  r\"^cf_prec_local_super_[^_]+_TEST$\",\n",
    "\n",
    "    \"cf_cov_localZ_TEST\":   r\"^cf_cov_localZ_[^_]+_TEST$\",\n",
    "    \"cf_comp_localZ_TEST\":  r\"^cf_comp_localZ_[^_]+_TEST$\",\n",
    "    \"cf_prec_localZ_TEST\":  r\"^cf_prec_localZ_[^_]+_TEST$\",\n",
    "\n",
    "    \"cf_cov_superZ_TEST\":   r\"^cf_cov_superZ_[^_]+_TEST$\",\n",
    "    \"cf_comp_superZ_TEST\":  r\"^cf_comp_superZ_[^_]+_TEST$\",\n",
    "    \"cf_prec_superZ_TEST\":  r\"^cf_prec_superZ_[^_]+_TEST$\",\n",
    "\n",
    "    # --------- Z ----------\n",
    "    \"cf_cov_merged_Z\":   r\"^cf_cov_merged_[^_]+_Z$\",\n",
    "    \"cf_prec_merged_Z\":  r\"^cf_prec_merged_[^_]+_Z$\",\n",
    "\n",
    "    \"cf_cov_lore_Z\":     r\"^cf_cov_lore_[^_]+_Z$\",\n",
    "    \"cf_prec_lore_Z\":    r\"^cf_prec_lore_[^_]+_Z$\",\n",
    "\n",
    "    \"cf_cov_super_Z\":    r\"^cf_cov_super_[^_]+_Z$\",\n",
    "    \"cf_prec_super_Z\":   r\"^cf_prec_super_[^_]+_Z$\",  # ojo: revisa este patrÃ³n si hiciera falta\n",
    "\n",
    "    \"cf_cov_local_local_Z\":   r\"^cf_cov_local_local_[^_]+_Z$\",\n",
    "    \"cf_prec_local_local_Z\":  r\"^cf_prec_local_local_[^_]+_Z$\",\n",
    "\n",
    "    \"cf_cov_local_super_Z\":   r\"^cf_cov_local_super_[^_]+_Z$\",\n",
    "    \"cf_prec_local_super_Z\":  r\"^cf_prec_local_super_[^_]+_Z$\",\n",
    "    \n",
    "    \"cf_cov_localZ_Z\":   r\"^cf_cov_localZ_[^_]+_Z$\",\n",
    "    \"cf_prec_localZ_Z\":  r\"^cf_prec_localZ_[^_]+_Z$\",\n",
    "\n",
    "    \"cf_cov_superZ_Z\":   r\"^cf_cov_superZ_[^_]+_Z$\",\n",
    "    \"cf_prec_superZ_Z\":  r\"^cf_prec_superZ_[^_]+_Z$\",\n",
    "}\n",
    "\n",
    "rows_new = []\n",
    "\n",
    "for new_name, pattern in collapse_patterns.items():\n",
    "    mask = means_df[\"metric\"].str.match(pattern)\n",
    "    sub = means_df[mask]\n",
    "    if len(sub) == 0:\n",
    "        continue\n",
    "    new_mean = sub[\"mean\"].mean()\n",
    "    rows_new.append({\"metric\": new_name, \"mean\": new_mean})\n",
    "\n",
    "# AÃ±adir las filas colapsadas\n",
    "if rows_new:\n",
    "    means_df = pd.concat([means_df, pd.DataFrame(rows_new)], ignore_index=True)\n",
    "\n",
    "# Eliminar mÃ©tricas CF especÃ­ficas por clase (Yes, No, 0, 1, B, M, etc.), tanto TEST como Z\n",
    "pattern_drop = r\"^cf_(cov|prec|comp)_\" \\\n",
    "               r\"(merged|lore|super|local_local|local_super|localZ|superZ)_\" \\\n",
    "               r\"[^_]+_(TEST|Z)$\"\n",
    "\n",
    "means_df = means_df[~means_df[\"metric\"].str.match(pattern_drop)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# ðŸ’¾ Guardar resultado final\n",
    "# ==========================================\n",
    "\n",
    "display(means_df.head(30))\n",
    "\n",
    "out_path = csv_dir / \"metrics_Balanced_global.csv\"\n",
    "means_df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\nâœ… Promedios globales guardados en: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
