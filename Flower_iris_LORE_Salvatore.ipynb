{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 12:05:35,085\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-05-09 12:05:39,580 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-09 12:05:39,795 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-05-09 12:05:39,919 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-05-09 12:05:39,921 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-05-09 12:05:40,243 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-05-09 12:05:40,607 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-05-09 12:05:40,725 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-05-09 12:05:40,729 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-05-09 12:05:40,986 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-05-09 12:05:41,110 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-05-09 12:05:41,267 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae?recursive=False&expand=False HTTP/11\" 200 291\n",
      "2025-05-09 12:05:41,420 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-05-09 12:05:41,569 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae/data?recursive=False&expand=False HTTP/11\" 200 249\n",
      "2025-05-09 12:05:41,574 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-09 12:05:41,714 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-05-09 12:05:41,846 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-05-09 12:05:41,978 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-05-09 12:05:41,984 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-09 12:05:42,162 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-05-09 12:05:42,165 filelock     DEBUG    Attempting to acquire lock 1675455462912 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_hitorilabs___iris_default_0.0.0_fa62476c42edcf9259f895f43da1a7bf9e2697ae.lock\n",
      "2025-05-09 12:05:42,166 filelock     DEBUG    Lock 1675455462912 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_hitorilabs___iris_default_0.0.0_fa62476c42edcf9259f895f43da1a7bf9e2697ae.lock\n",
      "2025-05-09 12:05:42,169 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-05-09 12:05:42,170 filelock     DEBUG    Attempting to release lock 1675455462912 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_hitorilabs___iris_default_0.0.0_fa62476c42edcf9259f895f43da1a7bf9e2697ae.lock\n",
      "2025-05-09 12:05:42,171 filelock     DEBUG    Lock 1675455462912 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_hitorilabs___iris_default_0.0.0_fa62476c42edcf9259f895f43da1a7bf9e2697ae.lock\n",
      "2025-05-09 12:05:42,213 filelock     DEBUG    Attempting to acquire lock 1675461816496 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\hitorilabs___iris\\default\\0.0.0\\fa62476c42edcf9259f895f43da1a7bf9e2697ae_builder.lock\n",
      "2025-05-09 12:05:42,214 filelock     DEBUG    Lock 1675461816496 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\hitorilabs___iris\\default\\0.0.0\\fa62476c42edcf9259f895f43da1a7bf9e2697ae_builder.lock\n",
      "2025-05-09 12:05:42,215 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-05-09 12:05:42,216 filelock     DEBUG    Attempting to release lock 1675461816496 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\hitorilabs___iris\\default\\0.0.0\\fa62476c42edcf9259f895f43da1a7bf9e2697ae_builder.lock\n",
      "2025-05-09 12:05:42,217 filelock     DEBUG    Lock 1675461816496 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\hitorilabs___iris\\default\\0.0.0\\fa62476c42edcf9259f895f43da1a7bf9e2697ae_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE_LABELS: ['Versicolor', 'Virginica', 'Setosa']\n",
      "FEATURES: ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
      "\n",
      "Contenido del TabularDataset:\n",
      "   petal_length  petal_width  sepal_length  sepal_width      target\n",
      "0           4.8          1.8           5.9          3.2  Versicolor\n",
      "1           3.5          1.0           5.7          2.6  Versicolor\n",
      "2           5.6          1.4           6.1          2.6   Virginica\n",
      "3           1.5          0.2           4.6          3.1      Setosa\n",
      "4           4.9          1.8           6.3          2.7   Virginica\n",
      "\n",
      "Descriptor del TabularDataset:\n",
      "{'numeric': {'petal_length': {'index': 0, 'min': 1.100000023841858, 'max': 6.699999809265137, 'mean': 3.9026663, 'std': 1.7214837074279785, 'median': 4.5, 'q1': 1.7000000476837158, 'q3': 5.099999904632568}, 'petal_width': {'index': 1, 'min': 0.10000000149011612, 'max': 2.5, 'mean': 1.228, 'std': 0.7334774732589722, 'median': 1.399999976158142, 'q1': 0.3500000089406967, 'q3': 1.7999999523162842}, 'sepal_length': {'index': 2, 'min': 4.300000190734863, 'max': 7.900000095367432, 'mean': 5.910667, 'std': 0.8623621463775635, 'median': 5.900000095367432, 'q1': 5.1499998569488525, 'q3': 6.450000047683716}, 'sepal_width': {'index': 3, 'min': 2.200000047683716, 'max': 4.199999809265137, 'mean': 3.0146666, 'std': 0.4056004583835602, 'median': 3.0, 'q1': 2.700000047683716, 'q3': 3.25}}, 'categorical': {}, 'ordinal': {}, 'target': {'target': {'index': 4, 'distinct_values': ['Versicolor', 'Virginica', 'Setosa'], 'count': {'Versicolor': 29, 'Virginica': 24, 'Setosa': 22}}}}\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# üì¶ IMPORTACIONES\n",
    "# =======================\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score, \n",
    "    f1_score, confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.common import Context, NDArrays, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =======================\n",
    "# ‚öôÔ∏è VARIABLES GLOBALES\n",
    "# =======================\n",
    "UNIQUE_LABELS = []\n",
    "FEATURES = []\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "NUM_CLIENTS = 2\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "fds = None  # Cache del FederatedDataset\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_dim = max(8, input_dim * 2)  # algo proporcional\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# =======================\n",
    "# üîß UTILIDADES MODELO\n",
    "# =======================\n",
    "\n",
    "def get_model_parameters(tree_model, nn_model):\n",
    "    tree_params = [\n",
    "        int(tree_model.get_params()[\"max_depth\"] or -1),\n",
    "        int(tree_model.get_params()[\"min_samples_split\"]),\n",
    "        int(tree_model.get_params()[\"min_samples_leaf\"]),\n",
    "    ]\n",
    "    nn_weights = [v.cpu().detach().numpy() for v in nn_model.state_dict().values()]\n",
    "    return {\n",
    "        \"tree\": tree_params,\n",
    "        \"nn\": nn_weights,\n",
    "    }\n",
    "\n",
    "\n",
    "def set_model_params(tree_model, nn_model, params):\n",
    "    tree_params = params[\"tree\"]\n",
    "    nn_weights = params[\"nn\"]\n",
    "\n",
    "    # Solo si tree_model no es None y tiene set_params\n",
    "    if tree_model is not None and hasattr(tree_model, \"set_params\"):\n",
    "        max_depth = tree_params[0] if tree_params[0] > 0 else None\n",
    "        tree_model.set_params(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=tree_params[1],\n",
    "            min_samples_leaf=tree_params[2],\n",
    "        )\n",
    "\n",
    "    # Actualizar pesos de la red neuronal\n",
    "    state_dict = nn_model.state_dict()\n",
    "    for (key, _), val in zip(state_dict.items(), nn_weights):\n",
    "        state_dict[key] = torch.tensor(val)\n",
    "    nn_model.load_state_dict(state_dict)\n",
    "\n",
    "    \n",
    "# =======================\n",
    "# üå≤ VISUALIZAR SUPERTREE\n",
    "# =======================\n",
    "\n",
    "def visualize_supertree(tree, feature_names=None, class_names=None, filename=\"supertree\"):\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def add_node(node, parent_id=None, edge_label=''):\n",
    "        curr_id = str(node_id[0])\n",
    "        node_id[0] += 1\n",
    "\n",
    "        if node.is_leaf:\n",
    "            class_index = np.argmax(node.labels)\n",
    "            class_label = class_names[class_index] if class_names else f\"class {class_index}\"\n",
    "            label = f\"class: {class_label}\\n{node.labels}\"\n",
    "        else:\n",
    "            fname = f\"X_{node.feat}\" if feature_names is None else feature_names[node.feat]\n",
    "            label = f\"{fname}\"\n",
    "\n",
    "        dot.node(curr_id, label)\n",
    "\n",
    "        if parent_id is not None:\n",
    "            dot.edge(parent_id, curr_id, label=edge_label)\n",
    "\n",
    "        if not node.is_leaf:\n",
    "            for i, child in enumerate(node.children):\n",
    "                label = f\"<= {node.intervals[i]:.2f}\" if i == 0 else f\"> {node.intervals[i - 1]:.2f}\"\n",
    "                add_node(child, curr_id, label)\n",
    "\n",
    "    add_node(tree)\n",
    "    dot.render(filename, format='png', cleanup=True)\n",
    "    print(f\"[SERVIDOR] üå≤ SuperTree guardado como '{filename}.png'\")\n",
    "\n",
    "# =======================\n",
    "# üìÑ CONVERTIR √ÅRBOL EN TEXTO A NODO\n",
    "# =======================\n",
    "\n",
    "def from_text_representation(text: str) -> SuperTree.Node:\n",
    "    lines = [line.rstrip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    root = None\n",
    "    stack = []\n",
    "\n",
    "    for line in lines:\n",
    "        indent = len(line) - len(line.lstrip())\n",
    "        level = indent // 4\n",
    "        content = line.strip()\n",
    "\n",
    "        if \"class:\" in content:\n",
    "            class_info = content.split(\"class: \")[-1]\n",
    "            node = SuperTree.Node(is_leaf=True)\n",
    "            node.predicted_class = class_info\n",
    "        else:\n",
    "            feat, cond = content.split(\" <= \")\n",
    "            node = SuperTree.Node(is_leaf=False)\n",
    "            node.feature = feat.strip()\n",
    "            node.threshold = float(cond.strip())\n",
    "\n",
    "        while len(stack) > level:\n",
    "            stack.pop()\n",
    "\n",
    "        if stack:\n",
    "            stack[-1].children.append(node)\n",
    "        else:\n",
    "            root = node\n",
    "\n",
    "        stack.append(node)\n",
    "\n",
    "    return root\n",
    "\n",
    "SuperTree.Node.from_text_representation = staticmethod(from_text_representation)\n",
    "\n",
    "# =======================\n",
    "# üì• CARGAR DATOS\n",
    "# =======================\n",
    "\n",
    "def load_data(partition_id: int, num_partitions: int):\n",
    "    global fds, UNIQUE_LABELS, FEATURES\n",
    "\n",
    "    if fds is None:\n",
    "        partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "        fds = FederatedDataset(dataset=\"hitorilabs/iris\", partitioners={\"train\": partitioner})\n",
    "\n",
    "    dataset = fds.load_partition(partition_id, \"train\").with_format(\"pandas\")[:]\n",
    "    target_column = dataset.columns[-1]\n",
    "\n",
    "    if dataset[target_column].dtype == \"object\":\n",
    "        label_encoder = LabelEncoder()\n",
    "        dataset[target_column] = label_encoder.fit_transform(dataset[target_column])\n",
    "    else:\n",
    "        dataset[target_column] = dataset[target_column].map({0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"})\n",
    "\n",
    "    dataset.rename(columns={target_column: \"target\"}, inplace=True)\n",
    "\n",
    "    if not UNIQUE_LABELS:\n",
    "        UNIQUE_LABELS = dataset[\"target\"].unique().tolist()\n",
    "    if not FEATURES:\n",
    "        FEATURES = dataset.drop(columns=[\"target\"]).columns.tolist()\n",
    "\n",
    "    tabular_dataset = TabularDataset(dataset, \"target\")\n",
    "\n",
    "    # Train/Test split (80/20)\n",
    "    X = dataset[FEATURES]\n",
    "    y = dataset[\"target\"]\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, tabular_dataset\n",
    "\n",
    "# =======================\n",
    "# üß™ PRUEBA DE CARGA LOCAL (solo en ejecuci√≥n directa)\n",
    "# =======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, y_train, X_test, y_test, dataset = load_data(partition_id=0, num_partitions=NUM_CLIENTS)\n",
    "\n",
    "    print(\"UNIQUE_LABELS:\", UNIQUE_LABELS)\n",
    "    print(\"FEATURES:\", FEATURES)\n",
    "\n",
    "    print(\"\\nContenido del TabularDataset:\")\n",
    "    print(dataset.df.head())\n",
    "\n",
    "    print(\"\\nDescriptor del TabularDataset:\")\n",
    "    print(dataset.descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir el cliente federado con Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "from flwr.client import NumPyClient\n",
    "from flwr.common import Context\n",
    "\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "\n",
    "from flwr.common import parameters_to_ndarrays\n",
    "\n",
    "class TorchNNWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X, dtype=np.float32)  # üëà Forzamos tipo compatible\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            outputs = self.model(X_tensor)\n",
    "            return outputs.argmax(dim=1).numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X, dtype=np.float32)  # üëà Igual aqu√≠\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            outputs = self.model(X_tensor)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            return probs.numpy()\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, tree_model, nn_model, X_train, y_train, X_test, y_test, dataset, client_id):\n",
    "        self.tree_model = tree_model\n",
    "        self.nn_model = nn_model\n",
    "        self.X_train = X_train.values\n",
    "        self.y_train = y_train.values\n",
    "        self.y_train_nn = LabelEncoder().fit_transform(self.y_train).astype(np.int64)\n",
    "        self.X_test = X_test.values\n",
    "        self.y_test = y_test.values\n",
    "        self.dataset = dataset\n",
    "        self.unique_labels = np.unique(y_train)\n",
    "        self.client_id = client_id\n",
    "        self.received_supertree = None\n",
    "\n",
    "    def _train_nn(self, epochs=10, lr=0.01):\n",
    "        self.nn_model.train()\n",
    "        optimizer = torch.optim.Adam(self.nn_model.parameters(), lr=lr)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        X_tensor = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(self.y_train_nn, dtype=torch.long)\n",
    "        \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.nn_model(X_tensor)\n",
    "            loss = loss_fn(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"[CLIENTE {self.client_id}] ‚úÖ Red neuronal entrenada \")\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_model_params(self.tree_model, self.nn_model, {\"tree\": [-1, 2, 1], \"nn\": parameters})\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "            self._train_nn()\n",
    "        nn_weights = get_model_parameters(self.tree_model, self.nn_model)[\"nn\"]\n",
    "        return nn_weights, len(self.X_train), {}\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_model_params(self.tree_model, self.nn_model, {\"tree\": [-1, 2, 1], \"nn\": parameters})\n",
    "\n",
    "        if \"supertree\" in config:\n",
    "            try:\n",
    "                supertree_dict = json.loads(config[\"supertree\"])\n",
    "                print(f\"[CLIENTE {self.client_id}] recibiendo SuperTree...\")\n",
    "                self.received_supertree = SuperTree.SuperNode.from_dict(supertree_dict)\n",
    "            except Exception as e:\n",
    "                print(f\"[CLIENTE {self.client_id}] ‚ùå Error al recibir SuperTree: {e}\")\n",
    "\n",
    "        try:\n",
    "            _ = self.tree_model.predict(self.X_test)\n",
    "        except NotFittedError:\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        y_pred = self.tree_model.predict(self.X_test)\n",
    "        y_proba = self.tree_model.predict_proba(self.X_test)\n",
    "\n",
    "        supertree = SuperTree()\n",
    "        root_node = supertree.rec_buildTree(self.tree_model, list(range(self.X_train.shape[1])))\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        self._save_local_tree(root_node, round_number)\n",
    "\n",
    "        tree_json = json.dumps([root_node.to_dict()])\n",
    "        print(f\"[CLIENTE {self.client_id}] ‚úÖ √Årbol local generado y enviado\")\n",
    "\n",
    "        self._explain_local_and_global(config)\n",
    "\n",
    "        return float(log_loss(self.y_test, y_proba)), len(self.X_test), {\n",
    "            \"Accuracy\": accuracy_score(self.y_test, y_pred),\n",
    "            \"Precision\": precision_score(self.y_test, y_pred, average=\"weighted\", zero_division=1),\n",
    "            \"Recall\": recall_score(self.y_test, y_pred, average=\"weighted\"),\n",
    "            \"F1_Score\": f1_score(self.y_test, y_pred, average=\"weighted\"),\n",
    "            \"AUC\": roc_auc_score(self.y_test, y_proba, multi_class=\"ovr\"),\n",
    "            \"tree_ensemble\": tree_json,\n",
    "        }\n",
    "    \n",
    "    def _print_tree_structure(self, node, prefix=\"\"):\n",
    "        if node is None:\n",
    "            print(f\"{prefix}None\")\n",
    "            return\n",
    "        leaf_info = f\"LEAF ‚Üí {node.labels}\" if node.is_leaf else f\"feat: {node.feat}, intervals: {getattr(node, 'intervals', None)}\"\n",
    "        print(f\"{prefix}{leaf_info}\")\n",
    "        if hasattr(node, \"children\") and node.children:\n",
    "            for idx, child in enumerate(node.children):\n",
    "                self._print_tree_structure(child, prefix + f\"  [{idx}]‚Üí \")\n",
    "\n",
    "\n",
    "    def _explain_local_and_global(self, config):\n",
    "        num_row = 5\n",
    "        local_df = pd.DataFrame(self.X_train, columns=self.dataset.df.columns[:-1]).astype(np.float32)\n",
    "        local_df[\"target\"] = self.y_train.astype(str)\n",
    "\n",
    "        local_tabular_dataset = TabularDataset(local_df, class_name=\"target\")\n",
    "        descriptor = local_tabular_dataset.get_descriptor()\n",
    "        encoder = ColumnTransformerEnc(descriptor)\n",
    "\n",
    "        # üß† Wrapper y generador LORE\n",
    "        nn_wrapper = TorchNNWrapper(self.nn_model)\n",
    "        bbox = sklearn_classifier_bbox.sklearnBBox(nn_wrapper)\n",
    "        lore = TabularGeneticGeneratorLore(bbox, local_tabular_dataset)\n",
    "\n",
    "        instance = local_tabular_dataset.df.iloc[num_row][:-1]\n",
    "        target = local_tabular_dataset.df.iloc[num_row][-1]\n",
    "\n",
    "        # üîç Generamos el √°rbol LORE\n",
    "        explanation = lore.explain_instance(instance.astype(np.float32), merge=True)\n",
    "        lore_tree = explanation[\"merged_tree\"]\n",
    "        self.lore_tree_root = lore_tree.root\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        self._save_lore_tree(lore_tree.root, round_number)\n",
    "\n",
    "        # üå≤ Fusionamos con SuperTree si est√° presente\n",
    "\n",
    "        print(f\"[CLIENTE {self.client_id}]  LORE:\")\n",
    "        self._print_tree_structure(self.lore_tree_root)\n",
    "        print(f\"[CLIENTE {self.client_id}] SuperTree:\")\n",
    "        self._print_tree_structure(self.received_supertree)\n",
    "\n",
    "\n",
    "        if self.received_supertree is not None:\n",
    "            merged_tree = SuperTree()\n",
    "            merged_root = merged_tree.mergeDecisionTrees(\n",
    "                roots=[self.lore_tree_root, self.received_supertree],\n",
    "                num_classes=len(self.unique_labels),\n",
    "                feature_names=self.dataset.df.columns[:-1].tolist(),\n",
    "            )\n",
    "\n",
    "            if merged_root is None:\n",
    "                print(\"[DEBUG] ‚ùå El merge no gener√≥ un √°rbol v√°lido.\")\n",
    "                return\n",
    "\n",
    "            merged_tree.root = merged_root\n",
    "            merged_tree.prune_redundant_leaves_full()\n",
    "            merged_tree.merge_equal_class_leaves()\n",
    "\n",
    "            print(\"Arbol podado\")\n",
    "            self._print_tree_structure(merged_tree.root)\n",
    "\n",
    "\n",
    "            self._save_tree(merged_tree.root, round_number, f\"LoreTree+Supertree_cliente_{self.client_id}_ronda_{round_number}\", f\"LoreTree+Supertree_Cliente_{self.client_id}\")\n",
    "\n",
    "        \n",
    "        # rule = explanation[\"rule\"]\n",
    "    \n",
    "    def _save_local_tree(self, tree, round_number):\n",
    "        self._save_tree(\n",
    "            tree,\n",
    "            round_number,\n",
    "            f\"arbol_local_cliente_{self.client_id}_ronda_{round_number}\",\n",
    "            f\"ArbolLocal_Cliente_{self.client_id}\"\n",
    "        )\n",
    "\n",
    "    def _save_tree(self, root_node, round_number, filename, subfolder):\n",
    "        dot = Digraph()\n",
    "        node_id = [0]\n",
    "\n",
    "\n",
    "        def add_node(node, parent_id=None, edge_label=\"\"):\n",
    "            curr_id = str(node_id[0])\n",
    "            node_id[0] += 1\n",
    "\n",
    "            if node.is_leaf:\n",
    "                class_index = np.argmax(node.labels)\n",
    "                class_label = str(self.unique_labels[class_index]) if len(self.unique_labels) > 0 else f\"class {class_index}\"\n",
    "                label = f\"class: {class_label}\\n{node.labels}\"\n",
    "            else:\n",
    "                fname = self.dataset.df.columns[node.feat] if node.feat is not None else \"?\"\n",
    "                label = f\"{fname}\"\n",
    "\n",
    "            dot.node(curr_id, label)\n",
    "\n",
    "            if parent_id:\n",
    "                dot.edge(parent_id, curr_id, label=edge_label)\n",
    "\n",
    "            if hasattr(node, \"children\") and hasattr(node, \"intervals\"):\n",
    "                for i, child in enumerate(node.children):\n",
    "                    # üëá Aqu√≠ cambiamos inf por una notaci√≥n comprensible\n",
    "                    left = node.intervals[i - 1] if i > 0 else None\n",
    "                    right = node.intervals[i] if i < len(node.intervals) else None\n",
    "\n",
    "                    if left is None:\n",
    "                        thr_label = f\"‚â§ {right:.2f}\" if right != float(\"inf\") else f\"> {node.intervals[-2]:.2f}\"\n",
    "                    else:\n",
    "                        thr_label = f\"> {left:.2f}\" if right == float(\"inf\") else f\"({left:.2f}, {right:.2f}]\"\n",
    "\n",
    "                    add_node(child, curr_id, thr_label)\n",
    "\n",
    "            elif hasattr(node, \"_left_child\") or hasattr(node, \"_right_child\"):\n",
    "                if node._left_child:\n",
    "                    add_node(node._left_child, curr_id, f\"‚â§ {node.thresh:.2f}\")\n",
    "                if node._right_child:\n",
    "                    add_node(node._right_child, curr_id, f\"> {node.thresh:.2f}\")\n",
    "\n",
    "        add_node(root_node)\n",
    "\n",
    "        round_folder = f\"Ronda_{round_number}\"\n",
    "        os.makedirs(round_folder, exist_ok=True)\n",
    "        folder_path = f\"{round_folder}/{subfolder}\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        filepath = f\"{folder_path}/{filename}\"\n",
    "        dot.render(filepath, format=\"png\", cleanup=True)\n",
    "        # print(f\"[CLIENTE {self.client_id}] üñº √Årbol guardado como '{filepath}.png'\")\n",
    "\n",
    "    def _save_lore_tree(self, root_node, round_number):\n",
    "        dot = Digraph()\n",
    "        node_id = [0]\n",
    "\n",
    "        def add_node(node, parent_id=None, edge_label=\"\"):\n",
    "            curr_id = str(node_id[0])\n",
    "            node_id[0] += 1\n",
    "\n",
    "            if node.is_leaf:\n",
    "                class_index = np.argmax(node.labels)\n",
    "                class_label = str(self.unique_labels[class_index]) if len(self.unique_labels) > 0 else f\"class {class_index}\"\n",
    "                label = f\"Clase: {class_label}\\n{node.labels}\"\n",
    "            else:\n",
    "                fname = self.dataset.df.columns[node.feat] if node.feat is not None else \"?\"\n",
    "                label = f\"{fname}\"\n",
    "\n",
    "            dot.node(curr_id, label)\n",
    "\n",
    "            if parent_id:\n",
    "                dot.edge(parent_id, curr_id, label=edge_label)\n",
    "\n",
    "            if not node.children:\n",
    "                return\n",
    "\n",
    "            for i, child in enumerate(node.children):\n",
    "                left = node.intervals[i - 1] if i > 0 else None\n",
    "                right = node.intervals[i] if i < len(node.intervals) else None\n",
    "\n",
    "                if left is None:\n",
    "                    thr_label = f\"‚â§ {right:.2f}\" if right != float(\"inf\") else f\"> {node.intervals[-2]:.2f}\"\n",
    "                else:\n",
    "                    thr_label = f\"> {left:.2f}\" if right == float(\"inf\") else f\"({left:.2f}, {right:.2f}]\"\n",
    "\n",
    "                add_node(child, curr_id, thr_label)\n",
    "\n",
    "        add_node(root_node)\n",
    "\n",
    "        round_folder = f\"Ronda_{round_number}\"\n",
    "        os.makedirs(round_folder, exist_ok=True)\n",
    "        folder_path = f\"{round_folder}/LoreTree_Cliente_{self.client_id}\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        filepath = f\"{folder_path}/lore_tree_cliente_{self.client_id}_ronda_{round_number}\"\n",
    "        dot.render(filepath, format=\"png\", cleanup=True)\n",
    "        print(f\"[CLIENTE {self.client_id}] üìÑ LoreTree guardado en '{filepath}.png'\")\n",
    "\n",
    "def create_tree_model():\n",
    "    return DecisionTreeClassifier(max_depth=5, min_samples_split=2, random_state=42)\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    X_train, y_train, X_test, y_test, dataset = load_data(partition_id, num_partitions)\n",
    "    tree_model = create_tree_model()\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(np.unique(y_train))\n",
    "    nn_model = Net(input_dim, output_dim)\n",
    "    return FlowerClient(tree_model, nn_model, X_train, y_train, X_test, y_test, dataset, client_id=partition_id + 1).to_client()\n",
    "\n",
    "client_app = ClientApp(client_fn=client_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurar el Servidor de Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üì¶ IMPORTACIONES NECESARIAS\n",
    "# ============================\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from flwr.common import Context, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "from graphviz import Digraph\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ‚öñÔ∏è CONFIGURACI√ìN GLOBAL\n",
    "# ============================\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "FEATURES = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "UNIQUE_LABELS = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
    "LATEST_SUPERTREE_JSON = None  # üå≤ Guardar √°rbol generado\n",
    "\n",
    "# ============================\n",
    "# üßê MODELO Y UTILIDADES\n",
    "# ============================\n",
    "\n",
    "def create_model():\n",
    "    input_dim = len(FEATURES)\n",
    "    output_dim = len(UNIQUE_LABELS)\n",
    "    return Net(input_dim, output_dim)\n",
    "\n",
    "def get_model_parameters(tree_model, nn_model):\n",
    "    tree_params = [ -1, 2, 1 ]  # Valores por defecto para el servidor\n",
    "    nn_weights = [v.cpu().detach().numpy() for v in nn_model.state_dict().values()]\n",
    "    return {\n",
    "        \"tree\": tree_params,\n",
    "        \"nn\": nn_weights,\n",
    "    }\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Dict[str, Scalar]:\n",
    "    total = sum(n for n, _ in metrics)\n",
    "    avg: Dict[str, List[float]] = {}\n",
    "    for n, met in metrics:\n",
    "        for k, v in met.items():\n",
    "            if isinstance(v, (float, int)):\n",
    "                avg.setdefault(k, []).append(n * float(v))\n",
    "    return {k: sum(vs) / total for k, vs in avg.items()}\n",
    "\n",
    "# ============================\n",
    "# üöÄ SERVIDOR FLOWER\n",
    "# ============================\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    model = create_model()\n",
    "    initial_params = ndarrays_to_parameters(get_model_parameters(None, model)[\"nn\"])\n",
    "\n",
    "\n",
    "    strategy = FedAvg(\n",
    "        min_available_clients=MIN_AVAILABLE_CLIENTS,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        initial_parameters=initial_params,\n",
    "    )\n",
    "\n",
    "    strategy.configure_fit = _inject_round(strategy.configure_fit)\n",
    "    strategy.configure_evaluate = _inject_round(strategy.configure_evaluate)\n",
    "\n",
    "    original_aggregate = strategy.aggregate_evaluate\n",
    "\n",
    "    def custom_aggregate_evaluate(server_round, results, failures):\n",
    "        global LATEST_SUPERTREE_JSON\n",
    "        aggregated_metrics = original_aggregate(server_round, results, failures)\n",
    "\n",
    "        try:\n",
    "            print(f\"\\n[SERVIDOR] üå≤ Generando SuperTree - Ronda {server_round}\")\n",
    "            tree_dicts = []\n",
    "            total_arboles = 0\n",
    "\n",
    "            for client_idx, (_, evaluate_res) in enumerate(results):\n",
    "                metrics = evaluate_res.metrics\n",
    "                trees_json = metrics.get(\"tree_ensemble\", None)\n",
    "                if trees_json:\n",
    "                    try:\n",
    "                        trees_list = json.loads(trees_json)\n",
    "                        for tdict in trees_list:\n",
    "                            root = SuperTree.Node.from_dict(tdict)\n",
    "                            if root:\n",
    "                                tree_dicts.append(root)\n",
    "                                total_arboles += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"[CLIENTE {client_idx+1}] ‚ùå Error al parsear √°rbol: {e}\")\n",
    "\n",
    "            # print(f\"[SERVIDOR] üìä Total de √°rboles: {total_arboles}\")\n",
    "\n",
    "            if not tree_dicts:\n",
    "                print(\"[SERVIDOR] ‚ö†Ô∏è No se recibieron √°rboles. Se omite SuperTree.\")\n",
    "                return aggregated_metrics\n",
    "\n",
    "            supertree = SuperTree()\n",
    "            supertree.mergeDecisionTrees(tree_dicts, num_classes=len(UNIQUE_LABELS), feature_names=FEATURES)\n",
    "            supertree.prune_redundant_leaves_full()\n",
    "            supertree.merge_equal_class_leaves()\n",
    "\n",
    "            _save_supertree_plot(supertree.root, server_round, feature_names=FEATURES, class_names=UNIQUE_LABELS)\n",
    "            LATEST_SUPERTREE_JSON = json.dumps(supertree.root.to_dict())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SERVIDOR] ‚ùå Error en SuperTree: {e}\")\n",
    "\n",
    "        time.sleep(10)\n",
    "        return aggregated_metrics\n",
    "\n",
    "    strategy.aggregate_evaluate = custom_aggregate_evaluate\n",
    "    config = ServerConfig(num_rounds=NUM_SERVER_ROUNDS)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# ============================\n",
    "# üìÇ HELPERS\n",
    "# ============================\n",
    "\n",
    "def _inject_round(original_fn):\n",
    "    def wrapper(server_round, parameters, client_manager):\n",
    "        global LATEST_SUPERTREE_JSON\n",
    "        instructions = original_fn(server_round, parameters, client_manager)\n",
    "        for _, ins in instructions:\n",
    "            ins.config[\"server_round\"] = server_round\n",
    "            if LATEST_SUPERTREE_JSON:\n",
    "                ins.config[\"supertree\"] = LATEST_SUPERTREE_JSON\n",
    "        return instructions\n",
    "    return wrapper\n",
    "\n",
    "def _save_supertree_plot(root_node, round_number, feature_names=None, class_names=None):\n",
    "    round_folder = f\"Ronda_{round_number}\"\n",
    "    os.makedirs(round_folder, exist_ok=True)\n",
    "\n",
    "    supertree_folder = f\"{round_folder}/Supertree\"\n",
    "    os.makedirs(supertree_folder, exist_ok=True)\n",
    "\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def add_node(node, parent=None, label=\"\"):\n",
    "        curr = str(node_id[0])\n",
    "        node_id[0] += 1\n",
    "\n",
    "        if node.is_leaf:\n",
    "            class_index = np.argmax(node.labels)\n",
    "            class_label = class_names[class_index] if class_names else f\"Clase {class_index}\"\n",
    "            label_text = f\"Clase: {class_label}\\n{node.labels}\"\n",
    "        else:\n",
    "            fname = f\"X_{node.feat}\" if feature_names is None else feature_names[node.feat]\n",
    "            label_text = f\"{fname}\"\n",
    "\n",
    "        dot.node(curr, label_text)\n",
    "\n",
    "        if parent:\n",
    "            dot.edge(parent, curr, label=label)\n",
    "\n",
    "        if not node.is_leaf:\n",
    "            for i, child in enumerate(node.children):\n",
    "                thr_label = f\"<= {node.intervals[i]:.2f}\" if i == 0 else f\"> {node.intervals[i - 1]:.2f}\"\n",
    "                add_node(child, curr, thr_label)\n",
    "\n",
    "    add_node(root_node)\n",
    "    filename = f\"{supertree_folder}/supertree_ronda_{round_number}\"\n",
    "    dot.render(filename, format=\"png\", cleanup=True)\n",
    "    # print(f\"[SERVIDOR] ‚úÖ SuperTree guardado como '{filename}.png'\")\n",
    "\n",
    "# ============================\n",
    "# üîß INICIALIZAR SERVER APP\n",
    "# ============================\n",
    "server_app = ServerApp(server_fn=server_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pasos que se realizan en el notebook:**\n",
    "\n",
    "1. El servidor inicializa el modelo y lo env√≠a a cada uno de los clientes.\n",
    "\n",
    "2. Cada cliente entrena un RandomForest con su respectivo subconjunto de datos o partici√≥n que hemos realizado al principio.\n",
    "\n",
    "3. Los clientes entrenan, y mandan sus hiperpar√°metros (N¬∫ de √°rboles, profundidad, etc.) al servidor.\n",
    "\n",
    "4. El servidor combina los par√°metros y actualiza el modelo global.\n",
    "\n",
    "5. Se mide el rendimiento del modelo sobre cada cliente, obteniendo tambi√©n sus contrafactuales y se repite el proceso las rondas que deseemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutar la Simulaci√≥n Federada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 12:05:47,693\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-05-09 12:05:53,135 flwr         DEBUG    Asyncio event loop already running.\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      ":job_id:01000000\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":job_id:01000000\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 1] ‚úÖ Red neuronal entrenada \n",
      "[CLIENTE 2] ‚úÖ Red neuronal entrenada \n",
      "[CLIENTE 2] ‚úÖ √Årbol local generado y enviado\n",
      "[CLIENTE 1] ‚úÖ √Årbol local generado y enviado\n",
      "[CLIENTE 2] üìÑ LoreTree guardado en 'Ronda_1/LoreTree_Cliente_2/lore_tree_cliente_2_ronda_1.png'\n",
      "[CLIENTE 2]  LORE:\n",
      "feat: 1, intervals: [2.8067674772644042, 2.8067774772644043, inf]\n",
      "  [0]‚Üí feat: 2, intervals: [1.7460639476776123, inf]\n",
      "  [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [0]‚Üí   [1]‚Üí feat: 0, intervals: [4.802204608917236, inf]\n",
      "  [0]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [0]‚Üí   [1]‚Üí   [1]‚Üí feat: 1, intervals: [2.3419976234436035, inf]\n",
      "  [0]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [0]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí feat: 1, intervals: [2.744604706764221, inf]\n",
      "  [0]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [0]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí feat: 2, intervals: [1.7460639476776123, inf]\n",
      "  [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí feat: 0, intervals: [4.802204608917236, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí feat: 2, intervals: [5.101480960845947, inf]\n",
      "  [2]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "[CLIENTE 2] SuperTree:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 1] üìÑ LoreTree guardado en 'Ronda_1/LoreTree_Cliente_1/lore_tree_cliente_1_ronda_1.png'\n",
      "[CLIENTE 1]  LORE:\n",
      "feat: 1, intervals: [3.6198809146881104, inf]\n",
      "  [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [1]‚Üí feat: 2, intervals: [5.880961431732178, 5.880971431732178, inf]\n",
      "  [1]‚Üí   [0]‚Üí feat: 0, intervals: [7.554922832717896, 7.5549328327178955, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí feat: 3, intervals: [2.310054911842346, 2.310064911842346, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí feat: 1, intervals: [3.926494850387573, 3.9265048503875732, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí feat: 1, intervals: [3.884672522544861, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí feat: 1, intervals: [3.926494850387573, 3.9265048503875732, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí feat: 1, intervals: [3.884672522544861, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [2]‚Üí feat: 1, intervals: [3.920169711112976, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí feat: 3, intervals: [2.310054911842346, 2.310064911842346, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí feat: 1, intervals: [3.926494850387573, 3.9265048503875732, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí feat: 1, intervals: [3.884672522544861, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí feat: 1, intervals: [3.926494850387573, 3.9265048503875732, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí feat: 1, intervals: [3.884672522544861, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [2]‚Üí feat: 1, intervals: [3.920169711112976, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [0]‚Üí   [2]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí feat: 0, intervals: [7.554922832717896, 7.5549328327178955, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí feat: 3, intervals: [2.310054911842346, 2.310064911842346, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí feat: 1, intervals: [3.926494850387573, 3.9265048503875732, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí feat: 1, intervals: [3.884672522544861, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí feat: 1, intervals: [3.926494850387573, 3.9265048503875732, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí feat: 1, intervals: [3.884672522544861, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [2]‚Üí feat: 1, intervals: [3.920169711112976, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí feat: 3, intervals: [2.310054911842346, 2.310064911842346, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí feat: 1, intervals: [3.926494850387573, 3.9265048503875732, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí feat: 1, intervals: [3.884672522544861, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí feat: 1, intervals: [3.926494850387573, 3.9265048503875732, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí feat: 1, intervals: [3.884672522544861, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [2]‚Üí feat: 1, intervals: [3.920169711112976, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [2]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí   [2]‚Üí LEAF ‚Üí [0. 1.]\n",
      "[CLIENTE 1] SuperTree:\n",
      "None\n",
      "\n",
      "[SERVIDOR] üå≤ Generando SuperTree - Ronda 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 2] ‚úÖ Red neuronal entrenada \n",
      "[CLIENTE 1] ‚úÖ Red neuronal entrenada \n",
      "[CLIENTE 2] recibiendo SuperTree...[CLIENTE 1] recibiendo SuperTree...\n",
      "\n",
      "[CLIENTE 1] ‚úÖ √Årbol local generado y enviado\n",
      "[CLIENTE 2] ‚úÖ √Årbol local generado y enviado\n",
      "[CLIENTE 2] üìÑ LoreTree guardado en 'Ronda_2/LoreTree_Cliente_2/lore_tree_cliente_2_ronda_2.png'\n",
      "[CLIENTE 2]  LORE:\n",
      "feat: 3, intervals: [1.7100539939308166, 1.7100639939308167, inf]\n",
      "  [0]‚Üí feat: 2, intervals: [6.40087628364563, inf]\n",
      "  [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí feat: 2, intervals: [6.40087628364563, inf]\n",
      "  [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí feat: 1, intervals: [2.8597201244735717, 2.8597301244735718, inf]\n",
      "  [2]‚Üí   [0]‚Üí feat: 2, intervals: [3.3639074563980103, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [1]‚Üí feat: 0, intervals: [6.732056617736816, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí feat: 0, intervals: [7.098649978637695, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí   [1]‚Üí feat: 2, intervals: [3.3639074563980103, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [1]‚Üí feat: 0, intervals: [6.732056617736816, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí feat: 0, intervals: [7.098649978637695, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí   [2]‚Üí feat: 2, intervals: [4.516696453094482, inf]\n",
      "  [2]‚Üí   [2]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [2]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "[CLIENTE 2] SuperTree:\n",
      "feat: 2, intervals: [2.699999988079071, inf]\n",
      "  [0]‚Üí LEAF ‚Üí [5. 2. 1.]\n",
      "  [1]‚Üí feat: 2, intervals: [4.949990047683716, 4.950000047683716, inf]\n",
      "  [1]‚Üí   [0]‚Üí feat: 3, intervals: [1.75, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [ 0. 20.  8.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí feat: 1, intervals: [3.0, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 0. 4.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1. 1.]\n",
      "  [1]‚Üí   [1]‚Üí feat: 3, intervals: [1.75, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 8. 4.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí feat: 1, intervals: [3.0, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 0. 4.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1. 1.]\n",
      "  [1]‚Üí   [2]‚Üí feat: 3, intervals: [1.74999, 1.75, inf]\n",
      "  [1]‚Üí   [2]‚Üí   [0]‚Üí feat: 3, intervals: [1.550000011920929, inf]\n",
      "  [1]‚Üí   [2]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [0. 0. 4.]\n",
      "  [1]‚Üí   [2]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1. 1.]\n",
      "  [1]‚Üí   [2]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1. 1.]\n",
      "  [1]‚Üí   [2]‚Üí   [2]‚Üí LEAF ‚Üí [0. 0. 2.]\n",
      "Arbol podado\n",
      "LEAF ‚Üí [9. 0. 0.]\n",
      "[CLIENTE 1] üìÑ LoreTree guardado en 'Ronda_2/LoreTree_Cliente_1/lore_tree_cliente_1_ronda_2.png'\n",
      "[CLIENTE 1]  LORE:\n",
      "feat: 1, intervals: [3.812204136123657, 3.8122141361236572, inf]\n",
      "  [0]‚Üí feat: 2, intervals: [4.8660197257995605, inf]\n",
      "  [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [0]‚Üí   [1]‚Üí feat: 3, intervals: [0.41533075273036957, inf]\n",
      "  [0]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [0]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [1]‚Üí feat: 2, intervals: [4.8660197257995605, inf]\n",
      "  [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí feat: 3, intervals: [0.41533075273036957, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí feat: 2, intervals: [5.7405555384063724, 5.740565538406372, inf]\n",
      "  [2]‚Üí   [0]‚Üí feat: 0, intervals: [5.700164331665039, 5.700174331665039, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [0]‚Üí feat: 3, intervals: [2.300839900970459, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí   [0]‚Üí   [1]‚Üí feat: 3, intervals: [2.300839900970459, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí feat: 3, intervals: [2.3332259790802, 2.3332359790802, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí feat: 0, intervals: [6.863468422164917, 6.863478422164917, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí   [0]‚Üí feat: 1, intervals: [3.9854016304016113, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí   [1]‚Üí feat: 1, intervals: [3.9854016304016113, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [0]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí feat: 0, intervals: [6.863468422164917, 6.863478422164917, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí   [0]‚Üí feat: 1, intervals: [3.9854016304016113, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí   [1]‚Üí feat: 1, intervals: [3.9854016304016113, inf]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [1]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [0]‚Üí   [2]‚Üí   [2]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí   [1]‚Üí feat: 0, intervals: [5.700164331665039, 5.700174331665039, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [0]‚Üí feat: 3, intervals: [2.300839900970459, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí   [1]‚Üí   [1]‚Üí feat: 3, intervals: [2.300839900970459, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [2. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí feat: 3, intervals: [2.3332259790802, 2.3332359790802, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí feat: 0, intervals: [6.863468422164917, 6.863478422164917, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí   [0]‚Üí feat: 1, intervals: [3.9854016304016113, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí   [1]‚Üí feat: 1, intervals: [3.9854016304016113, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [0]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí feat: 0, intervals: [6.863468422164917, 6.863478422164917, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí   [0]‚Üí feat: 1, intervals: [3.9854016304016113, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí   [1]‚Üí feat: 1, intervals: [3.9854016304016113, inf]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 2.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [1]‚Üí   [2]‚Üí LEAF ‚Üí [1. 0.]\n",
      "  [2]‚Üí   [1]‚Üí   [2]‚Üí   [2]‚Üí LEAF ‚Üí [0. 1.]\n",
      "  [2]‚Üí   [2]‚Üí LEAF ‚Üí [0. 1.]\n",
      "[CLIENTE 1] SuperTree:\n",
      "feat: 2, intervals: [2.699999988079071, inf]\n",
      "  [0]‚Üí LEAF ‚Üí [5. 2. 1.]\n",
      "  [1]‚Üí feat: 2, intervals: [4.949990047683716, 4.950000047683716, inf]\n",
      "  [1]‚Üí   [0]‚Üí feat: 3, intervals: [1.75, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [ 0. 20.  8.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí feat: 1, intervals: [3.0, inf]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 0. 4.]\n",
      "  [1]‚Üí   [0]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1. 1.]\n",
      "  [1]‚Üí   [1]‚Üí feat: 3, intervals: [1.75, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 8. 4.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí feat: 1, intervals: [3.0, inf]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [0]‚Üí LEAF ‚Üí [0. 0. 4.]\n",
      "  [1]‚Üí   [1]‚Üí   [1]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1. 1.]\n",
      "  [1]‚Üí   [2]‚Üí feat: 3, intervals: [1.74999, 1.75, inf]\n",
      "  [1]‚Üí   [2]‚Üí   [0]‚Üí feat: 3, intervals: [1.550000011920929, inf]\n",
      "  [1]‚Üí   [2]‚Üí   [0]‚Üí   [0]‚Üí LEAF ‚Üí [0. 0. 4.]\n",
      "  [1]‚Üí   [2]‚Üí   [0]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1. 1.]\n",
      "  [1]‚Üí   [2]‚Üí   [1]‚Üí LEAF ‚Üí [0. 1. 1.]\n",
      "  [1]‚Üí   [2]‚Üí   [2]‚Üí LEAF ‚Üí [0. 0. 2.]\n",
      "Arbol podado\n",
      "LEAF ‚Üí [9. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SERVIDOR] üå≤ Generando SuperTree - Ronda 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 2 round(s) in 140.68s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.220446049250313e-16\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 2.220446049250313e-16\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'AUC': [(1, 1.0), (2, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Accuracy': [(1, 1.0), (2, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'F1_Score': [(1, 1.0), (2, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Precision': [(1, 1.0), (2, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Recall': [(1, 1.0), (2, 1.0)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n"
     ]
    }
   ],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "import logging\n",
    "import warnings\n",
    "import ray\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger(\"filelock\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"ray\").setLevel(logging.WARNING)\n",
    "logging.getLogger('graphviz').setLevel(logging.WARNING)\n",
    "# logging.getLogger(\"flwr\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()  # Apagar cualquier sesi√≥n previa de Ray\n",
    "ray.init(local_mode=True)  # Desactiva multiprocessing, usa un solo proceso principal\n",
    "\n",
    "backend_config = {\"num_cpus\": 1}\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
