{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 09:53:08,400 datasets     INFO     PyTorch version 2.6.0 available.\n",
      "2025-04-02 09:53:08,664 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-02 09:53:08,877 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-04-02 09:53:09,027 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-04-02 09:53:09,030 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-04-02 09:53:09,371 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-04-02 09:53:09,495 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-04-02 09:53:09,624 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-04-02 09:53:09,627 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-04-02 09:53:09,942 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-04-02 09:53:10,064 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-04-02 09:53:10,305 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae?recursive=False&expand=False HTTP/11\" 200 291\n",
      "2025-04-02 09:53:10,429 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-04-02 09:53:10,554 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae/data?recursive=False&expand=False HTTP/11\" 200 249\n",
      "2025-04-02 09:53:10,558 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-02 09:53:10,736 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-04-02 09:53:10,860 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-04-02 09:53:10,993 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-04-02 09:53:10,999 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-02 09:53:11,155 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-04-02 09:53:11,159 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-04-02 09:53:11,193 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE_LABELS: ['Versicolor', 'Virginica', 'Setosa']\n",
      "FEATURES: ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
      "\n",
      "Contenido del TabularDataset:\n",
      "   petal_length  petal_width  sepal_length  sepal_width      target\n",
      "0           4.8          1.8           5.9          3.2  Versicolor\n",
      "1           3.5          1.0           5.7          2.6  Versicolor\n",
      "2           5.6          1.4           6.1          2.6   Virginica\n",
      "3           1.5          0.2           4.6          3.1      Setosa\n",
      "4           4.9          1.8           6.3          2.7   Virginica\n",
      "\n",
      "Descriptor del TabularDataset:\n",
      "{'numeric': {'petal_length': {'index': 0, 'min': 1.100000023841858, 'max': 6.699999809265137, 'mean': 3.9026663, 'std': 1.7214837074279785, 'median': 4.5, 'q1': 1.7000000476837158, 'q3': 5.099999904632568}, 'petal_width': {'index': 1, 'min': 0.10000000149011612, 'max': 2.5, 'mean': 1.228, 'std': 0.7334774732589722, 'median': 1.399999976158142, 'q1': 0.3500000089406967, 'q3': 1.7999999523162842}, 'sepal_length': {'index': 2, 'min': 4.300000190734863, 'max': 7.900000095367432, 'mean': 5.910667, 'std': 0.8623621463775635, 'median': 5.900000095367432, 'q1': 5.1499998569488525, 'q3': 6.450000047683716}, 'sepal_width': {'index': 3, 'min': 2.200000047683716, 'max': 4.199999809265137, 'mean': 3.0146666, 'std': 0.4056004583835602, 'median': 3.0, 'q1': 2.700000047683716, 'q3': 3.25}}, 'categorical': {}, 'ordinal': {}, 'target': {'target': {'index': 4, 'distinct_values': ['Versicolor', 'Virginica', 'Setosa'], 'count': {'Versicolor': 29, 'Virginica': 24, 'Setosa': 22}}}}\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 📦 IMPORTACIONES\n",
    "# =======================\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score, \n",
    "    f1_score, confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.common import Context, NDArrays, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "# =======================\n",
    "# ⚙️ VARIABLES GLOBALES\n",
    "# =======================\n",
    "UNIQUE_LABELS = []\n",
    "FEATURES = []\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "NUM_CLIENTS = 2\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "fds = None  # Cache del FederatedDataset\n",
    "\n",
    "# =======================\n",
    "# 🔧 UTILIDADES MODELO\n",
    "# =======================\n",
    "\n",
    "def get_model_parameters(model):\n",
    "    p = model.get_params()\n",
    "    return [\n",
    "        int(p[\"max_depth\"]) if p[\"max_depth\"] is not None else -1,\n",
    "        int(p[\"min_samples_split\"]),\n",
    "        int(p[\"min_samples_leaf\"]),\n",
    "    ]\n",
    "\n",
    "def set_model_params(model, params):\n",
    "    max_depth = int(params[0].item()) if hasattr(params[0], \"item\") else int(params[0])\n",
    "    min_samples_split = max(2, int(params[1].item()) if hasattr(params[1], \"item\") else int(params[1]))\n",
    "    min_samples_leaf = max(1, int(params[2].item()) if hasattr(params[2], \"item\") else int(params[2]))\n",
    "\n",
    "    model.set_params(\n",
    "        max_depth=max_depth if max_depth > 0 else None,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "    )\n",
    "# =======================\n",
    "# 🌲 VISUALIZAR SUPERTREE\n",
    "# =======================\n",
    "\n",
    "def visualize_supertree(tree, feature_names=None, class_names=None, filename=\"supertree\"):\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def add_node(node, parent_id=None, edge_label=''):\n",
    "        curr_id = str(node_id[0])\n",
    "        node_id[0] += 1\n",
    "\n",
    "        if node.is_leaf:\n",
    "            class_index = np.argmax(node.labels)\n",
    "            class_label = class_names[class_index] if class_names else f\"class {class_index}\"\n",
    "            label = f\"class: {class_label}\\n{node.labels}\"\n",
    "        else:\n",
    "            fname = f\"X_{node.feat}\" if feature_names is None else feature_names[node.feat]\n",
    "            label = f\"{fname}\"\n",
    "\n",
    "        dot.node(curr_id, label)\n",
    "\n",
    "        if parent_id is not None:\n",
    "            dot.edge(parent_id, curr_id, label=edge_label)\n",
    "\n",
    "        if not node.is_leaf:\n",
    "            for i, child in enumerate(node.children):\n",
    "                label = f\"<= {node.intervals[i]:.2f}\" if i == 0 else f\"> {node.intervals[i - 1]:.2f}\"\n",
    "                add_node(child, curr_id, label)\n",
    "\n",
    "    add_node(tree)\n",
    "    dot.render(filename, format='png', cleanup=True)\n",
    "    print(f\"[SERVIDOR] 🌲 SuperTree guardado como '{filename}.png'\")\n",
    "\n",
    "# =======================\n",
    "# 📄 CONVERTIR ÁRBOL EN TEXTO A NODO\n",
    "# =======================\n",
    "\n",
    "def from_text_representation(text: str) -> SuperTree.Node:\n",
    "    lines = [line.rstrip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    root = None\n",
    "    stack = []\n",
    "\n",
    "    for line in lines:\n",
    "        indent = len(line) - len(line.lstrip())\n",
    "        level = indent // 4\n",
    "        content = line.strip()\n",
    "\n",
    "        if \"class:\" in content:\n",
    "            class_info = content.split(\"class: \")[-1]\n",
    "            node = SuperTree.Node(is_leaf=True)\n",
    "            node.predicted_class = class_info\n",
    "        else:\n",
    "            feat, cond = content.split(\" <= \")\n",
    "            node = SuperTree.Node(is_leaf=False)\n",
    "            node.feature = feat.strip()\n",
    "            node.threshold = float(cond.strip())\n",
    "\n",
    "        while len(stack) > level:\n",
    "            stack.pop()\n",
    "\n",
    "        if stack:\n",
    "            stack[-1].children.append(node)\n",
    "        else:\n",
    "            root = node\n",
    "\n",
    "        stack.append(node)\n",
    "\n",
    "    return root\n",
    "\n",
    "SuperTree.Node.from_text_representation = staticmethod(from_text_representation)\n",
    "\n",
    "# =======================\n",
    "# 📥 CARGAR DATOS\n",
    "# =======================\n",
    "\n",
    "def load_data(partition_id: int, num_partitions: int):\n",
    "    global fds, UNIQUE_LABELS, FEATURES\n",
    "\n",
    "    if fds is None:\n",
    "        partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "        fds = FederatedDataset(dataset=\"hitorilabs/iris\", partitioners={\"train\": partitioner})\n",
    "\n",
    "    dataset = fds.load_partition(partition_id, \"train\").with_format(\"pandas\")[:]\n",
    "    target_column = dataset.columns[-1]\n",
    "\n",
    "    if dataset[target_column].dtype == \"object\":\n",
    "        label_encoder = LabelEncoder()\n",
    "        dataset[target_column] = label_encoder.fit_transform(dataset[target_column])\n",
    "    else:\n",
    "        dataset[target_column] = dataset[target_column].map({0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"})\n",
    "\n",
    "    dataset.rename(columns={target_column: \"target\"}, inplace=True)\n",
    "\n",
    "    if not UNIQUE_LABELS:\n",
    "        UNIQUE_LABELS = dataset[\"target\"].unique().tolist()\n",
    "    if not FEATURES:\n",
    "        FEATURES = dataset.drop(columns=[\"target\"]).columns.tolist()\n",
    "\n",
    "    tabular_dataset = TabularDataset(dataset, \"target\")\n",
    "\n",
    "    # Train/Test split (80/20)\n",
    "    X = dataset[FEATURES]\n",
    "    y = dataset[\"target\"]\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, tabular_dataset\n",
    "\n",
    "# =======================\n",
    "# 🧪 PRUEBA DE CARGA LOCAL (solo en ejecución directa)\n",
    "# =======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, y_train, X_test, y_test, dataset = load_data(partition_id=0, num_partitions=NUM_CLIENTS)\n",
    "\n",
    "    print(\"UNIQUE_LABELS:\", UNIQUE_LABELS)\n",
    "    print(\"FEATURES:\", FEATURES)\n",
    "\n",
    "    print(\"\\nContenido del TabularDataset:\")\n",
    "    print(dataset.df.head())\n",
    "\n",
    "    print(\"\\nDescriptor del TabularDataset:\")\n",
    "    print(dataset.descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir el cliente federado con Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, model, X_train, y_train, X_test, y_test, dataset, client_id):\n",
    "        self.model = model\n",
    "        self.X_train = X_train.values\n",
    "        self.y_train = y_train.values\n",
    "        self.X_test = X_test.values\n",
    "        self.y_test = y_test.values\n",
    "        self.dataset = dataset\n",
    "        self.unique_labels = np.unique(y_train)\n",
    "        self.client_id = client_id\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_model_params(self.model, parameters)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "        return get_model_parameters(self.model), len(self.X_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_model_params(self.model, parameters)\n",
    "\n",
    "        try:\n",
    "            _ = self.model.predict(self.X_test)\n",
    "        except NotFittedError:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        y_proba = self.model.predict_proba(self.X_test)\n",
    "\n",
    "        # ⚙️ LORE: Generar árboles únicamente\n",
    "        bbox = sklearn_classifier_bbox.sklearnBBox(self.model)\n",
    "        lore = TabularGeneticGeneratorLore(bbox, self.dataset)\n",
    "        x = self.dataset.df.iloc[5][:-1]\n",
    "        lore.explain_instance(x)\n",
    "\n",
    "        # Convertir árboles a dict\n",
    "        ensemble_trees = [\n",
    "            SuperTree().rec_buildTree(tree, list(range(self.X_train.shape[1]))).to_dict()\n",
    "            for tree in lore.surrogate.trees\n",
    "        ]\n",
    "\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        self._save_lore_trees(lore.surrogate.trees, round_number)\n",
    "\n",
    "        trees_json = json.dumps(ensemble_trees)\n",
    "\n",
    "        print(f\"[CLIENTE {self.client_id}] Árboles generados: {len(lore.surrogate.trees)}\")\n",
    "        print(f\"[CLIENTE {self.client_id}] ✅ Enviando árboles al servidor:\")\n",
    "        # print(trees_json[:300] + \"...\" if len(trees_json) > 300 else trees_json)\n",
    "\n",
    "        return float(log_loss(self.y_test, y_proba)), len(self.X_test), {\n",
    "            \"Accuracy\": accuracy_score(self.y_test, y_pred),\n",
    "            \"Precision\": precision_score(self.y_test, y_pred, average=\"weighted\", zero_division=1),\n",
    "            \"Recall\": recall_score(self.y_test, y_pred, average=\"weighted\"),\n",
    "            \"F1_Score\": f1_score(self.y_test, y_pred, average=\"weighted\"),\n",
    "            \"AUC\": roc_auc_score(self.y_test, y_proba, multi_class=\"ovr\"),\n",
    "            \"tree_ensemble\": trees_json,\n",
    "        }\n",
    "    \n",
    "    def _save_lore_trees(self, trees, round_number):\n",
    "        for idx, tree in enumerate(trees):\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            plot_tree(\n",
    "                tree,\n",
    "                feature_names=self.dataset.df.columns[:-1],\n",
    "                class_names=np.unique(self.y_train).astype(str),\n",
    "                filled=True,\n",
    "                rounded=True,\n",
    "                ax=ax\n",
    "            )\n",
    "            filename = f\"tree_cliente_{self.client_id}_arbol_{idx+1}_rondaServidor_{round_number}.png\"\n",
    "            plt.title(f\"Árbol {idx+1} - Cliente {self.client_id} - Ronda {round_number}\")\n",
    "            fig.savefig(filename)\n",
    "            plt.close(fig)\n",
    "            print(f\"[CLIENTE {self.client_id}] 🌲 Árbol {idx+1} guardado como '{filename}'\")\n",
    "\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    return DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    X_train, y_train, X_test, y_test, dataset = load_data(partition_id, num_partitions)\n",
    "    model = create_model()\n",
    "    return FlowerClient(model, X_train, y_train, X_test, y_test, dataset, client_id=partition_id + 1).to_client()\n",
    "\n",
    "\n",
    "client_app = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurar el Servidor de Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 📦 IMPORTACIONES NECESARIAS\n",
    "# ============================\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from flwr.common import Context, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from graphviz import Digraph\n",
    "\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "from lore_sa.dataset import TabularDataset\n",
    "\n",
    "# ============================\n",
    "# ⚖️ CONFIGURACIÓN GLOBAL\n",
    "# ============================\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "\n",
    "# ============================\n",
    "# 🧐 MODELO Y UTILIDADES\n",
    "# ============================\n",
    "\n",
    "def create_model():\n",
    "    return DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "def get_model_parameters(model):\n",
    "    p = model.get_params()\n",
    "    return [p[\"max_depth\"] or -1, p[\"min_samples_split\"], p[\"min_samples_leaf\"]]\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Dict[str, Scalar]:\n",
    "    total = sum(n for n, _ in metrics)\n",
    "    avg: Dict[str, List[float]] = {}\n",
    "    for n, met in metrics:\n",
    "        for k, v in met.items():\n",
    "            if isinstance(v, (float, int)):\n",
    "                avg.setdefault(k, []).append(n * float(v))\n",
    "    return {k: sum(vs) / total for k, vs in avg.items()}\n",
    "\n",
    "# ============================\n",
    "# 🚀 SERVIDOR FLOWER\n",
    "# ============================\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    model = create_model()\n",
    "    initial_params = ndarrays_to_parameters(get_model_parameters(model))\n",
    "\n",
    "    strategy = FedAvg(\n",
    "        min_available_clients=MIN_AVAILABLE_CLIENTS,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        initial_parameters=initial_params,\n",
    "    )\n",
    "\n",
    "    strategy.configure_fit = _inject_round(strategy.configure_fit)\n",
    "    strategy.configure_evaluate = _inject_round(strategy.configure_evaluate)\n",
    "\n",
    "    original_aggregate = strategy.aggregate_evaluate\n",
    "\n",
    "    def custom_aggregate_evaluate(server_round, results, failures):\n",
    "        aggregated_metrics = original_aggregate(server_round, results, failures)\n",
    "        try:\n",
    "            print(f\"\\n[SERVIDOR] 🌲 Generando SuperTree - Ronda {server_round}\")\n",
    "            tree_dicts = []\n",
    "            total_arboles = 0\n",
    "\n",
    "            for client_idx, (_, evaluate_res) in enumerate(results):\n",
    "                metrics = evaluate_res.metrics\n",
    "                # print(f\"[SERVIDOR] 🗕️ Cliente {client_idx+1} - Keys: {list(metrics.keys())}\")\n",
    "                trees_json = metrics.get(\"tree_ensemble\", None)\n",
    "                if trees_json:\n",
    "                    try:\n",
    "                        trees_list = json.loads(trees_json)\n",
    "                        # print(f\"[CLIENTE {client_idx+1}] 📆 {len(trees_list)} árboles recibidos\")\n",
    "                        for tdict in trees_list:\n",
    "                            root = SuperTree.Node.from_dict(tdict)\n",
    "                            if root:\n",
    "                                tree_dicts.append(root)\n",
    "                                total_arboles += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"[CLIENTE {client_idx+1}] ❌ Error al parsear 'tree_ensemble': {e}\")\n",
    "\n",
    "            print(f\"[SERVIDOR] 📊 Total de árboles: {total_arboles}\")\n",
    "\n",
    "            if not tree_dicts:\n",
    "                print(\"[SERVIDOR] ⚠️ No se recibieron árboles. Se omite SuperTree.\")\n",
    "                return aggregated_metrics\n",
    "\n",
    "            supertree = SuperTree()\n",
    "            supertree.mergeDecisionTrees(tree_dicts, num_classes=3)\n",
    "            supertree.prune_redundant_leaves_full()\n",
    "            supertree.merge_equal_class_leaves()\n",
    "            _save_supertree_plot(supertree.root, server_round, feature_names=FEATURES, class_names=UNIQUE_LABELS)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SERVIDOR] ❌ Error en SuperTree: {e}\")\n",
    "\n",
    "        time.sleep(10)\n",
    "        return aggregated_metrics\n",
    "\n",
    "    strategy.aggregate_evaluate = custom_aggregate_evaluate\n",
    "    config = ServerConfig(num_rounds=NUM_SERVER_ROUNDS)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# ============================\n",
    "# 📂 HELPERS\n",
    "# ============================\n",
    "\n",
    "def _inject_round(original_fn):\n",
    "    def wrapper(server_round, parameters, client_manager):\n",
    "        instructions = original_fn(server_round, parameters, client_manager)\n",
    "        for _, ins in instructions:\n",
    "            ins.config[\"server_round\"] = server_round\n",
    "        return instructions\n",
    "    return wrapper\n",
    "\n",
    "def _save_supertree_plot(root_node, round_number, feature_names=None, class_names=None):\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def add_node(node, parent=None, label=\"\"):\n",
    "        curr = str(node_id[0])\n",
    "        node_id[0] += 1\n",
    "\n",
    "        if node.is_leaf:\n",
    "            class_index = np.argmax(node.labels)\n",
    "            class_label = class_names[class_index] if class_names else f\"Clase {class_index}\"\n",
    "            label_text = f\"Clase: {class_label}\\n{node.labels}\"\n",
    "        else:\n",
    "            fname = f\"X_{node.feat}\" if feature_names is None else feature_names[node.feat]\n",
    "            label_text = f\"{fname}\"\n",
    "\n",
    "        dot.node(curr, label_text)\n",
    "\n",
    "        if parent:\n",
    "            dot.edge(parent, curr, label=label)\n",
    "\n",
    "        if not node.is_leaf:\n",
    "            for i, child in enumerate(node.children):\n",
    "                thr_label = f\"<= {node.intervals[i]:.2f}\" if i == 0 else f\"> {node.intervals[i - 1]:.2f}\"\n",
    "                add_node(child, curr, thr_label)\n",
    "\n",
    "    add_node(root_node)\n",
    "    filename = f\"supertree_ronda_{round_number}\"\n",
    "    dot.render(filename, format=\"png\", cleanup=True)\n",
    "    print(f\"[SERVIDOR] ✅ SuperTree guardado como '{filename}.png'\")\n",
    "\n",
    "# ============================\n",
    "# 🔧 INICIALIZAR SERVER APP\n",
    "# ============================\n",
    "server_app = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pasos que se realizan en el notebook:**\n",
    "\n",
    "1. El servidor inicializa el modelo y lo envía a cada uno de los clientes.\n",
    "\n",
    "2. Cada cliente entrena un RandomForest con su respectivo subconjunto de datos o partición que hemos realizado al principio.\n",
    "\n",
    "3. Los clientes entrenan, y mandan sus hiperparámetros (Nº de árboles, profundidad, etc.) al servidor.\n",
    "\n",
    "4. El servidor combina los parámetros y actualiza el modelo global.\n",
    "\n",
    "5. Se mide el rendimiento del modelo sobre cada cliente, obteniendo también sus contrafactuales y se repite el proceso las rondas que deseemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutar la Simulación Federada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 09:53:16,264\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-04-02 09:53:19,901 flwr         DEBUG    Asyncio event loop already running.\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      ":job_id:01000000\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":job_id:01000000\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 1] 🌲 Árbol 1 guardado como 'tree_cliente_1_arbol_1_rondaServidor_1.png'\n",
      "[CLIENTE 2] 🌲 Árbol 1 guardado como 'tree_cliente_2_arbol_1_rondaServidor_1.png'\n",
      "[CLIENTE 1] 🌲 Árbol 2 guardado como 'tree_cliente_1_arbol_2_rondaServidor_1.png'\n",
      "[CLIENTE 2] 🌲 Árbol 2 guardado como 'tree_cliente_2_arbol_2_rondaServidor_1.png'\n",
      "[CLIENTE 1] 🌲 Árbol 3 guardado como 'tree_cliente_1_arbol_3_rondaServidor_1.png'\n",
      "[CLIENTE 2] 🌲 Árbol 3 guardado como 'tree_cliente_2_arbol_3_rondaServidor_1.png'\n",
      "[CLIENTE 1] 🌲 Árbol 4 guardado como 'tree_cliente_1_arbol_4_rondaServidor_1.png'\n",
      "[CLIENTE 2] 🌲 Árbol 4 guardado como 'tree_cliente_2_arbol_4_rondaServidor_1.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 1] 🌲 Árbol 5 guardado como 'tree_cliente_1_arbol_5_rondaServidor_1.png'\n",
      "[CLIENTE 1] Árboles generados: 5\n",
      "[CLIENTE 1] ✅ Enviando árboles al servidor:\n",
      "[CLIENTE 2] 🌲 Árbol 5 guardado como 'tree_cliente_2_arbol_5_rondaServidor_1.png'\n",
      "[CLIENTE 2] Árboles generados: 5\n",
      "[CLIENTE 2] ✅ Enviando árboles al servidor:\n",
      "\n",
      "[SERVIDOR] 🌲 Generando SuperTree - Ronda 1\n",
      "[SERVIDOR] 📊 Total de árboles: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 09:54:17,184 graphviz.saving DEBUG    write lines to 'supertree_ronda_1'\n",
      "2025-04-02 09:54:17,188 graphviz.backend.execute DEBUG    run [WindowsPath('dot'), '-Kdot', '-Tpng', '-O', 'supertree_ronda_1']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Iniciando poda completa de SuperTree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 09:54:17,454 graphviz.rendering DEBUG    delete 'supertree_ronda_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVIDOR] ✅ SuperTree guardado como 'supertree_ronda_1.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 2] 🌲 Árbol 1 guardado como 'tree_cliente_2_arbol_1_rondaServidor_2.png'\n",
      "[CLIENTE 1] 🌲 Árbol 1 guardado como 'tree_cliente_1_arbol_1_rondaServidor_2.png'\n",
      "[CLIENTE 2] 🌲 Árbol 2 guardado como 'tree_cliente_2_arbol_2_rondaServidor_2.png'\n",
      "[CLIENTE 1] 🌲 Árbol 2 guardado como 'tree_cliente_1_arbol_2_rondaServidor_2.png'\n",
      "[CLIENTE 2] 🌲 Árbol 3 guardado como 'tree_cliente_2_arbol_3_rondaServidor_2.png'\n",
      "[CLIENTE 1] 🌲 Árbol 3 guardado como 'tree_cliente_1_arbol_3_rondaServidor_2.png'\n",
      "[CLIENTE 2] 🌲 Árbol 4 guardado como 'tree_cliente_2_arbol_4_rondaServidor_2.png'\n",
      "[CLIENTE 1] 🌲 Árbol 4 guardado como 'tree_cliente_1_arbol_4_rondaServidor_2.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 2] 🌲 Árbol 5 guardado como 'tree_cliente_2_arbol_5_rondaServidor_2.png'\n",
      "[CLIENTE 2] Árboles generados: 5\n",
      "[CLIENTE 2] ✅ Enviando árboles al servidor:\n",
      "[CLIENTE 1] 🌲 Árbol 5 guardado como 'tree_cliente_1_arbol_5_rondaServidor_2.png'\n",
      "[CLIENTE 1] Árboles generados: 5\n",
      "[CLIENTE 1] ✅ Enviando árboles al servidor:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 09:55:24,790 graphviz.saving DEBUG    write lines to 'supertree_ronda_2'\n",
      "2025-04-02 09:55:24,792 graphviz.backend.execute DEBUG    run [WindowsPath('dot'), '-Kdot', '-Tpng', '-O', 'supertree_ronda_2']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SERVIDOR] 🌲 Generando SuperTree - Ronda 2\n",
      "[SERVIDOR] 📊 Total de árboles: 10\n",
      "🔧 Iniciando poda completa de SuperTree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 09:55:25,320 graphviz.rendering DEBUG    delete 'supertree_ronda_2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVIDOR] ✅ SuperTree guardado como 'supertree_ronda_2.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 2 round(s) in 135.40s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 2.220446049250313e-16\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 2.220446049250313e-16\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'AUC': [(1, 1.0), (2, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Accuracy': [(1, 1.0), (2, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'F1_Score': [(1, 1.0), (2, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Precision': [(1, 1.0), (2, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Recall': [(1, 1.0), (2, 1.0)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n"
     ]
    }
   ],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "import logging\n",
    "import warnings\n",
    "import ray\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger(\"filelock\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"ray\").setLevel(logging.WARNING)\n",
    "# logging.getLogger(\"flwr\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()  # Apagar cualquier sesión previa de Ray\n",
    "ray.init(local_mode=True)  # Desactiva multiprocessing, usa un solo proceso principal\n",
    "\n",
    "backend_config = {\"num_cpus\": 1}\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
