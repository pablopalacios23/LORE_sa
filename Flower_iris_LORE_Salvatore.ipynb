{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 13:19:17,916\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr_datasets\\utils.py:109: UserWarning: The currently tested dataset are ['mnist', 'ylecun/mnist', 'cifar10', 'uoft-cs/cifar10', 'fashion_mnist', 'zalando-datasets/fashion_mnist', 'sasha/dog-food', 'zh-plus/tiny-imagenet', 'scikit-learn/adult-census-income', 'cifar100', 'uoft-cs/cifar100', 'svhn', 'ufldl-stanford/svhn', 'sentiment140', 'stanfordnlp/sentiment140', 'speech_commands', 'LIUM/tedlium', 'flwrlabs/femnist', 'flwrlabs/ucf101', 'flwrlabs/ambient-acoustic-context', 'jlh/uci-mushrooms', 'Mike0307/MNIST-M', 'flwrlabs/usps', 'scikit-learn/iris', 'flwrlabs/pacs', 'flwrlabs/cinic10', 'flwrlabs/caltech101', 'flwrlabs/office-home', 'flwrlabs/fed-isic2019']. Given: hitorilabs/iris.\n",
      "  warnings.warn(\n",
      "2025-03-10 13:19:22,580 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-10 13:19:22,777 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-10 13:19:23,128 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-10 13:19:23,128 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-03-10 13:19:23,428 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-10 13:19:23,694 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1868\n",
      "2025-03-10 13:19:23,814 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-10 13:19:23,814 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-03-10 13:19:24,052 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-10 13:19:24,185 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-10 13:19:24,324 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae?recursive=False&expand=False HTTP/11\" 200 291\n",
      "2025-03-10 13:19:24,464 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-10 13:19:24,609 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae/data?recursive=False&expand=False HTTP/11\" 200 249\n",
      "2025-03-10 13:19:24,609 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-10 13:19:24,765 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-10 13:19:24,925 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-10 13:19:25,058 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-10 13:19:25,077 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-10 13:19:25,274 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-10 13:19:25,274 filelock     DEBUG    Attempting to acquire lock 1708717970912 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_hitorilabs___iris_default_0.0.0_fa62476c42edcf9259f895f43da1a7bf9e2697ae.lock\n",
      "2025-03-10 13:19:25,290 filelock     DEBUG    Lock 1708717970912 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_hitorilabs___iris_default_0.0.0_fa62476c42edcf9259f895f43da1a7bf9e2697ae.lock\n",
      "2025-03-10 13:19:25,290 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-10 13:19:25,303 filelock     DEBUG    Attempting to release lock 1708717970912 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_hitorilabs___iris_default_0.0.0_fa62476c42edcf9259f895f43da1a7bf9e2697ae.lock\n",
      "2025-03-10 13:19:25,303 filelock     DEBUG    Lock 1708717970912 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_hitorilabs___iris_default_0.0.0_fa62476c42edcf9259f895f43da1a7bf9e2697ae.lock\n",
      "2025-03-10 13:19:25,363 filelock     DEBUG    Attempting to acquire lock 1708717046432 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\hitorilabs___iris\\default\\0.0.0\\fa62476c42edcf9259f895f43da1a7bf9e2697ae_builder.lock\n",
      "2025-03-10 13:19:25,363 filelock     DEBUG    Lock 1708717046432 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\hitorilabs___iris\\default\\0.0.0\\fa62476c42edcf9259f895f43da1a7bf9e2697ae_builder.lock\n",
      "2025-03-10 13:19:25,363 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-10 13:19:25,363 filelock     DEBUG    Attempting to release lock 1708717046432 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\hitorilabs___iris\\default\\0.0.0\\fa62476c42edcf9259f895f43da1a7bf9e2697ae_builder.lock\n",
      "2025-03-10 13:19:25,376 filelock     DEBUG    Lock 1708717046432 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\hitorilabs___iris\\default\\0.0.0\\fa62476c42edcf9259f895f43da1a7bf9e2697ae_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE_LABELS: ['Versicolor', 'Virginica', 'Setosa']\n",
      "FEATURES: ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
      "\n",
      " Contenido del TabularDataset:\n",
      "   petal_length  petal_width  sepal_length  sepal_width      target\n",
      "0           4.8          1.8           5.9          3.2  Versicolor\n",
      "1           3.5          1.0           5.7          2.6  Versicolor\n",
      "2           5.6          1.4           6.1          2.6   Virginica\n",
      "3           1.5          0.2           4.6          3.1      Setosa\n",
      "4           4.9          1.8           6.3          2.7   Virginica\n",
      "\n",
      " Descriptor del TabularDataset:\n",
      "{'numeric': {'petal_length': {'index': 0, 'min': 1.100000023841858, 'max': 6.699999809265137, 'mean': 3.9026663, 'std': 1.7214837074279785, 'median': 4.5, 'q1': 1.7000000476837158, 'q3': 5.099999904632568}, 'petal_width': {'index': 1, 'min': 0.10000000149011612, 'max': 2.5, 'mean': 1.228, 'std': 0.7334774732589722, 'median': 1.399999976158142, 'q1': 0.3500000089406967, 'q3': 1.7999999523162842}, 'sepal_length': {'index': 2, 'min': 4.300000190734863, 'max': 7.900000095367432, 'mean': 5.910667, 'std': 0.8623621463775635, 'median': 5.900000095367432, 'q1': 5.1499998569488525, 'q3': 6.450000047683716}, 'sepal_width': {'index': 3, 'min': 2.200000047683716, 'max': 4.199999809265137, 'mean': 3.0146666, 'std': 0.4056004583835602, 'median': 3.0, 'q1': 2.700000047683716, 'q3': 3.25}}, 'categorical': {}, 'ordinal': {}, 'target': {'target': {'index': 4, 'distinct_values': ['Versicolor', 'Virginica', 'Setosa'], 'count': {'Versicolor': 29, 'Virginica': 24, 'Setosa': 22}}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from flwr.common import NDArrays\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from typing import List\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lore_sa.dataset import TabularDataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# This information is needed to create a correct scikit-learn model\n",
    "UNIQUE_LABELS = []\n",
    "FEATURES = []\n",
    "NUM_SERVER_ROUNDS = 5\n",
    "NUM_CLIENTS = 2\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "fds = None  # Cache FederatedDataset\n",
    "\n",
    "def get_model_parameters(model):\n",
    "    \"\"\"Obtener los par√°metros del modelo de manera segura.\"\"\"\n",
    "    params = [\n",
    "        max(1, int(model.n_estimators)),  # Asegurar que `n_estimators ‚â• 1`\n",
    "        int(model.max_depth) if model.max_depth is not None else -1,  # Convertir `None` en `-1`\n",
    "        max(2, int(model.min_samples_split)),  # Asegurar que min_samples_split ‚â• 2\n",
    "        max(1, int(model.min_samples_leaf)),  # Asegurar que min_samples_leaf ‚â• 1\n",
    "    ]\n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_model_params(model, params):\n",
    "    \"\"\"Asegurar que los par√°metros son v√°lidos antes de asignarlos.\"\"\"\n",
    "    n_estimators_value = max(1, int(params[0]))  # Si `n_estimators=0`, convertirlo a `1`\n",
    "    max_depth_value = int(params[1]) if int(params[1]) > 0 else None  # Convertir `0` en `None`\n",
    "    min_samples_split_value = max(2, int(params[2]))  # Si `min_samples_split=0`, convertirlo a `2`\n",
    "    min_samples_leaf_value = max(1, int(params[3]))  # Si `min_samples_leaf=0`, convertirlo a `1`\n",
    "\n",
    "    model.set_params(\n",
    "        n_estimators=n_estimators_value,  # Corregido `n_estimators`\n",
    "        max_depth=max_depth_value,  # Corregido `max_depth`\n",
    "        min_samples_split=min_samples_split_value,  # Asegurar que min_samples_split ‚â• 2\n",
    "        min_samples_leaf=min_samples_leaf_value,  # Asegurar que min_samples_leaf ‚â• 1\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_rand_forest_and_instantiate_parameters():\n",
    "    \"\"\"Crea un RandomForestClassifier con los par√°metros iniciales.\"\"\"\n",
    "    return RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        criterion='entropy',\n",
    "        n_estimators=100,\n",
    "        max_depth=40,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def load_data(partition_id: int, num_partitions: int):\n",
    "    \"\"\"Carga los datos del dataset, inicializa UNIQUE_LABELS y FEATURES, y divide en train/test.\"\"\"\n",
    "    global fds, UNIQUE_LABELS, FEATURES\n",
    "\n",
    "    if fds is None:\n",
    "        partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "        fds = FederatedDataset(dataset=\"hitorilabs/iris\", partitioners={\"train\": partitioner})\n",
    "\n",
    "    dataset = fds.load_partition(partition_id, \"train\").with_format(\"pandas\")[:]\n",
    "\n",
    "    # Convertir la columna objetivo a valores num√©ricos si es categ√≥rica\n",
    "    target_column = dataset.columns[-1]  \n",
    "\n",
    "    if dataset[target_column].dtype == \"object\":\n",
    "        label_encoder = LabelEncoder()\n",
    "        dataset[target_column] = label_encoder.fit_transform(dataset[target_column])\n",
    "\n",
    "    else:\n",
    "\n",
    "        dataset[target_column] = dataset[target_column].map({0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"})  # Revertir a nombres\n",
    "\n",
    "    dataset.rename(columns={target_column: \"target\"}, inplace=True)\n",
    "\n",
    "    # # Guardar nombres de caracter√≠sticas antes de convertir a num√©rico\n",
    "    # categorical_columns = dataset.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    # if categorical_columns:\n",
    "    #     dataset = pd.get_dummies(dataset, columns=categorical_columns) \n",
    "\n",
    "    dataset.rename(columns={target_column: \"target\"}, inplace=True)\n",
    "\n",
    "    # Guardar etiquetas √∫nicas y nombres de caracter√≠sticas\n",
    "    if not UNIQUE_LABELS:\n",
    "        UNIQUE_LABELS = dataset[\"target\"].unique().tolist()\n",
    "\n",
    "    if not FEATURES:\n",
    "        FEATURES = dataset.drop(columns=[\"target\"]).columns.tolist()\n",
    "\n",
    "    # Convertir dataset a formato compatible con LORE\n",
    "    tabular_dataset = TabularDataset(dataset, \"target\")\n",
    "\n",
    "    # Dividir en train/test (80% train - 20% test)\n",
    "    X = dataset[FEATURES]\n",
    "    y = dataset[\"target\"]\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    # Devolvemos dataset completo para que LORE pueda acceder a los nombres de las columnas\n",
    "    return X_train, y_train, X_test, y_test, tabular_dataset\n",
    "\n",
    "\n",
    "# Cargar datos e inicializar variables autom√°ticamente\n",
    "X_train, y_train, X_test, y_test, dataset = load_data(partition_id=0, num_partitions=NUM_CLIENTS)\n",
    "\n",
    "print(\"UNIQUE_LABELS:\", UNIQUE_LABELS)\n",
    "print(\"FEATURES:\", FEATURES)\n",
    "\n",
    "# Imprimir los datos reales en el `TabularDataset`\n",
    "print(\"\\n Contenido del TabularDataset:\")\n",
    "print(dataset.df.head())  # Muestra las primeras filas del dataset\n",
    "\n",
    "# Imprimir el descriptor del dataset (informaci√≥n sobre las variables)\n",
    "print(\"\\n Descriptor del TabularDataset:\")\n",
    "print(dataset.descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir el cliente federado con Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"sklearnexample: A Flower / sklearn app.\"\"\"\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from flwr.common import Context\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys  # Para forzar la impresi√≥n en consola sin demoras\n",
    "from threading import Lock\n",
    "import random\n",
    "\n",
    "# NUEVO: Importar LORE\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularRandomGeneratorLore\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, client_id):\n",
    "    \"\"\"Plotea y muestra la matriz de confusi√≥n.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"[CLIENTE {client_id}] üìä MATRIZ DE CONFUSI√ìN\")\n",
    "    print(\"-\"*100)\n",
    "    print(cm)\n",
    "    print(\"-\"*100)\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, model, X_train, y_train, X_test, y_test, dataset, client_id):\n",
    "        self.model = model\n",
    "        self.X_train = X_train.values\n",
    "        self.y_train = y_train.values\n",
    "        self.X_test = X_test.values\n",
    "        self.y_test = y_test.values\n",
    "        self.dataset = dataset  # Guardamos dataset completo para LORE\n",
    "        self.unique_labels = np.unique(y_train)  # Asegurar etiquetas correctas\n",
    "        self.client_id = client_id  # üîπ Usamos el partition_id como ID fijo\n",
    "\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Entrenar el modelo antes de cada actualizaci√≥n.\"\"\"\n",
    "        set_model_params(self.model, parameters)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        return get_model_parameters(self.model), len(self.X_train), {}\n",
    "    \n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluar el modelo y aplicar LORE para explicabilidad.\"\"\"\n",
    "        set_model_params(self.model, parameters)\n",
    "\n",
    "        if not hasattr(self.model, \"estimators_\") or len(self.model.estimators_) == 0:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        y_pred_proba = self.model.predict_proba(self.X_test)\n",
    "\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred, average='weighted', zero_division=1)\n",
    "        recall = recall_score(self.y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(self.y_test, y_pred, average='weighted')\n",
    "        auc = roc_auc_score(self.y_test, y_pred_proba, multi_class='ovr')\n",
    "        loss = log_loss(self.y_test, y_pred_proba)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"[CLIENTE {self.client_id}] üîç INICIO DE EVALUACI√ìN\")\n",
    "        print(\"=\"*100)\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # **Matriz de Confusi√≥n**\n",
    "        plot_confusion_matrix(self.y_test, y_pred, labels=self.unique_labels, client_id=self.client_id)\n",
    "\n",
    "        # **Aplicar LORE**\n",
    "        print(f\"\\n[CLIENTE {self.client_id}] üîç Aplicando LORE para explicabilidad...\")\n",
    "        print(\"=\" * 100)\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Convertimos el modelo en \"caja negra\" para LORE\n",
    "        bbox = sklearn_classifier_bbox.sklearnBBox(self.model)\n",
    "\n",
    "        # Seleccionamos una muestra de prueba del dataset para explicar\n",
    "        num_row = random.randint(0, len(self.dataset.df) - 1)  # Se puede cambiar para seleccionar una muestra espec√≠fica, en cada ronda se elegir√° una muestra aleatoria\n",
    "        x = self.dataset.df.iloc[num_row, :-1]  # Excluir la variable objetivo\n",
    "\n",
    "        # Aplicamos LORE para generar la explicaci√≥n\n",
    "        tabularLore = TabularRandomGeneratorLore(bbox, self.dataset)\n",
    "        explanation = tabularLore.explain(x)\n",
    "\n",
    "        # Obtener la predicci√≥n real del modelo\n",
    "        predicted_class = self.model.predict([x])[0]  # `x` es la muestra que estamos explicando\n",
    "        \n",
    "        # Mostramos la explicaci√≥n\n",
    "        print(f\"\\n[CLIENTE {self.client_id}] üìå EXPLICACI√ìN DEL CLIENTE:\\n\")\n",
    "        print(format_explanation(explanation, predicted_class, self.model, self.dataset))\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(3)  # Pausa para evitar solapamientos\n",
    "\n",
    "        return float(loss), len(self.X_test), {\n",
    "            \"Accuracy\": float(accuracy),\n",
    "            \"Precision\": float(precision),\n",
    "            \"Recall\": float(recall),\n",
    "            \"F1_Score\": float(f1),\n",
    "            \"AUC\": float(auc)\n",
    "        }\n",
    "\n",
    "def format_explanation(explanation, predicted_class, model, dataset):\n",
    "    \"\"\"Formatea la explicaci√≥n de LORE incluyendo la predicci√≥n y las clases en los contrafactuales.\"\"\"\n",
    "    result = \"\\n\" + \"=\"*50 + \"\\n\"\n",
    "    result += \"üìå EXPLICACI√ìN DEL MODELO\\n\"\n",
    "    result += \"=\"*50 + \"\\n\\n\"\n",
    "    \n",
    "    # Mostrar la predicci√≥n realizada\n",
    "    result += f\"üéØ **Predicci√≥n realizada:** {predicted_class}\\n\\n\"\n",
    "\n",
    "    rule = explanation['rule']\n",
    "    result += \"‚úÖ **Condiciones para la predicci√≥n:**\\n\"\n",
    "    for condition in rule['premises']:\n",
    "        attr = condition['attr'].replace(\"-\", \" \").capitalize()\n",
    "        val = condition['val']\n",
    "        op = condition['op']\n",
    "        op_text = {\"<=\": \"‚â§\", \">=\": \"‚â•\", \"!=\": \"NO es\"}.get(op, op)\n",
    "        result += f\"  - {attr} {op_text} {val}\\n\"\n",
    "    \n",
    "    result += \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "    result += \"üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\\n\"\n",
    "    result += \"-\"*50 + \"\\n\\n\"\n",
    "\n",
    "    for idx, cf in enumerate(explanation['counterfactuals'], start=1):\n",
    "        # Aplicamos los cambios del caso contrafactual a la muestra original\n",
    "        x_cf = dataset.df.iloc[10, :-1].copy()\n",
    "        for condition in cf['premises']:\n",
    "            attr = condition['attr']\n",
    "            val = condition['val']\n",
    "            x_cf[attr] = val  # Aplicamos los cambios\n",
    "\n",
    "        # Usamos el modelo para predecir la nueva clase tras el cambio\n",
    "        counterfactual_class = model.predict([x_cf.values])[0] \n",
    "\n",
    "        if counterfactual_class == predicted_class:\n",
    "            result += f\"üõë **CASO {idx}:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **{predicted_class}**\\n\"\n",
    "        else:\n",
    "            result += f\"üõë **CASO {idx}:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **{counterfactual_class}**\\n\"\n",
    "\n",
    "        for condition in cf['premises']:\n",
    "            attr = condition['attr'].replace(\"-\", \" \").capitalize()\n",
    "            val = condition['val']\n",
    "            op = condition['op']\n",
    "            op_text = {\"<=\": \"‚â§\", \">=\": \"‚â•\", \"!=\": \"NO es\"}.get(op, op)\n",
    "            result += f\"  - {attr} {op_text} {val}\\n\"\n",
    "        result += \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "\n",
    "    return result\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    \"\"\"Construir un cliente Flower asegurando que los datos est√©n cargados correctamente.\"\"\"\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    # Cargar datos correctamente\n",
    "    X_train, y_train, X_test, y_test, dataset = load_data(partition_id, num_partitions)\n",
    "\n",
    "    # Crear modelo RandomForest\n",
    "    model = create_rand_forest_and_instantiate_parameters()\n",
    "\n",
    "    return FlowerClient(model, X_train, y_train, X_test, y_test, dataset, client_id=partition_id + 1).to_client()\n",
    "\n",
    "# üöÄ Crear la aplicaci√≥n cliente de Flower\n",
    "client_app = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurar el Servidor de Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"sklearnexample: A Flower / sklearn app.\"\"\"\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from flwr.common import Context, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Dict[str, Scalar]:\n",
    "    \"\"\"Compute weighted average.\n",
    "\n",
    "    It is a generic implementation that averages only over floats and ints and drops the\n",
    "    other data types of the Metrics.\n",
    "    \"\"\"\n",
    "    # num_samples_list can represent the number of samples\n",
    "    # or the number of batches depending on the client\n",
    "    num_samples_list = [n_batches for n_batches, _ in metrics]\n",
    "    num_samples_sum = sum(num_samples_list)\n",
    "    metrics_lists: Dict[str, List[float]] = {}\n",
    "    for num_samples, all_metrics_dict in metrics:\n",
    "        #  Calculate each metric one by one\n",
    "        for single_metric, value in all_metrics_dict.items():\n",
    "            if isinstance(value, (float, int)):\n",
    "                metrics_lists[single_metric] = []\n",
    "        # Just one iteration needed to initialize the keywords\n",
    "        break\n",
    "\n",
    "    for num_samples, all_metrics_dict in metrics:\n",
    "        # Calculate each metric one by one\n",
    "        for single_metric, value in all_metrics_dict.items():\n",
    "            # Add weighted metric\n",
    "            if isinstance(value, (float, int)):\n",
    "                metrics_lists[single_metric].append(float(num_samples * value))\n",
    "\n",
    "    weighted_metrics: Dict[str, Scalar] = {}\n",
    "    for metric_name, metric_values in metrics_lists.items():\n",
    "        weighted_metrics[metric_name] = sum(metric_values) / num_samples_sum\n",
    "\n",
    "    return weighted_metrics\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    \"\"\"Construct components that set the ServerApp behavior.\"\"\"\n",
    "\n",
    "    # penalty = context.run_config.get(\"penalty\", \"l1\")\n",
    "    model = create_rand_forest_and_instantiate_parameters()\n",
    "    ndarrays = get_model_parameters(model)\n",
    "    global_model_init = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    # Define the strategy\n",
    "    min_available_clients = context.run_config.get(\"min-available-clients\", MIN_AVAILABLE_CLIENTS)\n",
    "    strategy = FedAvg(\n",
    "        min_available_clients=min_available_clients,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        initial_parameters=global_model_init,\n",
    "    )\n",
    "    \n",
    "    # Guardamos la versi√≥n original de la funci√≥n de agregaci√≥n\n",
    "    original_aggregate_evaluate = strategy.aggregate_evaluate\n",
    "\n",
    "    def custom_aggregate_evaluate(server_round, results, failures):\n",
    "        \"\"\"Forzar espera antes de continuar con la siguiente ronda del servidor.\"\"\"\n",
    "        aggregated_metrics = original_aggregate_evaluate(server_round, results, failures)\n",
    "\n",
    "        # **Sincronizaci√≥n:** Esperar antes de iniciar la siguiente ronda\n",
    "        print(f\"\\n‚è≥ [SERVIDOR] Esperando 10 segundos antes de iniciar la siguiente ronda...\\n\")\n",
    "        time.sleep(10)  # A√±adimos una pausa antes de la siguiente ronda\n",
    "\n",
    "        return aggregated_metrics\n",
    "\n",
    "    # Sustituye la agregaci√≥n original por la personalizada (corrigiendo la recursi√≥n)\n",
    "    strategy.aggregate_evaluate = custom_aggregate_evaluate\n",
    "\n",
    "    num_rounds = context.run_config.get(\"num-server-rounds\", NUM_SERVER_ROUNDS)\n",
    "    config = ServerConfig(num_rounds=num_rounds)\n",
    "\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "# Create ServerApp\n",
    "server_app = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pasos que se realizan en el notebook:**\n",
    "\n",
    "1. El servidor inicializa el modelo y lo env√≠a a cada uno de los clientes.\n",
    "\n",
    "2. Cada cliente entrena un RandomForest con su respectivo subconjunto de datos o partici√≥n que hemos realizado al principio.\n",
    "\n",
    "3. Los clientes entrenan, y mandan sus hiperpar√°metros (N¬∫ de √°rboles, profundidad, etc.) al servidor.\n",
    "\n",
    "4. El servidor combina los par√°metros y actualiza el modelo global.\n",
    "\n",
    "5. Se mide el rendimiento del modelo sobre cada cliente, obteniendo tambi√©n sus contrafactuales y se repite el proceso las rondas que deseemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Fases del proceso en cada ronda**\n",
    "\n",
    "**1. El servidor inicia una nueva ronda `(ServerApp)`**\n",
    "\n",
    "- Llama a `server_fn()`, donde se inicializa la estrategia FedAvg con los par√°metros globales.\n",
    "\n",
    "- Llama a `configure_fit()`, que selecciona qu√© clientes participar√°n en la ronda.\n",
    "\n",
    "---\n",
    "\n",
    "**2. El servidor env√≠a los par√°metros a los clientes**\n",
    "\n",
    "- Llama a `client_fn(context)`, lo que crea un nuevo cliente (`FlowerClient`).\n",
    "\n",
    "- Dentro del cliente, se ejecuta:\n",
    "\n",
    "    ```python\n",
    "\n",
    "    set_model_params(self.model, parameters)  # Recibe los par√°metros globales\n",
    "\n",
    "    ```\n",
    "\n",
    "- Cada cliente actualiza su modelo local con los par√°metros del servidor.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**3. Cada cliente entrena su modelo en sus propios datos**\n",
    "\n",
    "- Se ejecuta fit() en FlowerClient, que llama a:\n",
    "    ```python\n",
    "\n",
    "    self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    ```\n",
    "\n",
    "- Se entrena un nuevo modelo con los datos locales de cada cliente.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**4. Los clientes env√≠an los par√°metros actualizados al servidor**\n",
    "\n",
    "- Despu√©s de entrenar, cada cliente ejecuta:\n",
    "    ```Python\n",
    "\n",
    "    return get_model_parameters(self.model), len(self.X_train), {}\n",
    "\n",
    "    ```\n",
    "- Los par√°metros del modelo local se devuelven al servidor.\n",
    "\n",
    "---\n",
    "\n",
    "**5. El servidor actualiza el modelo global con FedAvg**\n",
    "\n",
    "- Recibe los par√°metros de cada cliente.\n",
    "\n",
    "- Llama a: \n",
    "\n",
    "    ```python\n",
    "\n",
    "    strategy.aggregate_fit(server_round, results, failures)\n",
    "\n",
    "    ```\n",
    "\n",
    "- Se hace un promedio ponderado de los par√°metros recibidos.\n",
    "\n",
    "- Se actualizan los par√°metros globales del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**6. Cada cliente eval√∫a el modelo**\n",
    "\n",
    "- Se llama a `evaluate()` en `FlowerClient`, donde:\n",
    "\n",
    "    ```python\n",
    "\n",
    "    set_model_params(self.model, parameters)  # Recibe el modelo global actualizado\n",
    "\n",
    "    y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "    ```\n",
    "\n",
    "- Cada cliente eval√∫a el modelo con su conjunto de prueba.\n",
    "\n",
    "---\n",
    "\n",
    "**7. Los clientes env√≠an los resultados de la evaluaci√≥n al servidor**\n",
    "\n",
    "- Devuelven m√©tricas Accuracy, Precision, Recall, etc.\n",
    "\n",
    "- Se ejecuta en el servidor:\n",
    "\n",
    "    ```python\n",
    "\n",
    "    strategy.aggregate_evaluate(server_round, results, failures)\n",
    "\n",
    "    ```\n",
    "\n",
    "- Se obtiene la evaluaci√≥n global.\n",
    "\n",
    "---\n",
    "\n",
    "**8. Se espera antes de iniciar la siguiente ronda**\n",
    "\n",
    "- Se ejecuta el `custom_aggregate_evaluate` para hacer una pausa de 10 segundos antes de la siguiente ronda.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutar la Simulaci√≥n Federada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 13:13:05,386\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[4 0 0]\n",
      " [0 8 0]\n",
      " [0 0 3]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 1 6]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[CLIENTE 1] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 2] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 1] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Virginica\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_length ‚â§ 5.158425331115723\n",
      "  - Petal_length > 2.6255003213882446\n",
      "  - Sepal_length ‚â§ 6.8689398765563965\n",
      "  - Sepal_width > 2.833991527557373\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Virginica**\n",
      "  - Petal_length > 5.158425331115723\n",
      "  - Sepal_length > 4.651970148086548\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 2:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Setosa**\n",
      "  - Petal_length ‚â§ 2.6255003213882446\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 3:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Setosa**\n",
      "  - Petal_length ‚â§ 5.158425331115723\n",
      "  - Petal_length > 2.6255003213882446\n",
      "  - Sepal_length > 6.8689398765563965\n",
      "  - Petal_width ‚â§ 1.5435811281204224\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "[CLIENTE 2] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Virginica\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_width ‚â§ 0.7979415357112885\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Setosa**\n",
      "  - Petal_width > 0.7979415357112885\n",
      "  - Petal_length ‚â§ 4.5760838985443115\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ [SERVIDOR] Esperando 10 segundos antes de iniciar la siguiente ronda...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 1 6]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[4 0 0]\n",
      " [0 4 4]\n",
      " [0 0 3]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[CLIENTE 2] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 1] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 2] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Virginica\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_length ‚â§ 2.5453015565872192\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Virginica**\n",
      "  - Petal_length > 5.085720777511597\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 2:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Versicolor**\n",
      "  - Petal_length ‚â§ 4.7956788539886475\n",
      "  - Petal_length > 2.5453015565872192\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 3:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Versicolor**\n",
      "  - Petal_length ‚â§ 5.085720777511597\n",
      "  - Petal_length > 4.7956788539886475\n",
      "  - Sepal_length ‚â§ 6.952340602874756\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "[CLIENTE 1] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Setosa\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_length ‚â§ 4.8720057010650635\n",
      "  - Sepal_width > 3.6030008792877197\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Setosa**\n",
      "  - Petal_length ‚â§ 4.8720057010650635\n",
      "  - Sepal_width ‚â§ 2.756852388381958\n",
      "  - Sepal_length ‚â§ 5.443597793579102\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ [SERVIDOR] Esperando 10 segundos antes de iniciar la siguiente ronda...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[4 0 0]\n",
      " [0 7 1]\n",
      " [0 0 3]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[CLIENTE 1] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 2] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 2] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Setosa\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_width > 1.779465138912201\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Setosa**\n",
      "  - Petal_width ‚â§ 0.7932414710521698\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 2:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Setosa**\n",
      "  - Petal_width ‚â§ 1.779465138912201\n",
      "  - Petal_width > 0.7932414710521698\n",
      "  - Petal_length ‚â§ 5.412226915359497\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "[CLIENTE 1] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Setosa\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_length ‚â§ 4.736778736114502\n",
      "  - Petal_width > 0.6529271006584167\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Versicolor**\n",
      "  - Petal_length ‚â§ 4.736778736114502\n",
      "  - Petal_width ‚â§ 0.6529271006584167\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 2:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Versicolor**\n",
      "  - Petal_length > 4.736778736114502\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ [SERVIDOR] Esperando 10 segundos antes de iniciar la siguiente ronda...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[4 0 0]\n",
      " [1 4 3]\n",
      " [0 0 3]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[CLIENTE 1] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 2] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 1] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Versicolor\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_length ‚â§ 4.651082277297974\n",
      "  - Petal_length > 2.951871633529663\n",
      "  - Sepal_length ‚â§ 5.370950698852539\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Versicolor**\n",
      "  - Petal_length ‚â§ 4.651082277297974\n",
      "  - Sepal_length > 5.370950698852539\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 2:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Versicolor**\n",
      "  - Petal_length ‚â§ 2.951871633529663\n",
      "  - Sepal_length ‚â§ 5.370950698852539\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "[CLIENTE 2] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Versicolor\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_length > 2.5667777061462402\n",
      "  - Petal_width ‚â§ 1.4469894170761108\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Setosa**\n",
      "  - Petal_length > 2.5667777061462402\n",
      "  - Petal_width > 1.7341139912605286\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 2:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Setosa**\n",
      "  - Petal_length ‚â§ 2.5667777061462402\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ [SERVIDOR] Esperando 10 segundos antes de iniciar la siguiente ronda...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üîç INICIO DE EVALUACI√ìN\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 1] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[4 0 0]\n",
      " [0 8 0]\n",
      " [0 0 3]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "[CLIENTE 2] üìä MATRIZ DE CONFUSI√ìN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[CLIENTE 1] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 2] üîç Aplicando LORE para explicabilidad...\n",
      "====================================================================================================\n",
      "\n",
      "[CLIENTE 2] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Versicolor\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_length ‚â§ 3.001419425010681\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Virginica**\n",
      "  - Petal_length ‚â§ 4.895909309387207\n",
      "  - Petal_length > 4.7893226146698\n",
      "  - Sepal_length ‚â§ 5.9342942237854\n",
      "  - Sepal_length > 4.692183017730713\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 2:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Virginica**\n",
      "  - Petal_length ‚â§ 6.598191976547241\n",
      "  - Petal_length > 4.895909309387207\n",
      "  - Sepal_length > 4.674283504486084\n",
      "  - Sepal_width > 2.4307583570480347\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 3:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Versicolor**\n",
      "  - Petal_length ‚â§ 4.7893226146698\n",
      "  - Petal_length > 3.001419425010681\n",
      "  - Sepal_length > 4.692183017730713\n",
      "  - Petal_width > 0.18091244250535965\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 4:** Si se cumplen estas condiciones, la predicci√≥n NO cambiar√≠a de **Versicolor**\n",
      "  - Petal_length > 6.598191976547241\n",
      "  - Sepal_width ‚â§ 2.7738577127456665\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "[CLIENTE 1] üìå EXPLICACI√ìN DEL CLIENTE:\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìå EXPLICACI√ìN DEL MODELO\n",
      "==================================================\n",
      "\n",
      "üéØ **Predicci√≥n realizada:** Virginica\n",
      "\n",
      "‚úÖ **Condiciones para la predicci√≥n:**\n",
      "  - Petal_length ‚â§ 4.788024425506592\n",
      "  - Petal_width > 0.6871498823165894\n",
      "  - Sepal_width > 2.4253560304641724\n",
      "\n",
      "--------------------------------------------------\n",
      "üîÑ **Casos contrafactuales donde el modelo predice otra clase:**\n",
      "--------------------------------------------------\n",
      "\n",
      "üõë **CASO 1:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Versicolor**\n",
      "  - Petal_length > 4.788024425506592\n",
      "  - Petal_width > 1.5501418113708496\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 2:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Setosa**\n",
      "  - Petal_length ‚â§ 4.788024425506592\n",
      "  - Petal_width ‚â§ 0.6871498823165894\n",
      "\n",
      "--------------------------------------------------\n",
      "üõë **CASO 3:** Si se cumplen estas condiciones, la predicci√≥n cambiar√≠a a **Versicolor**\n",
      "  - Petal_length ‚â§ 4.788024425506592\n",
      "  - Petal_width > 1.4919059872627258\n",
      "  - Sepal_width ‚â§ 2.4253560304641724\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ [SERVIDOR] Esperando 10 segundos antes de iniciar la siguiente ronda...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 101.57s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.2014551129705717\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 6.007275564852859\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.2014551129705717\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 4.805820451882287\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 2.220446049250313e-16\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'AUC': [(1, 0.9816849816849818),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (2, 0.9122405372405373),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (3, 0.9826388888888888),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (4, 0.9299242424242424),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (5, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Accuracy': [(1, 0.9666666666666667),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.8333333333333334),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.9666666666666667),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.8666666666666667),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'F1_Score': [(1, 0.9687179487179487),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.8398290598290598),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.967936507936508),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.8629629629629629),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Precision': [(1, 0.9777777777777777),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (2, 0.9206349206349206),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (3, 0.975),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (4, 0.9233333333333333),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (5, 1.0)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Recall': [(1, 0.9666666666666667),\n",
      "\u001b[92mINFO \u001b[0m:      \t            (2, 0.8333333333333334),\n",
      "\u001b[92mINFO \u001b[0m:      \t            (3, 0.9666666666666667),\n",
      "\u001b[92mINFO \u001b[0m:      \t            (4, 0.8666666666666667),\n",
      "\u001b[92mINFO \u001b[0m:      \t            (5, 1.0)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n"
     ]
    }
   ],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import ray\n",
    "\n",
    "ray.shutdown()  # Apagar cualquier sesi√≥n previa de Ray\n",
    "ray.init(local_mode=True)  # Desactiva multiprocessing, usa un solo proceso principal\n",
    "\n",
    "backend_config = {\"num_cpus\": 1}\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
