{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 14:11:46,740 urllib3.connectionpool DEBUG    Resetting dropped connection: huggingface.co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 14:11:46,973 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:11:47,111 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:11:47,114 urllib3.connectionpool DEBUG    Resetting dropped connection: s3.amazonaws.com\n",
      "2025-03-31 14:11:47,451 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:11:47,598 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:11:47,602 urllib3.connectionpool DEBUG    Resetting dropped connection: datasets-server.huggingface.co\n",
      "2025-03-31 14:11:47,974 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:11:48,119 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:11:48,134 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:11:48,351 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:11:48,492 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:11:48,641 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:11:48,647 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:11:48,933 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:11:48,936 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:11:48,940 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE_LABELS: ['Versicolor', 'Virginica', 'Setosa']\n",
      "FEATURES: ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
      "\n",
      "Contenido del TabularDataset:\n",
      "   petal_length  petal_width  sepal_length  sepal_width      target\n",
      "0           4.8          1.8           5.9          3.2  Versicolor\n",
      "1           3.5          1.0           5.7          2.6  Versicolor\n",
      "2           5.6          1.4           6.1          2.6   Virginica\n",
      "3           1.5          0.2           4.6          3.1      Setosa\n",
      "4           4.9          1.8           6.3          2.7   Virginica\n",
      "\n",
      "Descriptor del TabularDataset:\n",
      "{'numeric': {'petal_length': {'index': 0, 'min': 1.100000023841858, 'max': 6.699999809265137, 'mean': 3.9026663, 'std': 1.7214837074279785, 'median': 4.5, 'q1': 1.7000000476837158, 'q3': 5.099999904632568}, 'petal_width': {'index': 1, 'min': 0.10000000149011612, 'max': 2.5, 'mean': 1.228, 'std': 0.7334774732589722, 'median': 1.399999976158142, 'q1': 0.3500000089406967, 'q3': 1.7999999523162842}, 'sepal_length': {'index': 2, 'min': 4.300000190734863, 'max': 7.900000095367432, 'mean': 5.910667, 'std': 0.8623621463775635, 'median': 5.900000095367432, 'q1': 5.1499998569488525, 'q3': 6.450000047683716}, 'sepal_width': {'index': 3, 'min': 2.200000047683716, 'max': 4.199999809265137, 'mean': 3.0146666, 'std': 0.4056004583835602, 'median': 3.0, 'q1': 2.700000047683716, 'q3': 3.25}}, 'categorical': {}, 'ordinal': {}, 'target': {'target': {'index': 4, 'distinct_values': ['Versicolor', 'Virginica', 'Setosa'], 'count': {'Versicolor': 29, 'Virginica': 24, 'Setosa': 22}}}}\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# üì¶ IMPORTACIONES\n",
    "# =======================\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score, \n",
    "    f1_score, confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.common import Context, NDArrays, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "# =======================\n",
    "# ‚öôÔ∏è VARIABLES GLOBALES\n",
    "# =======================\n",
    "UNIQUE_LABELS = []\n",
    "FEATURES = []\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "NUM_CLIENTS = 2\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "fds = None  # Cache del FederatedDataset\n",
    "\n",
    "# =======================\n",
    "# üîß UTILIDADES MODELO\n",
    "# =======================\n",
    "\n",
    "def get_model_parameters(model):\n",
    "    p = model.get_params()\n",
    "    return [\n",
    "        int(p[\"max_depth\"]) if p[\"max_depth\"] is not None else -1,\n",
    "        int(p[\"min_samples_split\"]),\n",
    "        int(p[\"min_samples_leaf\"]),\n",
    "    ]\n",
    "\n",
    "def set_model_params(model, params):\n",
    "    max_depth = int(params[0].item()) if hasattr(params[0], \"item\") else int(params[0])\n",
    "    min_samples_split = max(2, int(params[1].item()) if hasattr(params[1], \"item\") else int(params[1]))\n",
    "    min_samples_leaf = max(1, int(params[2].item()) if hasattr(params[2], \"item\") else int(params[2]))\n",
    "\n",
    "    model.set_params(\n",
    "        max_depth=max_depth if max_depth > 0 else None,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "    )\n",
    "# =======================\n",
    "# üå≤ VISUALIZAR SUPERTREE\n",
    "# =======================\n",
    "\n",
    "def visualize_supertree(tree, feature_names=None, class_names=None, filename=\"supertree\"):\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def add_node(node, parent_id=None, edge_label=''):\n",
    "        curr_id = str(node_id[0])\n",
    "        node_id[0] += 1\n",
    "\n",
    "        if node.is_leaf:\n",
    "            class_index = np.argmax(node.labels)\n",
    "            class_label = class_names[class_index] if class_names else f\"class {class_index}\"\n",
    "            label = f\"class: {class_label}\\n{node.labels}\"\n",
    "        else:\n",
    "            fname = f\"X_{node.feat}\" if feature_names is None else feature_names[node.feat]\n",
    "            label = f\"{fname}\"\n",
    "\n",
    "        dot.node(curr_id, label)\n",
    "\n",
    "        if parent_id is not None:\n",
    "            dot.edge(parent_id, curr_id, label=edge_label)\n",
    "\n",
    "        if not node.is_leaf:\n",
    "            for i, child in enumerate(node.children):\n",
    "                label = f\"<= {node.intervals[i]:.2f}\" if i == 0 else f\"> {node.intervals[i - 1]:.2f}\"\n",
    "                add_node(child, curr_id, label)\n",
    "\n",
    "    add_node(tree)\n",
    "    dot.render(filename, format='png', cleanup=True)\n",
    "    print(f\"[SERVIDOR] üå≤ SuperTree guardado como '{filename}.png'\")\n",
    "\n",
    "# =======================\n",
    "# üìÑ CONVERTIR √ÅRBOL EN TEXTO A NODO\n",
    "# =======================\n",
    "\n",
    "def from_text_representation(text: str) -> SuperTree.Node:\n",
    "    lines = [line.rstrip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    root = None\n",
    "    stack = []\n",
    "\n",
    "    for line in lines:\n",
    "        indent = len(line) - len(line.lstrip())\n",
    "        level = indent // 4\n",
    "        content = line.strip()\n",
    "\n",
    "        if \"class:\" in content:\n",
    "            class_info = content.split(\"class: \")[-1]\n",
    "            node = SuperTree.Node(is_leaf=True)\n",
    "            node.predicted_class = class_info\n",
    "        else:\n",
    "            feat, cond = content.split(\" <= \")\n",
    "            node = SuperTree.Node(is_leaf=False)\n",
    "            node.feature = feat.strip()\n",
    "            node.threshold = float(cond.strip())\n",
    "\n",
    "        while len(stack) > level:\n",
    "            stack.pop()\n",
    "\n",
    "        if stack:\n",
    "            stack[-1].children.append(node)\n",
    "        else:\n",
    "            root = node\n",
    "\n",
    "        stack.append(node)\n",
    "\n",
    "    return root\n",
    "\n",
    "SuperTree.Node.from_text_representation = staticmethod(from_text_representation)\n",
    "\n",
    "# =======================\n",
    "# üì• CARGAR DATOS\n",
    "# =======================\n",
    "\n",
    "def load_data(partition_id: int, num_partitions: int):\n",
    "    global fds, UNIQUE_LABELS, FEATURES\n",
    "\n",
    "    if fds is None:\n",
    "        partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "        fds = FederatedDataset(dataset=\"hitorilabs/iris\", partitioners={\"train\": partitioner})\n",
    "\n",
    "    dataset = fds.load_partition(partition_id, \"train\").with_format(\"pandas\")[:]\n",
    "    target_column = dataset.columns[-1]\n",
    "\n",
    "    if dataset[target_column].dtype == \"object\":\n",
    "        label_encoder = LabelEncoder()\n",
    "        dataset[target_column] = label_encoder.fit_transform(dataset[target_column])\n",
    "    else:\n",
    "        dataset[target_column] = dataset[target_column].map({0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"})\n",
    "\n",
    "    dataset.rename(columns={target_column: \"target\"}, inplace=True)\n",
    "\n",
    "    if not UNIQUE_LABELS:\n",
    "        UNIQUE_LABELS = dataset[\"target\"].unique().tolist()\n",
    "    if not FEATURES:\n",
    "        FEATURES = dataset.drop(columns=[\"target\"]).columns.tolist()\n",
    "\n",
    "    tabular_dataset = TabularDataset(dataset, \"target\")\n",
    "\n",
    "    # Train/Test split (80/20)\n",
    "    X = dataset[FEATURES]\n",
    "    y = dataset[\"target\"]\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, tabular_dataset\n",
    "\n",
    "# =======================\n",
    "# üß™ PRUEBA DE CARGA LOCAL (solo en ejecuci√≥n directa)\n",
    "# =======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, y_train, X_test, y_test, dataset = load_data(partition_id=0, num_partitions=NUM_CLIENTS)\n",
    "\n",
    "    print(\"UNIQUE_LABELS:\", UNIQUE_LABELS)\n",
    "    print(\"FEATURES:\", FEATURES)\n",
    "\n",
    "    print(\"\\nContenido del TabularDataset:\")\n",
    "    print(dataset.df.head())\n",
    "\n",
    "    print(\"\\nDescriptor del TabularDataset:\")\n",
    "    print(dataset.descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir el cliente federado con Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, model, X_train, y_train, X_test, y_test, dataset, client_id):\n",
    "        self.model = model\n",
    "        self.X_train = X_train.values\n",
    "        self.y_train = y_train.values\n",
    "        self.X_test = X_test.values\n",
    "        self.y_test = y_test.values\n",
    "        self.dataset = dataset\n",
    "        self.unique_labels = np.unique(y_train)\n",
    "        self.client_id = client_id\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_model_params(self.model, parameters)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        return get_model_parameters(self.model), len(self.X_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_model_params(self.model, parameters)\n",
    "\n",
    "        try:\n",
    "            _ = self.model.predict(self.X_test)\n",
    "        except NotFittedError:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        y_proba = self.model.predict_proba(self.X_test)\n",
    "\n",
    "        # üîÅ Generar √°rboles de LORE y exportarlos\n",
    "        bbox = sklearn_classifier_bbox.sklearnBBox(self.model)\n",
    "        lore = TabularGeneticGeneratorLore(bbox, self.dataset)\n",
    "        x = self.dataset.df.iloc[5][:-1]\n",
    "        lore.explain_instance(x)\n",
    "\n",
    "        ensemble_trees = []\n",
    "        for tree in lore.surrogate.trees:\n",
    "            node = SuperTree().rec_buildTree(tree, list(range(self.X_train.shape[1])))\n",
    "            ensemble_trees.append(node.to_dict())\n",
    "\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        self._save_lore_trees(lore.surrogate.trees, round_number)\n",
    "\n",
    "        return float(log_loss(self.y_test, y_proba)), len(self.X_test), {\n",
    "            \"Accuracy\": accuracy_score(self.y_test, y_pred),\n",
    "            \"Precision\": precision_score(self.y_test, y_pred, average=\"weighted\", zero_division=1),\n",
    "            \"Recall\": recall_score(self.y_test, y_pred, average=\"weighted\"),\n",
    "            \"F1_Score\": f1_score(self.y_test, y_pred, average=\"weighted\"),\n",
    "            \"AUC\": roc_auc_score(self.y_test, y_proba, multi_class=\"ovr\"),\n",
    "            \"tree_ensemble\": json.dumps(ensemble_trees),\n",
    "        }\n",
    "\n",
    "    def _save_lore_trees(self, trees, round_number):\n",
    "        for idx, tree in enumerate(trees):\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            plot_tree(\n",
    "                tree,\n",
    "                feature_names=self.dataset.df.columns[:-1],\n",
    "                class_names=np.unique(self.y_train).astype(str),\n",
    "                filled=True,\n",
    "                rounded=True,\n",
    "                ax=ax\n",
    "            )\n",
    "            filename = f\"tree_cliente_{self.client_id}_lore_{idx+1}_ronda_{round_number}.png\"\n",
    "            plt.title(f\"√Årbol {idx+1} - Cliente {self.client_id} - Ronda {round_number}\")\n",
    "            fig.savefig(filename)\n",
    "            plt.close(fig)\n",
    "            print(f\"[CLIENTE {self.client_id}] üå≤ √Årbol {idx+1} guardado como '{filename}'\")\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    return DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    X_train, y_train, X_test, y_test, dataset = load_data(partition_id, num_partitions)\n",
    "    model = create_model()\n",
    "    return FlowerClient(model, X_train, y_train, X_test, y_test, dataset, client_id=partition_id + 1).to_client()\n",
    "\n",
    "\n",
    "client_app = ClientApp(client_fn=client_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurar el Servidor de Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üì¶ IMPORTACIONES NECESARIAS\n",
    "# ============================\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from flwr.common import Context, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from graphviz import Digraph\n",
    "\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "\n",
    "# ============================\n",
    "# ‚öôÔ∏è CONFIGURACI√ìN GLOBAL\n",
    "# ============================\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "fds = None  # Dataset cache global\n",
    "\n",
    "# ============================\n",
    "# üß† MODELO Y UTILIDADES\n",
    "# ============================\n",
    "\n",
    "def create_model():\n",
    "    return DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "def get_model_parameters(model):\n",
    "    p = model.get_params()\n",
    "    return [p[\"max_depth\"] or -1, p[\"min_samples_split\"], p[\"min_samples_leaf\"]]\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Dict[str, Scalar]:\n",
    "    num_samples_list = [n for n, _ in metrics]\n",
    "    total = sum(num_samples_list)\n",
    "    metrics_agg: Dict[str, List[float]] = {}\n",
    "    for n, met in metrics:\n",
    "        for k, v in met.items():\n",
    "            if isinstance(v, (float, int)):\n",
    "                metrics_agg.setdefault(k, []).append(n * float(v))\n",
    "    return {k: sum(vs) / total for k, vs in metrics_agg.items()}\n",
    "\n",
    "# ============================\n",
    "# üöÄ SERVIDOR FLOWER\n",
    "# ============================\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    model = create_model()\n",
    "    initial_params = ndarrays_to_parameters(get_model_parameters(model))\n",
    "\n",
    "    strategy = FedAvg(\n",
    "        min_available_clients=MIN_AVAILABLE_CLIENTS,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        initial_parameters=initial_params,\n",
    "    )\n",
    "\n",
    "    strategy.configure_fit = _inject_round(strategy.configure_fit)\n",
    "    strategy.configure_evaluate = _inject_round(strategy.configure_evaluate)\n",
    "\n",
    "    original_aggregate = strategy.aggregate_evaluate\n",
    "\n",
    "    def custom_aggregate_evaluate(server_round, results, failures):\n",
    "        aggregated_metrics = original_aggregate(server_round, results, failures)\n",
    "\n",
    "        try:\n",
    "            print(f\"\\n[SERVIDOR] üå≤ Generando SuperTree - Ronda {server_round}\")\n",
    "            tree_dicts = []\n",
    "            total_arboles = 0\n",
    "\n",
    "            for client_idx, (_, metrics) in enumerate(results):\n",
    "                if isinstance(metrics, dict) and \"tree_ensemble\" in metrics:\n",
    "                    try:\n",
    "                        trees_list = json.loads(metrics[\"tree_ensemble\"])\n",
    "                        print(f\"[CLIENTE {client_idx+1}] üì¶ {len(trees_list)} √°rbol(es) recibido(s)\")\n",
    "                        total_arboles += len(trees_list)\n",
    "                        for tdict in trees_list:\n",
    "                            root = SuperTree.Node.from_dict(tdict)\n",
    "                            if root:\n",
    "                                tree_dicts.append(root)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[CLIENTE {client_idx+1}] ‚ùå Error al cargar √°rbol: {e}\")\n",
    "                        continue\n",
    "\n",
    "            print(f\"[SERVIDOR] üìä Total de √°rboles recibidos: {total_arboles}\")\n",
    "\n",
    "            if not tree_dicts:\n",
    "                print(\"[SERVIDOR] ‚ö†Ô∏è No se recibieron √°rboles. Se omite SuperTree.\")\n",
    "                return aggregated_metrics\n",
    "\n",
    "            supertree = SuperTree()\n",
    "            supertree.mergeDecisionTrees(tree_dicts, num_classes=3)\n",
    "            supertree.prune_redundant_leaves_full()\n",
    "            supertree.merge_equal_class_leaves()\n",
    "\n",
    "            _save_supertree_plot(supertree.root, server_round)\n",
    "\n",
    "            # üîç Regla y contraejemplos\n",
    "            from flwr_datasets import FederatedDataset\n",
    "            from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "            global fds\n",
    "            if fds is None:\n",
    "                fds = FederatedDataset(dataset=\"hitorilabs/iris\", partitioners={\"train\": IidPartitioner(num_partitions=2)})\n",
    "\n",
    "            sample_df = fds.load_partition(0, \"train\").with_format(\"pandas\")[:]\n",
    "            dataset = TabularDataset(sample_df, \"target\")\n",
    "            encoder = ColumnTransformerEnc(dataset.descriptor)\n",
    "\n",
    "            x = sample_df.iloc[5][:-1]\n",
    "            [z] = encoder.encode([x])\n",
    "            rule = supertree.get_rule(z, encoder)\n",
    "\n",
    "            neigh_X = sample_df.drop(columns=[\"target\"]).values\n",
    "            neigh_y_raw = sample_df[\"target\"].values\n",
    "            neigh_yb = encoder.encode_target_class(neigh_y_raw.reshape(-1, 1)).squeeze()\n",
    "            cf_rules, deltas = supertree.get_counterfactual_rules(z, neigh_X, neigh_yb, encoder)\n",
    "\n",
    "            print(\"\\nüìå Regla principal:\")\n",
    "            for cond in rule.premises:\n",
    "                print(f\" - {cond.variable} {cond.operator.__name__} {round(cond.value, 2)}\")\n",
    "            print(f\"=> {rule.consequences.variable} = {rule.consequences.value}\")\n",
    "\n",
    "            print(\"\\nüîÑ Counterfactuals:\")\n",
    "            for i, delta in enumerate(deltas):\n",
    "                print(f\"\\nüö´ Caso {i+1}:\")\n",
    "                for cond in delta:\n",
    "                    print(f\" - {cond.variable} {cond.operator.__name__} {round(cond.value, 2)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SERVIDOR] ‚ùå Error creando SuperTree o explicaci√≥n: {e}\")\n",
    "\n",
    "        print(f\"\\n‚è≥ Esperando 10 segundos antes de la siguiente ronda...\\n\")\n",
    "        time.sleep(10)\n",
    "        return aggregated_metrics\n",
    "\n",
    "    strategy.aggregate_evaluate = custom_aggregate_evaluate\n",
    "\n",
    "    config = ServerConfig(num_rounds=NUM_SERVER_ROUNDS)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# ============================\n",
    "# üóÇ HELPERS\n",
    "# ============================\n",
    "\n",
    "def _inject_round(original_fn):\n",
    "    def wrapper(server_round, parameters, client_manager):\n",
    "        instructions = original_fn(server_round, parameters, client_manager)\n",
    "        for _, ins in instructions:\n",
    "            ins.config[\"server_round\"] = server_round\n",
    "        return instructions\n",
    "    return wrapper\n",
    "\n",
    "def _save_supertree_plot(root_node, round_number):\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def add_node(node, parent=None, label=\"\"):\n",
    "        curr = str(node_id[0])\n",
    "        node_id[0] += 1\n",
    "        label_text = f\"Clase: {np.argmax(node.labels)}\\n{node.labels}\" if node.is_leaf else f\"X_{node.feat}\"\n",
    "        dot.node(curr, label_text)\n",
    "        if parent:\n",
    "            dot.edge(parent, curr, label=label)\n",
    "        if not node.is_leaf:\n",
    "            for i, child in enumerate(node.children):\n",
    "                thr_label = f\"<= {node.intervals[i]:.2f}\" if i == 0 else f\"> {node.intervals[i - 1]:.2f}\"\n",
    "                add_node(child, curr, thr_label)\n",
    "\n",
    "    add_node(root_node)\n",
    "    filename = f\"supertree_ronda_{round_number}\"\n",
    "    dot.render(filename, format=\"png\", cleanup=True)\n",
    "    print(f\"[SERVIDOR] ‚úÖ SuperTree guardado como '{filename}.png'\")\n",
    "\n",
    "# ============================\n",
    "# üîß INICIALIZAR SERVER APP\n",
    "# ============================\n",
    "server_app = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pasos que se realizan en el notebook:**\n",
    "\n",
    "1. El servidor inicializa el modelo y lo env√≠a a cada uno de los clientes.\n",
    "\n",
    "2. Cada cliente entrena un RandomForest con su respectivo subconjunto de datos o partici√≥n que hemos realizado al principio.\n",
    "\n",
    "3. Los clientes entrenan, y mandan sus hiperpar√°metros (N¬∫ de √°rboles, profundidad, etc.) al servidor.\n",
    "\n",
    "4. El servidor combina los par√°metros y actualiza el modelo global.\n",
    "\n",
    "5. Se mide el rendimiento del modelo sobre cada cliente, obteniendo tambi√©n sus contrafactuales y se repite el proceso las rondas que deseemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutar la Simulaci√≥n Federada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 14:11:54,071\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "2025-03-31 14:11:58,521 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:11:58,522 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 14:11:58,719 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:11:58,735 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:11:58,856 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:11:58,858 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-03-31 14:11:58,868 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:11:58,872 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-03-31 14:11:59,189 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:11:59,189 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:11:59,332 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:11:59,336 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:11:59,477 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:11:59,485 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-03-31 14:11:59,530 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:11:59,536 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-03-31 14:11:59,688 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:11:59,753 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:11:59,833 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:11:59,897 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:11:59,973 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae?recursive=False&expand=False HTTP/11\" 200 291\n",
      "2025-03-31 14:12:00,036 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae?recursive=False&expand=False HTTP/11\" 200 291\n",
      "2025-03-31 14:12:00,115 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:12:00,181 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:12:00,248 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae/data?recursive=False&expand=False HTTP/11\" 200 249\n",
      "2025-03-31 14:12:00,252 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:00,322 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae/data?recursive=False&expand=False HTTP/11\" 200 249\n",
      "2025-03-31 14:12:00,327 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:00,460 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:00,545 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:00,592 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:12:00,684 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:12:00,732 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:12:00,739 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:00,833 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:12:00,839 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:00,920 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:00,926 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:12:00,931 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:12:01,025 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:01,029 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:12:01,034 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "2025-03-31 14:12:01,250 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:01,252 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:01,441 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:12:01,477 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:12:01,582 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:12:01,584 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-03-31 14:12:01,656 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:12:01,660 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-03-31 14:12:01,895 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:12:01,970 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:12:02,047 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:02,117 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:02,184 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:12:02,187 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-03-31 14:12:02,305 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:12:02,314 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-03-31 14:12:02,529 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:12:02,656 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:12:02,672 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:02,788 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:02,806 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae?recursive=False&expand=False HTTP/11\" 200 291\n",
      "2025-03-31 14:12:02,943 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:12:03,085 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae/data?recursive=False&expand=False HTTP/11\" 200 249\n",
      "2025-03-31 14:12:03,090 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:03,293 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:03,296 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae?recursive=False&expand=False HTTP/11\" 200 291\n",
      "2025-03-31 14:12:03,445 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:12:03,447 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:12:03,582 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae/data?recursive=False&expand=False HTTP/11\" 200 249\n",
      "2025-03-31 14:12:03,587 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:03,719 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:12:03,724 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:03,923 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:03,926 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:12:03,929 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:12:03,965 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:04,255 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:12:04,548 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:12:04,664 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:12:05,144 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:12:05,405 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:12:05,833 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ merge_trees() fue llamado\n",
      "üîß Iniciando poda completa de SuperTree\n",
      "‚úÖ merge_trees() fue llamado\n",
      "üîß Iniciando poda completa de SuperTree\n",
      "‚úÖ merge_trees() fue llamado\n",
      "üîß Iniciando poda completa de SuperTree\n",
      "‚úÖ merge_trees() fue llamado\n",
      "üîß Iniciando poda completa de SuperTree\n",
      "[CLIENTE 2] üå≤ √Årbol 1 guardado como 'tree_cliente_2_lore_1_ronda_1.png'\n",
      "[CLIENTE 1] üå≤ √Årbol 1 guardado como 'tree_cliente_1_lore_1_ronda_1.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVIDOR] üå≤ Generando SuperTree - Ronda 1\n",
      "[SERVIDOR] ‚ö†Ô∏è No se recibieron √°rboles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 14:13:16,279 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:13:16,283 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:13:16,423 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:13:16,426 urllib3.connectionpool DEBUG    Resetting dropped connection: s3.amazonaws.com\n",
      "2025-03-31 14:13:16,427 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:13:16,432 urllib3.connectionpool DEBUG    Resetting dropped connection: s3.amazonaws.com\n",
      "2025-03-31 14:13:16,759 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:13:16,767 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:13:16,915 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:13:16,944 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:13:17,082 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:13:17,159 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:13:17,245 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:13:17,277 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:17,332 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:13:17,378 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:17,512 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:17,580 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:17,660 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:13:17,748 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:13:17,804 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:13:17,813 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:17,889 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:13:17,899 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:18,002 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:18,007 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:13:18,019 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:13:18,076 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:18,105 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:13:18,110 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "2025-03-31 14:13:18,261 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:18,398 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:13:18,441 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/main/README.md HTTP/11\" 200 0\n",
      "2025-03-31 14:13:18,536 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:13:18,538 urllib3.connectionpool DEBUG    Resetting dropped connection: s3.amazonaws.com\n",
      "2025-03-31 14:13:18,580 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:13:18,583 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-03-31 14:13:18,840 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:13:18,913 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/hitorilabs/iris/hitorilabs/iris.py HTTP/11\" 404 0\n",
      "2025-03-31 14:13:18,983 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:13:19,134 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:19,149 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:13:19,272 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-03-31 14:13:19,276 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-03-31 14:13:19,292 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:13:19,299 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:19,494 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:19,622 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=hitorilabs/iris HTTP/11\" 200 None\n",
      "2025-03-31 14:13:19,644 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:13:19,758 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:19,788 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:13:19,795 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:19,899 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae?recursive=False&expand=False HTTP/11\" 200 291\n",
      "2025-03-31 14:13:19,994 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:20,002 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:13:20,007 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:13:20,047 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:13:20,706 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/tree/fa62476c42edcf9259f895f43da1a7bf9e2697ae/data?recursive=False&expand=False HTTP/11\" 200 249\n",
      "2025-03-31 14:13:20,985 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:21,393 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:21,853 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/hitorilabs/iris/resolve/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-03-31 14:13:22,432 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/hitorilabs/iris/paths-info/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 281\n",
      "2025-03-31 14:13:22,496 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-03-31 14:13:22,805 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/hitorilabs/iris/revision/fa62476c42edcf9259f895f43da1a7bf9e2697ae HTTP/11\" 200 1884\n",
      "2025-03-31 14:13:23,123 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n",
      "2025-03-31 14:13:23,763 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/hitorilabs___iris/default/0.0.0/fa62476c42edcf9259f895f43da1a7bf9e2697ae/dataset_info.json\n"
     ]
    }
   ],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "import logging\n",
    "import warnings\n",
    "import ray\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger(\"filelock\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"ray\").setLevel(logging.WARNING)\n",
    "# logging.getLogger(\"flwr\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()  # Apagar cualquier sesi√≥n previa de Ray\n",
    "ray.init(local_mode=True)  # Desactiva multiprocessing, usa un solo proceso principal\n",
    "\n",
    "backend_config = {\"num_cpus\": 1}\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
