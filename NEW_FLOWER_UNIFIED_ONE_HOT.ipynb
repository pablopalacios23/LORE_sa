{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68391f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 12:50:18,793\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-06-30 12:50:21,907 graphviz._tools DEBUG    deprecate positional args: graphviz.backend.piping.pipe(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "2025-06-30 12:50:21,907 graphviz._tools DEBUG    deprecate positional args: graphviz.backend.rendering.render(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.backend.unflattening.unflatten(['stagger', 'fanout', 'chain', 'encoding'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.backend.viewing.view(['quiet'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.quoting.quote(['is_html_string', 'is_valid_id', 'dot_keywords', 'endswith_odd_number_of_backslashes', 'escape_unescaped_quotes'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.quoting.a_list(['kwargs', 'attributes'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.quoting.attr_list(['kwargs', 'attributes'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.clear(['keep_attrs'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.__iter__(['subgraph'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.node(['_attributes'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.edge(['_attributes'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.attr(['_attributes'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.dot.Dot.subgraph(['name', 'comment', 'graph_attr', 'node_attr', 'edge_attr', 'body'])\n",
      "2025-06-30 12:50:21,923 graphviz._tools DEBUG    deprecate positional args: graphviz.piping.Pipe._pipe_legacy(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "2025-06-30 12:50:21,939 graphviz._tools DEBUG    deprecate positional args: graphviz.saving.Save.save(['directory'])\n",
      "2025-06-30 12:50:21,939 graphviz._tools DEBUG    deprecate positional args: graphviz.rendering.Render.render(['directory', 'view', 'cleanup', 'format', 'renderer', 'formatter', 'neato_no_op', 'quiet', 'quiet_view'])\n",
      "2025-06-30 12:50:21,939 graphviz._tools DEBUG    deprecate positional args: graphviz.rendering.Render.view(['directory', 'cleanup', 'quiet', 'quiet_view'])\n",
      "2025-06-30 12:50:21,939 graphviz._tools DEBUG    deprecate positional args: graphviz.unflattening.Unflatten.unflatten(['stagger', 'fanout', 'chain'])\n",
      "2025-06-30 12:50:21,939 graphviz._tools DEBUG    deprecate positional args: graphviz.graphs.BaseGraph.__init__(['comment', 'filename', 'directory', 'format', 'engine', 'encoding', 'graph_attr', 'node_attr', 'edge_attr', 'body', 'strict'])\n",
      "2025-06-30 12:50:21,939 graphviz._tools DEBUG    deprecate positional args: graphviz.sources.Source.from_file(['directory', 'format', 'engine', 'encoding', 'renderer', 'formatter'])\n",
      "2025-06-30 12:50:21,939 graphviz._tools DEBUG    deprecate positional args: graphviz.sources.Source.__init__(['filename', 'directory', 'format', 'engine', 'encoding'])\n",
      "2025-06-30 12:50:21,939 graphviz._tools DEBUG    deprecate positional args: graphviz.sources.Source.save(['directory'])\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 📦 IMPORTACIONES\n",
    "# =======================\n",
    "\n",
    "# Built-in\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from typing import List, Tuple, Dict\n",
    "import operator\n",
    "\n",
    "# NumPy, Pandas, Matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, roc_auc_score, pairwise_distances\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from collections import defaultdict\n",
    "\n",
    "# Flower\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.common import (\n",
    "    Context, NDArrays, Metrics, Scalar,\n",
    "    ndarrays_to_parameters, parameters_to_ndarrays\n",
    ")\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# LORE\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "from lore_sa.rule import Expression, Rule\n",
    "\n",
    "# Otros\n",
    "from graphviz import Digraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41dd2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# ⚙️ VARIABLES GLOBALES\n",
    "# =======================\n",
    "UNIQUE_LABELS = []\n",
    "FEATURES = []\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "NUM_CLIENTS = 2\n",
    "MIN_AVAILABLE_CLIENTS = NUM_CLIENTS\n",
    "fds = None  # Cache del FederatedDataset\n",
    "CAT_ENCODINGS = {}\n",
    "USING_DATASET = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_dim = max(8, input_dim * 2)  # algo proporcional\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "\n",
    "class TorchNNWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            outputs = self.model(X_tensor)\n",
    "            return outputs.argmax(dim=1).numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            outputs = self.model(X_tensor)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            return probs.numpy()\n",
    "\n",
    "# =======================\n",
    "# 🔧 UTILIDADES MODELO\n",
    "# =======================\n",
    "\n",
    "def get_model_parameters(tree_model, nn_model):\n",
    "    tree_params = [\n",
    "        int(tree_model.get_params()[\"max_depth\"] or -1),\n",
    "        int(tree_model.get_params()[\"min_samples_split\"]),\n",
    "        int(tree_model.get_params()[\"min_samples_leaf\"]),\n",
    "    ]\n",
    "    nn_weights = [v.cpu().detach().numpy() for v in nn_model.state_dict().values()]\n",
    "    return {\n",
    "        \"tree\": tree_params,\n",
    "        \"nn\": nn_weights,\n",
    "    }\n",
    "\n",
    "\n",
    "def set_model_params(tree_model, nn_model, params):\n",
    "    tree_params = params[\"tree\"]\n",
    "    nn_weights = params[\"nn\"]\n",
    "\n",
    "    # Solo si tree_model no es None y tiene set_params\n",
    "    if tree_model is not None and hasattr(tree_model, \"set_params\"):\n",
    "        max_depth = tree_params[0] if tree_params[0] > 0 else None\n",
    "        tree_model.set_params(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=tree_params[1],\n",
    "            min_samples_leaf=tree_params[2],\n",
    "        )\n",
    "\n",
    "    # Actualizar pesos de la red neuronal\n",
    "    state_dict = nn_model.state_dict()\n",
    "    for (key, _), val in zip(state_dict.items(), nn_weights):\n",
    "        state_dict[key] = torch.tensor(val)\n",
    "    nn_model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 📥 CARGAR DATOS\n",
    "# =======================\n",
    "\n",
    "def load_data_general(flower_dataset_name: str, class_col: str, num_partitions: int):\n",
    "    global UNIQUE_LABELS, FEATURES\n",
    "\n",
    "    if \"csv\" in flower_dataset_name:\n",
    "        dataset = pd.read_csv(flower_dataset_name)\n",
    "    else:\n",
    "        from flwr_datasets import FederatedDataset\n",
    "        fds = FederatedDataset(dataset=flower_dataset_name, partitioners={\"train\": IidPartitioner(num_partitions=NUM_CLIENTS)})\n",
    "        dataset = fds.load_partition(0, \"train\").with_format(\"pandas\")[:]\n",
    "\n",
    "    # LIMPIEZA SEGÚN DATASET\n",
    "    if \"adult_small\" in flower_dataset_name.lower():\n",
    "        drop_cols = ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss']\n",
    "        dataset.drop(columns=[col for col in drop_cols if col in dataset.columns], inplace=True)\n",
    "        dataset = dataset[~dataset[\"workclass\"].isin([\" ?\"])]\n",
    "        dataset = dataset[~dataset[\"occupation\"].isin([\" ?\"])]\n",
    "    elif \"churn\" in flower_dataset_name.lower():\n",
    "        drop_cols = ['customerID', 'TotalCharges']\n",
    "        dataset.drop(columns=[col for col in drop_cols if col in dataset.columns], inplace=True)\n",
    "        dataset['MonthlyCharges'] = pd.to_numeric(dataset['MonthlyCharges'], errors='coerce')\n",
    "        dataset['tenure'] = pd.to_numeric(dataset['tenure'], errors='coerce')\n",
    "        dataset.dropna(subset=['MonthlyCharges', 'tenure'], inplace=True)\n",
    "\n",
    "    # Convierte strings a category si pocas categorías\n",
    "    for col in dataset.select_dtypes(include=[\"object\"]).columns:\n",
    "        if dataset[col].nunique() < 50:\n",
    "            dataset[col] = dataset[col].astype(\"category\")\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    dataset[class_col] = label_encoder.fit_transform(dataset[class_col])\n",
    "    dataset.rename(columns={class_col: \"class\"}, inplace=True)\n",
    "    y = dataset[\"class\"].reset_index(drop=True).to_numpy()\n",
    "    if not UNIQUE_LABELS:\n",
    "        UNIQUE_LABELS[:] = label_encoder.classes_.tolist()\n",
    "\n",
    "    numeric_features = list(dataset.select_dtypes(include=[np.number]).columns)\n",
    "    numeric_features = [f for f in numeric_features if f != \"class\"]\n",
    "    categorical_features = [c for c in dataset.columns if str(dataset[c].dtype) == \"category\"]\n",
    "    FEATURES[:] = numeric_features + categorical_features\n",
    "\n",
    "    numeric_indices = list(range(len(numeric_features)))\n",
    "    categorical_indices = list(range(len(numeric_features), len(FEATURES)))\n",
    "    X_array = dataset[FEATURES].to_numpy()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), numeric_indices),\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), categorical_indices)\n",
    "    ])\n",
    "    X_encoded = preprocessor.fit_transform(X_array)\n",
    "\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"]\n",
    "    onehot_feature_names = ohe.get_feature_names_out([FEATURES[i] for i in categorical_indices])\n",
    "    all_feature_names = numeric_features + list(onehot_feature_names)\n",
    "\n",
    "    # Divide en particiones para federado\n",
    "    X_parts = np.array_split(X_encoded, num_partitions)\n",
    "    y_parts = np.array_split(y, num_partitions)\n",
    "\n",
    "    # En cada partición, haz split train/test y guarda en listas\n",
    "    X_train_parts, X_test_parts, y_train_parts, y_test_parts = [], [], [], []\n",
    "    for X_part, y_part in zip(X_parts, y_parts):\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "            X_part, y_part, test_size=0.2, random_state=42, stratify=y_part\n",
    "        )\n",
    "        X_train_parts.append(X_tr)\n",
    "        X_test_parts.append(X_te)\n",
    "        y_train_parts.append(y_tr)\n",
    "        y_test_parts.append(y_te)\n",
    "\n",
    "    # Devuelve también el DataFrame original limpio\n",
    "    return (\n",
    "        X_train_parts, X_test_parts, y_train_parts, y_test_parts,\n",
    "        dataset,                          # <--- Añade el dataset original aquí\n",
    "        all_feature_names, label_encoder, preprocessor.named_transformers_[\"num\"], numeric_features, preprocessor\n",
    "    )\n",
    "# =======================\n",
    "\n",
    "\n",
    "\n",
    "DATASET_NAME = \"pablopalacios23/adult_small\"\n",
    "CLASS_COLUMN = \"class\"\n",
    "\n",
    "\n",
    "# DATASET_NAME = \"pablopalacios23/Iris\"\n",
    "# CLASS_COLUMN = \"target\"\n",
    "\n",
    "\n",
    "# DEMASIADO GRANDE EL DATASET :/\n",
    "# DATASET_NAME = \"pablopalacios23/churn\"\n",
    "# CLASS_COLUMN = \"Churn\" \n",
    " \n",
    "\n",
    "# =======================\n",
    "\n",
    "\n",
    "# load_data_general(DATASET_NAME, CLASS_COLUMN, partition_id=0, num_partitions=NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f28fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 12:50:21,973 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-06-30 12:50:22,341 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/main/README.md HTTP/11\" 404 0\n",
      "2025-06-30 12:50:22,474 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small HTTP/11\" 200 612\n",
      "2025-06-30 12:50:22,613 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/475f19aed5f80dea1d48deab705f11928fe27493/adult_small.py HTTP/11\" 404 0\n",
      "2025-06-30 12:50:22,615 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-06-30 12:50:22,920 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/pablopalacios23/adult_small/pablopalacios23/adult_small.py HTTP/11\" 404 0\n",
      "2025-06-30 12:50:23,056 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/475f19aed5f80dea1d48deab705f11928fe27493/README.md HTTP/11\" 404 0\n",
      "2025-06-30 12:50:23,181 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/revision/475f19aed5f80dea1d48deab705f11928fe27493 HTTP/11\" 200 612\n",
      "2025-06-30 12:50:23,311 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/475f19aed5f80dea1d48deab705f11928fe27493/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-06-30 12:50:23,316 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-06-30 12:50:23,492 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=pablopalacios23/adult_small HTTP/11\" 200 None\n",
      "2025-06-30 12:50:23,619 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/revision/475f19aed5f80dea1d48deab705f11928fe27493 HTTP/11\" 200 612\n",
      "2025-06-30 12:50:23,756 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/tree/475f19aed5f80dea1d48deab705f11928fe27493?recursive=False&expand=False HTTP/11\" 200 204\n",
      "2025-06-30 12:50:23,884 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/tree/475f19aed5f80dea1d48deab705f11928fe27493/data?recursive=False&expand=False HTTP/11\" 404 79\n",
      "2025-06-30 12:50:24,007 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-06-30 12:50:24,160 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/revision/475f19aed5f80dea1d48deab705f11928fe27493 HTTP/11\" 200 612\n",
      "2025-06-30 12:50:24,286 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/475f19aed5f80dea1d48deab705f11928fe27493/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-06-30 12:50:24,286 filelock     DEBUG    Attempting to acquire lock 1995672882688 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___adult_small_default_0.0.0_475f19aed5f80dea1d48deab705f11928fe27493.lock\n",
      "2025-06-30 12:50:24,286 filelock     DEBUG    Lock 1995672882688 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___adult_small_default_0.0.0_475f19aed5f80dea1d48deab705f11928fe27493.lock\n",
      "2025-06-30 12:50:24,286 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___adult_small/default/0.0.0/475f19aed5f80dea1d48deab705f11928fe27493/dataset_info.json\n",
      "2025-06-30 12:50:24,286 filelock     DEBUG    Attempting to release lock 1995672882688 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___adult_small_default_0.0.0_475f19aed5f80dea1d48deab705f11928fe27493.lock\n",
      "2025-06-30 12:50:24,302 filelock     DEBUG    Lock 1995672882688 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\_Users_pablo_.cache_huggingface_datasets_pablopalacios23___adult_small_default_0.0.0_475f19aed5f80dea1d48deab705f11928fe27493.lock\n",
      "2025-06-30 12:50:24,339 filelock     DEBUG    Attempting to acquire lock 1995682323040 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___adult_small\\default\\0.0.0\\475f19aed5f80dea1d48deab705f11928fe27493_builder.lock\n",
      "2025-06-30 12:50:24,341 filelock     DEBUG    Lock 1995682323040 acquired on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___adult_small\\default\\0.0.0\\475f19aed5f80dea1d48deab705f11928fe27493_builder.lock\n",
      "2025-06-30 12:50:24,343 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___adult_small/default/0.0.0/475f19aed5f80dea1d48deab705f11928fe27493/dataset_info.json\n",
      "2025-06-30 12:50:24,346 filelock     DEBUG    Attempting to release lock 1995682323040 on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___adult_small\\default\\0.0.0\\475f19aed5f80dea1d48deab705f11928fe27493_builder.lock\n",
      "2025-06-30 12:50:24,346 filelock     DEBUG    Lock 1995682323040 released on C:\\Users\\pablo\\.cache\\huggingface\\datasets\\pablopalacios23___adult_small\\default\\0.0.0\\475f19aed5f80dea1d48deab705f11928fe27493_builder.lock\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m (X_train_parts, X_test_parts, y_train_parts, y_test_parts, \n\u001b[1;32m----> 2\u001b[0m  dataset, feature_names, label_encoder, scaler, numeric_features, preprocessor) \u001b[38;5;241m=\u001b[39m load_data_general(\n\u001b[0;32m      3\u001b[0m     DATASET_NAME, CLASS_COLUMN, num_partitions\u001b[38;5;241m=\u001b[39mNUM_CLIENTS\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Selecciona partición (por ejemplo, cliente 0)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train_parts[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[2], line 154\u001b[0m, in \u001b[0;36mload_data_general\u001b[1;34m(flower_dataset_name, class_col, num_partitions)\u001b[0m\n\u001b[0;32m    152\u001b[0m X_train_parts, X_test_parts, y_train_parts, y_test_parts \u001b[38;5;241m=\u001b[39m [], [], [], []\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_part, y_part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_parts, y_parts):\n\u001b[1;32m--> 154\u001b[0m     X_tr, X_te, y_tr, y_te \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m    155\u001b[0m         X_part, y_part, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my_part\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    157\u001b[0m     X_train_parts\u001b[38;5;241m.\u001b[39mappend(X_tr)\n\u001b[0;32m    158\u001b[0m     X_test_parts\u001b[38;5;241m.\u001b[39mappend(X_te)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2872\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2868\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2870\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2877\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2878\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2879\u001b[0m     )\n\u001b[0;32m   2880\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1909\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \n\u001b[0;32m   1881\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1907\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1908\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1909\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1910\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2318\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2316\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2322\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2323\u001b[0m     )\n\u001b[0;32m   2325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   2326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2329\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "(X_train_parts, X_test_parts, y_train_parts, y_test_parts, \n",
    " dataset, feature_names, label_encoder, scaler, numeric_features, preprocessor) = load_data_general(\n",
    "    DATASET_NAME, CLASS_COLUMN, num_partitions=NUM_CLIENTS\n",
    ")\n",
    "\n",
    "# Selecciona partición (por ejemplo, cliente 0)\n",
    "X_train = X_train_parts[0]\n",
    "X_test  = X_test_parts[0]\n",
    "y_train = y_train_parts[0]\n",
    "y_test  = y_test_parts[0]\n",
    "\n",
    "print(\"\\n📦 X_train (primeras filas):\")\n",
    "print(pd.DataFrame(X_train).head())\n",
    "\n",
    "print(\"\\n🎯 y_train (primeros valores):\")\n",
    "print(y_train[:5])\n",
    "\n",
    "print(\"\\n📦 X_test (primeras filas):\")\n",
    "print(pd.DataFrame(X_test).head())\n",
    "\n",
    "print(\"\\n🎯 y_test (primeros valores):\")\n",
    "print(y_test[:5])\n",
    "\n",
    "print(\"\\n🗃️ DataFrame original limpio:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346e6dc",
   "metadata": {},
   "source": [
    "# Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab462923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 🌼 CLIENTE FLOWER\n",
    "# ==========================\n",
    "import operator\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from flwr.client import NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.common import parameters_to_ndarrays\n",
    "\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.rule import Expression, Rule\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "class TorchNNWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            outputs = self.model(X_tensor)\n",
    "            return outputs.argmax(dim=1).numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            outputs = self.model(X_tensor)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            return probs.numpy()\n",
    "        \n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, tree_model, nn_model, X_train, y_train, X_test, y_test, dataset, client_id, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor):\n",
    "        self.tree_model = tree_model\n",
    "        self.nn_model = nn_model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.dataset = dataset\n",
    "        self.client_id = client_id\n",
    "        self.feature_names = feature_names\n",
    "        self.label_encoder = label_encoder\n",
    "        self.scaler = scaler\n",
    "        self.numeric_features = numeric_features\n",
    "        self.encoder = encoder\n",
    "        self.unique_labels = label_encoder.classes_.tolist()\n",
    "        self.y_train_nn = y_train.astype(np.int64)\n",
    "        self.y_test_nn = y_test.astype(np.int64)\n",
    "        self.received_supertree = None\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def _train_nn(self, epochs=10, lr=0.01):\n",
    "        self.nn_model.train()\n",
    "        optimizer = torch.optim.Adam(self.nn_model.parameters(), lr=lr)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        X_tensor = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(self.y_train_nn, dtype=torch.long)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.nn_model(X_tensor)\n",
    "            loss = loss_fn(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"[CLIENTE {self.client_id}] ✅ Red neuronal entrenada\")\n",
    "\n",
    "    def decode_X_onehot(X, numeric_features, categorical_features, feature_names, original_categories, scaler):\n",
    "        # X: array, feature_names: nombres de las columnas one-hot + numéricas\n",
    "\n",
    "        # Desescalar numéricas\n",
    "        X_num = X[:, :len(numeric_features)]\n",
    "        X_num_inv = scaler.inverse_transform(X_num)\n",
    "        df_num = pd.DataFrame(X_num_inv, columns=numeric_features)\n",
    "\n",
    "        # Decodificar categóricas (buscar columna activa para cada variable original)\n",
    "        df_cat = {}\n",
    "        idx = len(numeric_features)\n",
    "        for cat in categorical_features:\n",
    "            n_values = len(original_categories[cat])\n",
    "            cols = feature_names[idx:idx+n_values]\n",
    "            # Para una sola muestra, np.argmax(X_cat) te dice el valor activado\n",
    "            active = np.argmax(X[:, idx:idx+n_values], axis=1)\n",
    "            vals = [original_categories[cat][i] for i in active]\n",
    "            df_cat[cat] = vals\n",
    "            idx += n_values\n",
    "\n",
    "        df_cat = pd.DataFrame(df_cat)\n",
    "        return pd.concat([df_num, df_cat], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_model_params(self.tree_model, self.nn_model, {\"tree\": [-1, 2, 1], \"nn\": parameters})\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            # print(f\"[CLIENTE {self.client_id}]\")\n",
    "            # print(\"X TEST instancia a explicar:\")\n",
    "            # print(pd.DataFrame(self.X_test).iloc[2])\n",
    "            # print(\"y TEST:\")\n",
    "            # print(pd.DataFrame(self.y_test).iloc[2])\n",
    "\n",
    "            # print(pd.DataFrame(self.X_train).shape)\n",
    "\n",
    "\n",
    "            # print(f\"[CLIENTE {self.client_id}]\")\n",
    "            # df_decoded = self.decode_X(self.X_test, self.preprocessor, self.numeric_features, self.encoder)\n",
    "            \n",
    "            # print(\"Instancia a explicar (EN EL FIT):\")\n",
    "            # print(df_decoded.iloc[2])\n",
    "\n",
    "            # print(\"target:\")\n",
    "            # print(df_decoded.iloc[2][-1])\n",
    "\n",
    "            print(self.X_train.shape, self.y_train.shape)\n",
    "\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "            self._train_nn()\n",
    "        \n",
    "            # self.print_tree_human_readable(self.tree_model, FEATURES, self.numeric_features, self.scaler, self.encoder)\n",
    "            # print(\"\\n\")\n",
    "\n",
    "\n",
    "        nn_weights = get_model_parameters(self.tree_model, self.nn_model)[\"nn\"]\n",
    "        return nn_weights, len(self.X_train), {}\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "\n",
    "\n",
    "        set_model_params(self.tree_model, self.nn_model, {\"tree\": [-1, 2, 1], \"nn\": parameters})\n",
    "\n",
    "        if \"supertree\" in config:\n",
    "            try:\n",
    "                print(\"Recibiendo supertree....\")\n",
    "                supertree_dict = json.loads(config[\"supertree\"])\n",
    "                self.received_supertree = SuperTree.convert_SuperNode_to_Node(SuperTree.SuperNode.from_dict(supertree_dict))\n",
    "                self.global_mapping = json.loads(config[\"global_mapping\"])\n",
    "                self.feature_names = json.loads(config[\"feature_names\"])\n",
    "\n",
    "                # self.received_supertree = SuperTree.SuperNode.from_dict(supertree_dict)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[CLIENTE {self.client_id}] ❌ Error al recibir SuperTree: {e}\")\n",
    "\n",
    "        try:\n",
    "            _ = self.tree_model.predict(self.X_test)\n",
    "        except NotFittedError:\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        supertree = SuperTree()\n",
    "        root_node = supertree.rec_buildTree(self.tree_model, list(range(self.X_train.shape[1])), len(self.unique_labels))\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        self._save_local_tree(root_node, round_number, FEATURES, self.numeric_features, self.scaler, UNIQUE_LABELS, self.encoder)\n",
    "        tree_json = json.dumps([root_node.to_dict()])\n",
    "\n",
    "        \n",
    "        if self.received_supertree is not None:\n",
    "            self._explain_local_and_global(config)\n",
    "\n",
    "        return 0.0, len(self.X_test), {\n",
    "            f\"tree_ensemble_{self.client_id}\": tree_json,\n",
    "            f\"scaler_mean_{self.client_id}\": json.dumps(self.scaler.mean_.tolist()),\n",
    "            f\"scaler_std_{self.client_id}\": json.dumps(self.scaler.scale_.tolist()),\n",
    "            f\"encoded_feature_names_{self.client_id}\": json.dumps(FEATURES),\n",
    "            f\"numeric_features_{self.client_id}\": json.dumps(self.numeric_features),\n",
    "            f\"unique_labels_{self.client_id}\": json.dumps(self.unique_labels),\n",
    "            f\"encoder_descriptor_{self.client_id}\": json.dumps(self.encoder.dataset_descriptor),\n",
    "            f\"distinct_values_{self.client_id}\": json.dumps(self.encoder.dataset_descriptor[\"categorical\"])\n",
    "        }\n",
    "    \n",
    "    def _explain_local_and_global(self, config):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        import numpy as np\n",
    "    \n",
    "        num_row = 2\n",
    "\n",
    "        # Reconstruir DataFrame original codificado\n",
    "        # feature_cols = self.feature_names\n",
    "\n",
    "        # 1. Visualizar instancia escalada y decodificada usando el encoder/preprocessor ORIGINAL\n",
    "        # print(f\"\\n[CLIENTE {self.client_id}] 🧪 Instancia a explicar (escalada):\")\n",
    "        # print(pd.Series(self.X_test[num_row], index=self.feature_names))\n",
    "\n",
    "        decoded_instance = self.decode_X(\n",
    "            self.X_test[num_row].reshape(1, -1),\n",
    "            self.preprocessor,\n",
    "            self.numeric_features,\n",
    "            self.encoder\n",
    "        ).iloc[0]\n",
    "\n",
    "        print(f\"\\n[CLIENTE {self.client_id}] 🧪 Instancia a explicar (decodificada):\")\n",
    "        print(decoded_instance)\n",
    "        print(f\"[CLIENTE {self.client_id}] 🧪 Clase real: {self.label_encoder.inverse_transform([self.y_test_nn[num_row]])[0]}\")\n",
    "\n",
    "        # 2. Construir DataFrame para LORE (si es necesario, solo para TabularDataset)\n",
    "        local_df = pd.DataFrame(self.X_test, columns=FEATURES).astype(np.float32)\n",
    "        local_df[\"target\"] = self.label_encoder.inverse_transform(self.y_test_nn)\n",
    "        local_tabular_dataset = TabularDataset(local_df, class_name=\"target\")\n",
    "\n",
    "        # Explicabilidad local\n",
    "        nn_wrapper = TorchNNWrapper(self.nn_model)\n",
    "        bbox = sklearn_classifier_bbox.sklearnBBox(nn_wrapper)\n",
    "        lore = TabularGeneticGeneratorLore(bbox, local_tabular_dataset)\n",
    "\n",
    "        instance_scaled = local_tabular_dataset.df.iloc[num_row][:-1]\n",
    "\n",
    "\n",
    "\n",
    "        # Explicación LORE\n",
    "        explanation = lore.explain_instance(instance_scaled.astype(np.float32), merge=True, num_classes=len(UNIQUE_LABELS), feature_names= self.feature_names, categorical_features=list(self.global_mapping.keys()), global_mapping=self.global_mapping)\n",
    "        lore_tree = explanation[\"merged_tree\"]\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "\n",
    "        encoder_for_print = {\n",
    "            \"categorical\": {\n",
    "                k: {\"distinct_values\": v} for k, v in self.global_mapping.items()\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "        self.print_tree_readable(\n",
    "            lore_tree.root,\n",
    "            self.feature_names,\n",
    "            self.unique_labels,\n",
    "            numeric_features=self.numeric_features,\n",
    "            scaler={\n",
    "                \"mean\": [self.scaler.mean_[self.numeric_features.index(f)] for f in self.numeric_features],\n",
    "                \"std\": [self.scaler.scale_[self.numeric_features.index(f)] for f in self.numeric_features]\n",
    "            },\n",
    "            encoder=encoder_for_print\n",
    "        )\n",
    "\n",
    "        \n",
    "        self._save_lore_tree(lore_tree.root, round_number)\n",
    "\n",
    "\n",
    "\n",
    "    def pretty_print_rule(rule, feature_names):\n",
    "        conditions = []\n",
    "        for i, cond in enumerate(rule):\n",
    "            # Si es columna onehot\n",
    "            for feat in feature_names:\n",
    "                if cond.startswith(feat) and \"_\"+feat in cond:\n",
    "                    var, val = feat.split('_', 1)\n",
    "                    conditions.append(f'{var} = \"{val}\"')\n",
    "        print(\" AND \".join(conditions))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def print_tree_readable(self, node, feature_names, class_names, numeric_features, scaler, encoder, depth=0):\n",
    "        indent = \"|   \" * depth\n",
    "        if node.is_leaf:\n",
    "            class_idx = int(np.argmax(node.labels))\n",
    "            print(f\"{indent}|--- class: {class_names[class_idx]}\")\n",
    "            return\n",
    "\n",
    "        feat_name = feature_names[node.feat]\n",
    "        base_feat = feat_name.split(\"=\")[0] if \"=\" in feat_name else feat_name\n",
    "\n",
    "        if base_feat in encoder[\"categorical\"]:\n",
    "            val_idx = int(node.thresh)\n",
    "            try:\n",
    "                val = encoder[\"categorical\"][base_feat][\"distinct_values\"][val_idx]\n",
    "            except IndexError:\n",
    "                val = f\"[desconocido ({val_idx})]\"\n",
    "            print(f\"{indent}|--- {base_feat} <= \\\"{val}\\\"\")\n",
    "            self.print_tree_readable(node._left_child, feature_names, class_names, numeric_features, scaler, encoder, depth + 1)\n",
    "            print(f\"{indent}|--- {base_feat} > \\\"{val}\\\"\")\n",
    "            self.print_tree_readable(node._right_child, feature_names, class_names, numeric_features, scaler, encoder, depth + 1)\n",
    "\n",
    "        elif base_feat in numeric_features:\n",
    "            idx = numeric_features.index(base_feat)\n",
    "            threshold = node.thresh * scaler[\"std\"][idx] + scaler[\"mean\"][idx]\n",
    "            print(f\"{indent}|--- {base_feat} <= {threshold:.2f}\")\n",
    "            self.print_tree_readable(node._left_child, feature_names, class_names, numeric_features, scaler, encoder, depth + 1)\n",
    "            print(f\"{indent}|--- {base_feat} > {threshold:.2f}\")\n",
    "            self.print_tree_readable(node._right_child, feature_names, class_names, numeric_features, scaler, encoder, depth + 1)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "    def _save_local_tree(self, root_node, round_number, feature_names, numeric_features, scaler, unique_labels, encoder, tree_type= \"LocalTree\"):\n",
    "        dot = Digraph()\n",
    "        node_id = [0]\n",
    "\n",
    "        def base_name(feat):\n",
    "            return feat.split('=')[0] if '=' in feat else feat\n",
    "\n",
    "        def add_node(node, parent=None, edge_label=\"\"):\n",
    "            curr = str(node_id[0])\n",
    "            node_id[0] += 1\n",
    "\n",
    "            # Etiqueta del nodo\n",
    "            if node.is_leaf:\n",
    "                class_index = np.argmax(node.labels)\n",
    "                class_label = unique_labels[class_index]\n",
    "                label = f\"class: {class_label}\\n{node.labels}\"\n",
    "            else:\n",
    "                try:\n",
    "                    fname = feature_names[node.feat]\n",
    "                    label = base_name(fname)\n",
    "                except:\n",
    "                    label = f\"X_{node.feat}\"\n",
    "\n",
    "            dot.node(curr, label)\n",
    "            if parent:\n",
    "                dot.edge(parent, curr, label=edge_label)\n",
    "\n",
    "            # Árbol tipo SuperTree\n",
    "            if hasattr(node, \"children\") and node.children is not None and hasattr(node, \"intervals\"):\n",
    "                for i, child in enumerate(node.children):\n",
    "                    try:\n",
    "                        fname = feature_names[node.feat]\n",
    "                    except:\n",
    "                        fname = f\"X_{node.feat}\"\n",
    "\n",
    "                    original_feat = base_name(fname)\n",
    "                    if original_feat in encoder.dataset_descriptor[\"categorical\"]:\n",
    "                        val_idx = node.intervals[i] if i == 0 else node.intervals[i - 1]\n",
    "                        val_idx = int(val_idx)\n",
    "                        val = encoder.dataset_descriptor[\"categorical\"][original_feat][\"distinct_values\"][val_idx] if val_idx < len(encoder.dataset_descriptor[\"categorical\"][original_feat][\"distinct_values\"]) else f\"desconocido({val_idx})\"\n",
    "                        edge = f'≠ \"{val}\"' if i == 0 else f'= \"{val}\"'\n",
    "                    elif original_feat in numeric_features:\n",
    "                        idx = numeric_features.index(original_feat)\n",
    "                        mean = scaler.mean_[idx]\n",
    "                        std = scaler.scale_[idx]\n",
    "                        val = node.intervals[i] if i == 0 else node.intervals[i - 1]\n",
    "                        val = val * std + mean\n",
    "                        edge = f\"<= {val:.2f}\" if i == 0 else f\"> {val:.2f}\"\n",
    "                    else:\n",
    "                        edge = \"?\"\n",
    "\n",
    "                    add_node(child, curr, edge)\n",
    "\n",
    "            elif hasattr(node, \"_left_child\") or hasattr(node, \"_right_child\"):\n",
    "                try:\n",
    "                    fname = feature_names[node.feat]\n",
    "                except:\n",
    "                    fname = f\"X_{node.feat}\"\n",
    "\n",
    "                original_feat = base_name(fname)\n",
    "                if original_feat in encoder.dataset_descriptor[\"categorical\"]:\n",
    "                    val_idx = int(node.thresh)\n",
    "                    val = encoder.dataset_descriptor[\"categorical\"][original_feat][\"distinct_values\"][val_idx] if val_idx < len(encoder.dataset_descriptor[\"categorical\"][original_feat][\"distinct_values\"]) else f\"desconocido({val_idx})\"\n",
    "                    left_label = f'= \"{val}\"'\n",
    "                    right_label = f'≠ \"{val}\"'\n",
    "                elif original_feat in numeric_features:\n",
    "                    idx = numeric_features.index(original_feat)\n",
    "                    mean = scaler.mean_[idx]\n",
    "                    std = scaler.scale_[idx]\n",
    "                    thresh = node.thresh * std + mean\n",
    "                    left_label = f\"<= {thresh:.2f}\"\n",
    "                    right_label = f\"> {thresh:.2f}\"\n",
    "                else:\n",
    "                    left_label = \"≤ ?\"\n",
    "                    right_label = \"> ?\"\n",
    "\n",
    "                if node._left_child:\n",
    "                    add_node(node._left_child, curr, left_label)\n",
    "                if node._right_child:\n",
    "                    add_node(node._right_child, curr, right_label)\n",
    "\n",
    "        add_node(root_node)\n",
    "        folder = f\"Ronda_{round_number}/{tree_type}_Cliente_{self.client_id}\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        filepath = f\"{folder}/{tree_type.lower()}_cliente_{self.client_id}_ronda_{round_number}\"\n",
    "        dot.render(filepath, format=\"png\", cleanup=True)\n",
    "\n",
    "    def _save_lore_tree(self, root_node, round_number):\n",
    "         self._save_generic_tree(\n",
    "            root_node,\n",
    "            round_number,\n",
    "            tree_type=\"LoreTree\",\n",
    "            feature_names=self.feature_names,\n",
    "            categorical_features=list(self.global_mapping.keys()),\n",
    "            global_mapping=self.global_mapping,\n",
    "            scaler=self.scaler,\n",
    "            numeric_features=self.numeric_features\n",
    "        )\n",
    "\n",
    "    def _save_merged_tree(self, root_node, round_number):\n",
    "        self._save_generic_tree(\n",
    "            root_node, \n",
    "            round_number, \n",
    "            tree_type=\"MergedTree\"\n",
    "        )\n",
    "\n",
    "    def _save_generic_tree(self, root_node, round_number, tree_type, feature_names=None,categorical_features=None,global_mapping=None,scaler=None,numeric_features=None):\n",
    "        from graphviz import Digraph\n",
    "        import numpy as np\n",
    "        import os\n",
    "\n",
    "        dot = Digraph()\n",
    "        node_id = [0]\n",
    "\n",
    "        def base_name(feat):\n",
    "            return feat.split('=')[0] if '=' in feat else feat\n",
    "\n",
    "        def add_node(node, parent=None, edge_label=\"\"):\n",
    "            curr = str(node_id[0])\n",
    "            node_id[0] += 1\n",
    "\n",
    "            # Etiqueta del nodo\n",
    "            if node.is_leaf:\n",
    "                class_index = np.argmax(node.labels)\n",
    "                class_label = self.unique_labels[class_index]\n",
    "                label = f\"class: {class_label}\\n{node.labels}\"\n",
    "            else:\n",
    "                try:\n",
    "                    fname = feature_names[node.feat] if feature_names else f\"X_{node.feat}\"\n",
    "                    label = base_name(fname)\n",
    "                except Exception:\n",
    "                    label = f\"X_{node.feat}\"\n",
    "\n",
    "            dot.node(curr, label)\n",
    "            if parent:\n",
    "                dot.edge(parent, curr, label=edge_label)\n",
    "\n",
    "            # Árbol tipo SuperTree (ramas como lista children+intervals)\n",
    "            if hasattr(node, \"children\") and node.children is not None and hasattr(node, \"intervals\"):\n",
    "                for i, child in enumerate(node.children):\n",
    "                    try:\n",
    "                        fname = feature_names[node.feat] if feature_names else f\"X_{node.feat}\"\n",
    "                    except Exception:\n",
    "                        fname = f\"X_{node.feat}\"\n",
    "\n",
    "                    original_feat = base_name(fname)\n",
    "                    edge = \"?\"\n",
    "\n",
    "                    # Categórica\n",
    "                    if categorical_features and original_feat in categorical_features and global_mapping:\n",
    "                        idx = node.intervals[i]\n",
    "                        if original_feat in global_mapping and idx < len(global_mapping[original_feat]):\n",
    "                            val_real = global_mapping[original_feat][idx]\n",
    "                            if len(node.children) == 2:\n",
    "                                edge = f\"= {val_real}\" if i == 0 else f\"≠ {val_real}\"\n",
    "                            else:\n",
    "                                edge = f\"= {val_real}\"\n",
    "                        else:\n",
    "                            edge = f\"= {idx}\"\n",
    "                    # Numérica\n",
    "                    elif scaler and numeric_features and original_feat in numeric_features:\n",
    "                        idx = numeric_features.index(original_feat)\n",
    "                        mean = scaler.mean_[idx]\n",
    "                        std = scaler.scale_[idx]\n",
    "                        val = node.intervals[i]\n",
    "                        val_real = val * std + mean\n",
    "                        if len(node.children) == 2:\n",
    "                            edge = f\"<= {val_real:.2f}\" if i == 0 else f\"> {val_real:.2f}\"\n",
    "                        else:\n",
    "                            edge = f\"= {val_real:.2f}\"\n",
    "                    # Genérico\n",
    "                    else:\n",
    "                        val = node.intervals[i]\n",
    "                        if len(node.children) == 2:\n",
    "                            edge = f\"<= {val:.2f}\" if i == 0 else f\"> {val:.2f}\"\n",
    "                        else:\n",
    "                            edge = f\"= {val:.2f}\"\n",
    "\n",
    "                    add_node(child, curr, edge)\n",
    "\n",
    "            # Árbol binario clásico (ramas como _left_child/_right_child)\n",
    "            elif hasattr(node, \"_left_child\") or hasattr(node, \"_right_child\"):\n",
    "                try:\n",
    "                    fname = feature_names[node.feat] if feature_names else f\"X_{node.feat}\"\n",
    "                except Exception:\n",
    "                    fname = f\"X_{node.feat}\"\n",
    "\n",
    "                original_feat = base_name(fname)\n",
    "                # Categórica\n",
    "                if categorical_features and original_feat in categorical_features and global_mapping:\n",
    "                    idx = int(node.thresh) if node.thresh is not None else None\n",
    "                    if idx is not None and original_feat in global_mapping and idx < len(global_mapping[original_feat]):\n",
    "                        val_real = global_mapping[original_feat][idx]\n",
    "                        left_label = f\"= {val_real}\"\n",
    "                        right_label = f\"≠ {val_real}\"\n",
    "                    else:\n",
    "                        left_label = \"= ?\"\n",
    "                        right_label = \"≠ ?\"\n",
    "                # Numérica\n",
    "                elif scaler and numeric_features and original_feat in numeric_features:\n",
    "                    idx = numeric_features.index(original_feat)\n",
    "                    mean = scaler.mean_[idx]\n",
    "                    std = scaler.scale_[idx]\n",
    "                    thresh = node.thresh * std + mean if node.thresh is not None else None\n",
    "                    left_label = f\"<= {thresh:.2f}\" if thresh is not None else \"≤ ?\"\n",
    "                    right_label = f\"> {thresh:.2f}\" if thresh is not None else \"> ?\"\n",
    "                # Genérico\n",
    "                else:\n",
    "                    thresh = node.thresh\n",
    "                    left_label = f\"<= {thresh:.2f}\" if thresh is not None else \"≤ ?\"\n",
    "                    right_label = f\"> {thresh:.2f}\" if thresh is not None else \"> ?\"\n",
    "\n",
    "                if hasattr(node, \"_left_child\") and node._left_child:\n",
    "                    add_node(node._left_child, curr, left_label)\n",
    "                if hasattr(node, \"_right_child\") and node._right_child:\n",
    "                    add_node(node._right_child, curr, right_label)\n",
    "\n",
    "        add_node(root_node)\n",
    "        folder = f\"Ronda_{round_number}/{tree_type}_Cliente_{self.client_id}\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        filepath = f\"{folder}/{tree_type.lower()}_cliente_{self.client_id}_ronda_{round_number}\"\n",
    "        dot.render(filepath, format=\"png\", cleanup=True)\n",
    "\n",
    "\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "\n",
    "    print(\"partition_id:\", partition_id)\n",
    "    \n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    dataset_name = DATASET_NAME \n",
    "    class_col = CLASS_COLUMN \n",
    "\n",
    "    (X_parts, y_parts, feature_names, label_encoder, scaler, numeric_features, preprocessor) = load_data_general(\n",
    "        flower_dataset_name=dataset_name,\n",
    "        class_col=class_col,\n",
    "        num_partitions=num_partitions\n",
    "    )\n",
    "    X_train = X_parts[partition_id]\n",
    "    y_train = y_parts[partition_id]\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(np.unique(y_train))\n",
    "    \n",
    "    print(\"Shape X_train:\", X_train.shape)\n",
    "    print(\"Features:\", feature_names)\n",
    "    print(\"Modelo input_dim:\", input_dim)\n",
    "\n",
    "    tree_model = DecisionTreeClassifier(max_depth=5, min_samples_split=2, random_state=42)\n",
    "    nn_model = Net(input_dim, output_dim)\n",
    "    return FlowerClient(\n",
    "        tree_model=tree_model,\n",
    "        nn_model=nn_model,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        dataset=dataset,\n",
    "        client_id=partition_id + 1,\n",
    "        feature_names=feature_names,\n",
    "        label_encoder=label_encoder,\n",
    "        scaler=scaler,\n",
    "        numeric_features=numeric_features,\n",
    "        encoder=encoder,\n",
    "        preprocessor=preprocessor\n",
    "    ).to_client()\n",
    "\n",
    "client_app = ClientApp(client_fn=client_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c927a9",
   "metadata": {},
   "source": [
    "# Servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 📦 IMPORTACIONES NECESARIAS\n",
    "# ============================\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from flwr.common import Context, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "from graphviz import Digraph\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ⚙️ CONFIGURACIÓN GLOBAL\n",
    "# ============================\n",
    "# MIN_AVAILABLE_CLIENTS = 4\n",
    "# NUM_SERVER_ROUNDS = 2\n",
    "\n",
    "FEATURES = []  # se rellenan dinámicamente\n",
    "UNIQUE_LABELS = []\n",
    "LATEST_SUPERTREE_JSON = None\n",
    "GLOBAL_MAPPING_JSON = None\n",
    "FEATURE_NAMES_JSON = None\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 🧠 UTILIDADES MODELO\n",
    "# ============================\n",
    "def create_model(input_dim, output_dim):\n",
    "    from __main__ import Net  # necesario si Net está en misma libreta\n",
    "    return Net(input_dim, output_dim)\n",
    "\n",
    "\n",
    "def get_model_parameters(tree_model, nn_model):\n",
    "    tree_params = [-1, 2, 1]\n",
    "    nn_weights = [v.cpu().detach().numpy() for v in nn_model.state_dict().values()]\n",
    "    return {\n",
    "        \"tree\": tree_params,\n",
    "        \"nn\": nn_weights,\n",
    "    }\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Dict[str, Scalar]:\n",
    "    total = sum(n for n, _ in metrics)\n",
    "    avg: Dict[str, List[float]] = {}\n",
    "    for n, met in metrics:\n",
    "        for k, v in met.items():\n",
    "            if isinstance(v, (float, int)):\n",
    "                avg.setdefault(k, []).append(n * float(v))\n",
    "    return {k: sum(vs) / total for k, vs in avg.items()}\n",
    "\n",
    "# ============================\n",
    "# 🚀 SERVIDOR FLOWER\n",
    "# ============================\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    global FEATURES, UNIQUE_LABELS\n",
    "\n",
    "    # Justo antes de llamar a create_model\n",
    "    if not FEATURES or not UNIQUE_LABELS:\n",
    "        \n",
    "        load_data_general(DATASET_NAME, CLASS_COLUMN, num_partitions=NUM_CLIENTS)\n",
    "\n",
    "\n",
    "    FEATURES = FEATURES or [\"feat_0\", \"feat_1\"]  # fallback por si no se cargó antes\n",
    "    UNIQUE_LABELS = UNIQUE_LABELS or [\"Class_0\", \"Class_1\"]\n",
    "\n",
    "\n",
    "    model = create_model(len(FEATURES), len(UNIQUE_LABELS))\n",
    "    initial_params = ndarrays_to_parameters(get_model_parameters(None, model)[\"nn\"])\n",
    "\n",
    "    strategy = FedAvg(\n",
    "        min_available_clients=MIN_AVAILABLE_CLIENTS,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        initial_parameters=initial_params,\n",
    "    )\n",
    "\n",
    "    strategy.configure_fit = _inject_round(strategy.configure_fit)\n",
    "    strategy.configure_evaluate = _inject_round(strategy.configure_evaluate)\n",
    "    original_aggregate = strategy.aggregate_evaluate\n",
    "\n",
    "    def custom_aggregate_evaluate(server_round, results, failures):\n",
    "        global LATEST_SUPERTREE_JSON, GLOBAL_MAPPING_JSON, FEATURE_NAMES_JSON\n",
    "        aggregated_metrics = original_aggregate(server_round, results, failures)\n",
    "\n",
    "        try:\n",
    "            print(f\"\\n[SERVIDOR] 🌲 Generando SuperTree - Ronda {server_round}\")\n",
    "            tree_dicts = []\n",
    "            all_distincts = defaultdict(set)\n",
    "            client_encoders = {}\n",
    "\n",
    "            for (_, evaluate_res) in results:\n",
    "                metrics = evaluate_res.metrics\n",
    "                for key, value in metrics.items():\n",
    "                    if key.startswith(\"distinct_values_\"):\n",
    "                        client_id = key.split(\"_\")[-1]\n",
    "                        client_encoders[client_id] = json.loads(value)\n",
    "                        for feat, d in client_encoders[client_id].items():\n",
    "                            all_distincts[feat].update(d[\"distinct_values\"])\n",
    "\n",
    "            global_mapping = {feat: sorted(list(vals)) for feat, vals in all_distincts.items()}\n",
    "\n",
    "            for (_, evaluate_res) in results:\n",
    "                metrics = evaluate_res.metrics\n",
    "                for key, value in metrics.items():\n",
    "                    if key.startswith(\"tree_ensemble_\"):\n",
    "                        client_id = key.split(\"_\")[-1]\n",
    "                        trees_list = json.loads(value)\n",
    "                        local_encoder = client_encoders[client_id]\n",
    "                        feature_names = json.loads(metrics.get(f\"encoded_feature_names_{client_id}\"))\n",
    "                        numeric_features = json.loads(metrics.get(f\"numeric_features_{client_id}\"))\n",
    "                        unique_labels = json.loads(metrics.get(f\"unique_labels_{client_id}\"))\n",
    "                        scaler = {\n",
    "                            \"mean\": json.loads(metrics.get(f\"scaler_mean_{client_id}\")),\n",
    "                            \"std\": json.loads(metrics.get(f\"scaler_std_{client_id}\")),\n",
    "                        }\n",
    "\n",
    "                        for tdict in trees_list:\n",
    "                            root = SuperTree.Node.from_dict(tdict)\n",
    "\n",
    "                            def normalize_thresholds(node):\n",
    "                                if node is None or node.is_leaf:\n",
    "                                    return\n",
    "\n",
    "                                fname = feature_names[node.feat]\n",
    "\n",
    "                                if fname in numeric_features:\n",
    "                                    try:\n",
    "                                        idx = numeric_features.index(fname)\n",
    "                                        real_val = node.thresh * scaler[\"std\"][idx] + scaler[\"mean\"][idx]\n",
    "                                        node.real_thresh = real_val  # ⬅️ Lo guardamos\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"[WARNING] No se pudo desescalar {fname}: {e}\")\n",
    "\n",
    "                                elif fname in local_encoder and fname in global_mapping:\n",
    "                                    try:\n",
    "                                        local_vals = local_encoder[fname][\"distinct_values\"]\n",
    "                                        real_val = local_vals[int(node.thresh)]\n",
    "                                        node.thresh = global_mapping[fname].index(real_val)\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"[WARNING] No se pudo normalizar {fname}: {e}\")\n",
    "\n",
    "                                normalize_thresholds(getattr(node, \"_left_child\", None))\n",
    "                                normalize_thresholds(getattr(node, \"_right_child\", None))\n",
    "\n",
    "                            normalize_thresholds(root)\n",
    "\n",
    "                            encoder_for_print = {\n",
    "                                \"categorical\": {\n",
    "                                    k: {\"distinct_values\": v}\n",
    "                                    for k, v in global_mapping.items()\n",
    "                                    if k in FEATURES and k not in numeric_features\n",
    "                                }\n",
    "                            }\n",
    "\n",
    "                            # print(f\"\\n[CLIENTE {client_id}] 🌳 Árbol normalizado:\")\n",
    "                            # print_tree_readable(\n",
    "                            #     root,\n",
    "                            #     feature_names,\n",
    "                            #     unique_labels,\n",
    "                            #     numeric_features=numeric_features,\n",
    "                            #     scaler={\n",
    "                            #         \"mean\": [scaler[\"mean\"][i] for i, f in enumerate(feature_names) if f in numeric_features],\n",
    "                            #         \"std\": [scaler[\"std\"][i] for i, f in enumerate(feature_names) if f in numeric_features]\n",
    "                            #     },\n",
    "                            #     encoder=encoder_for_print\n",
    "                            # )\n",
    "                            # print(\"Local tree del cliente\", client_id)\n",
    "                            # print(root.to_dict())\n",
    "                            tree_dicts.append(root)\n",
    "                            \n",
    "            # print(tree_dicts)\n",
    "            \n",
    "            if not tree_dicts:\n",
    "                print(\"[SERVIDOR] ⚠️ No se recibieron árboles. Se omite SuperTree.\")\n",
    "                return aggregated_metrics\n",
    "            \n",
    "                        \n",
    "            supertree = SuperTree()\n",
    "            # print(\"feature_names: \", feature_names)\n",
    "            # print(\"global_mapping: \", global_mapping)\n",
    "            # print(\"global_mapping keys: \", list(global_mapping.keys()))\n",
    "            \n",
    "            supertree.mergeDecisionTrees(tree_dicts, num_classes=len(UNIQUE_LABELS), feature_names=feature_names, categorical_features=list(global_mapping.keys()), global_mapping=global_mapping)\n",
    "            supertree.prune_redundant_leaves_full()\n",
    "            supertree.merge_equal_class_leaves()\n",
    "\n",
    "            # print(\"\\n[SERVIDOR] 🌳 SuperTree legible:\")\n",
    "            \n",
    "            # print_supertree_readable_fusionado(\n",
    "            #     node=supertree.root,\n",
    "            #     global_mapping=global_mapping,\n",
    "            #     feature_names=feature_names,\n",
    "            #     class_names=UNIQUE_LABELS,\n",
    "            #     numeric_features=numeric_features,\n",
    "            #     scaler=scaler  # sin acceder a .mean_ ni .scale_\n",
    "            # )\n",
    "\n",
    "            _save_supertree_plot(\n",
    "                root_node=supertree.root,\n",
    "                round_number=server_round,\n",
    "                feature_names=feature_names,\n",
    "                class_names=UNIQUE_LABELS,\n",
    "                scaler_means=scaler[\"mean\"],\n",
    "                scaler_stds=scaler[\"std\"],\n",
    "                global_mapping=global_mapping,\n",
    "                numeric_features=numeric_features\n",
    "            )\n",
    "\n",
    "            LATEST_SUPERTREE_JSON = json.dumps(supertree.root.to_dict())\n",
    "            GLOBAL_MAPPING_JSON = json.dumps(global_mapping)\n",
    "            FEATURE_NAMES_JSON = json.dumps(feature_names)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SERVIDOR] ❌ Error en SuperTree: {e}\")\n",
    "\n",
    "        time.sleep(3)\n",
    "        return aggregated_metrics\n",
    "\n",
    "    strategy.aggregate_evaluate = custom_aggregate_evaluate\n",
    "    return ServerAppComponents(strategy=strategy, config=ServerConfig(num_rounds=NUM_SERVER_ROUNDS))\n",
    "\n",
    "# ============================\n",
    "# 🧩 FUNCIONES AUXILIARES\n",
    "# ============================\n",
    "def _inject_round(original_fn):\n",
    "    def wrapper(server_round, parameters, client_manager):\n",
    "        global LATEST_SUPERTREE_JSON, GLOBAL_MAPPING_JSON, FEATURE_NAMES_JSON\n",
    "        instructions = original_fn(server_round, parameters, client_manager)\n",
    "        for _, ins in instructions:\n",
    "            ins.config[\"server_round\"] = server_round\n",
    "            \n",
    "            if LATEST_SUPERTREE_JSON:\n",
    "                ins.config[\"supertree\"] = LATEST_SUPERTREE_JSON\n",
    "                ins.config[\"global_mapping\"] = GLOBAL_MAPPING_JSON\n",
    "                ins.config[\"feature_names\"] = FEATURE_NAMES_JSON\n",
    "                \n",
    "        return instructions\n",
    "    return wrapper\n",
    "\n",
    "def print_supertree_readable_fusionado(node, global_mapping, feature_names, class_names, numeric_features, scaler, depth=0):\n",
    "    if node is None:\n",
    "        print(f\"{'|   ' * depth}|--- [Nodo None]\")\n",
    "        return\n",
    "\n",
    "    indent = \"|   \" * depth\n",
    "\n",
    "    if node.is_leaf:\n",
    "        class_idx = int(np.argmax(node.labels))\n",
    "        print(f\"{indent}|--- class: {class_names[class_idx]}\")\n",
    "        return\n",
    "\n",
    "    feat_name = feature_names[node.feat]\n",
    "    base_feat = feat_name.split(\"=\")[0] if \"=\" in feat_name else feat_name\n",
    "\n",
    "    is_numeric = base_feat in numeric_features\n",
    "    is_categorical = base_feat in global_mapping and not is_numeric\n",
    "\n",
    "    for i, child in enumerate(node.children):\n",
    "        if hasattr(node, \"intervals\") and node.intervals is not None:\n",
    "            if i < len(node.intervals):\n",
    "                val_idx = node.intervals[i]\n",
    "            else:\n",
    "                val_idx = node.intervals[0]\n",
    "        else:\n",
    "            val_idx = i  # fallback\n",
    "\n",
    "        if is_numeric:\n",
    "            idx = numeric_features.index(base_feat)\n",
    "            if hasattr(node, \"real_thresh\"):\n",
    "                real_val = node.real_thresh\n",
    "            else:\n",
    "                real_val = val_idx * scaler[\"std\"][idx] + scaler[\"mean\"][idx]\n",
    "            op = \"≤\" if i == 0 else \">\"\n",
    "            print(f\"{indent}|--- {base_feat} {op} {real_val:.2f}\")\n",
    "        elif is_categorical:\n",
    "            values = global_mapping[base_feat]\n",
    "            val_idx = int(val_idx)\n",
    "            val = values[val_idx] if 0 <= val_idx < len(values) else f\"[desconocido {val_idx}]\"\n",
    "            op = \"=\" if i == 0 else \"≠\"\n",
    "            print(f\"{indent}|--- {base_feat} {op} \\\"{val}\\\"\")\n",
    "        else:\n",
    "            print(f\"{indent}|--- {base_feat} [tipo desconocido]\")\n",
    "\n",
    "        # Recursivo\n",
    "        print_supertree_readable_fusionado(\n",
    "            node=child,\n",
    "            global_mapping=global_mapping,\n",
    "            feature_names=feature_names,\n",
    "            class_names=class_names,\n",
    "            numeric_features=numeric_features,\n",
    "            scaler=scaler,\n",
    "            depth=depth + 1\n",
    "        )\n",
    "\n",
    "\n",
    "def print_tree_readable(node, feature_names, class_names, numeric_features, scaler, encoder, depth=0):\n",
    "    indent = \"|   \" * depth\n",
    "    if node.is_leaf:\n",
    "        class_idx = int(np.argmax(node.labels))\n",
    "        print(f\"{indent}|--- class: {class_names[class_idx]}\")\n",
    "        return\n",
    "\n",
    "    feat_name = feature_names[node.feat]\n",
    "    base_feat = feat_name.split(\"=\")[0] if \"=\" in feat_name else feat_name\n",
    "\n",
    "    if base_feat in encoder[\"categorical\"]:\n",
    "        val_idx = int(node.thresh)\n",
    "        try:\n",
    "            val = encoder[\"categorical\"][base_feat][\"distinct_values\"][val_idx]\n",
    "        except IndexError:\n",
    "            val = f\"[desconocido ({val_idx})]\"\n",
    "        print(f\"{indent}|--- {base_feat} <= \\\"{val}\\\"\")\n",
    "        print_tree_readable(node._left_child, feature_names, class_names, numeric_features, scaler, encoder, depth + 1)\n",
    "        print(f\"{indent}|--- {base_feat} > \\\"{val}\\\"\")\n",
    "        print_tree_readable(node._right_child, feature_names, class_names, numeric_features, scaler, encoder, depth + 1)\n",
    "\n",
    "    elif base_feat in numeric_features:\n",
    "        idx = numeric_features.index(base_feat)\n",
    "        threshold = node.thresh * scaler[\"std\"][idx] + scaler[\"mean\"][idx]\n",
    "        print(f\"{indent}|--- {base_feat} <= {threshold:.2f}\")\n",
    "        print_tree_readable(node._left_child, feature_names, class_names, numeric_features, scaler, encoder, depth + 1)\n",
    "        print(f\"{indent}|--- {base_feat} > {threshold:.2f}\")\n",
    "        print_tree_readable(node._right_child, feature_names, class_names, numeric_features, scaler, encoder, depth + 1)\n",
    "\n",
    "\n",
    "def _save_supertree_plot(root_node, round_number, feature_names=None, class_names=None,\n",
    "                         scaler_means=None, scaler_stds=None,\n",
    "                         global_mapping=None, numeric_features=None):\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def base_name(feat):\n",
    "        return feat.split('=')[0] if '=' in feat else feat\n",
    "\n",
    "    def add_node(node, parent=None, label=\"\"):\n",
    "        curr = str(node_id[0])\n",
    "        node_id[0] += 1\n",
    "\n",
    "        if node.is_leaf:\n",
    "            class_index = int(np.argmax(node.labels))\n",
    "            class_label = class_names[class_index] if class_names else f\"Clase {class_index}\"\n",
    "            label_text = f\"Clase: {class_label}\\n{node.labels}\"\n",
    "        else:\n",
    "            try:\n",
    "                fname = feature_names[node.feat]\n",
    "                label_text = base_name(fname)\n",
    "            except Exception:\n",
    "                label_text = f\"X_{node.feat}\"\n",
    "\n",
    "        dot.node(curr, label_text)\n",
    "        if parent:\n",
    "            dot.edge(parent, curr, label=label)\n",
    "\n",
    "        if not node.is_leaf:\n",
    "            for i, child in enumerate(node.children):\n",
    "                try:\n",
    "                    fname = feature_names[node.feat]\n",
    "                    base = base_name(fname)\n",
    "                except Exception:\n",
    "                    fname = f\"X_{node.feat}\"\n",
    "                    base = fname\n",
    "\n",
    "                if global_mapping and base in global_mapping:\n",
    "                    # Variable categórica\n",
    "                    values = global_mapping[base]\n",
    "                    try:\n",
    "                        val_idx = node.intervals[i] if node.intervals and i < len(node.intervals) else node.thresh\n",
    "                        val = values[int(val_idx)] if int(val_idx) < len(values) else f\"? ({val_idx})\"\n",
    "                    except Exception:\n",
    "                        val = \"?\"\n",
    "                    edge_label = f'= \"{val}\"' if i == 0 else f'≠ \"{val}\"'\n",
    "\n",
    "                elif numeric_features and base in numeric_features:\n",
    "                    # Variable numérica\n",
    "                    try:\n",
    "                        idx = feature_names.index(base)\n",
    "                        raw_val = node.intervals[i] if node.intervals and i < len(node.intervals) else node.thresh\n",
    "                        val = raw_val * scaler_stds[idx] + scaler_means[idx] if scaler_means and scaler_stds else raw_val\n",
    "                        edge_label = f\"≤ {val:.2f}\" if i == 0 else f\"> {val:.2f}\"\n",
    "                    except Exception:\n",
    "                        edge_label = \"?\"\n",
    "\n",
    "                else:\n",
    "                    edge_label = \"?\"\n",
    "\n",
    "                add_node(child, curr, edge_label)\n",
    "\n",
    "    add_node(root_node)\n",
    "    folder = f\"Ronda_{round_number}/Supertree\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filename = f\"{folder}/supertree_ronda_{round_number}\"\n",
    "    dot.render(filename, format=\"png\", cleanup=True)\n",
    "    return f\"{filename}.png\"\n",
    "\n",
    "# ============================\n",
    "# 🔧 INICIALIZAR SERVER APP\n",
    "# ============================\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d278d1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 12:43:33,670\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-06-30 12:43:37,120 flwr         DEBUG    Asyncio event loop already running.\n",
      "2025-06-30 12:43:37,140 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      ":job_id:01000000\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      "2025-06-30 12:43:37,292 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/main/README.md HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":job_id:01000000\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 12:43:37,412 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small HTTP/11\" 200 612\n",
      "2025-06-30 12:43:37,533 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/475f19aed5f80dea1d48deab705f11928fe27493/adult_small.py HTTP/11\" 404 0\n",
      "2025-06-30 12:43:37,533 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-06-30 12:43:37,835 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/pablopalacios23/adult_small/pablopalacios23/adult_small.py HTTP/11\" 404 0\n",
      "2025-06-30 12:43:37,956 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/475f19aed5f80dea1d48deab705f11928fe27493/README.md HTTP/11\" 404 0\n",
      "2025-06-30 12:43:38,078 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/revision/475f19aed5f80dea1d48deab705f11928fe27493 HTTP/11\" 200 612\n",
      "2025-06-30 12:43:38,208 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/475f19aed5f80dea1d48deab705f11928fe27493/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-06-30 12:43:38,211 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-06-30 12:43:38,397 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=pablopalacios23/adult_small HTTP/11\" 200 None\n",
      "2025-06-30 12:43:38,521 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/revision/475f19aed5f80dea1d48deab705f11928fe27493 HTTP/11\" 200 612\n",
      "2025-06-30 12:43:38,658 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/tree/475f19aed5f80dea1d48deab705f11928fe27493?recursive=False&expand=False HTTP/11\" 200 204\n",
      "2025-06-30 12:43:38,781 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/tree/475f19aed5f80dea1d48deab705f11928fe27493/data?recursive=False&expand=False HTTP/11\" 404 79\n",
      "2025-06-30 12:43:38,895 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-06-30 12:43:39,081 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/revision/475f19aed5f80dea1d48deab705f11928fe27493 HTTP/11\" 200 612\n",
      "2025-06-30 12:43:39,208 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/475f19aed5f80dea1d48deab705f11928fe27493/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-06-30 12:43:39,211 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___adult_small/default/0.0.0/475f19aed5f80dea1d48deab705f11928fe27493/dataset_info.json\n",
      "2025-06-30 12:43:39,214 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___adult_small/default/0.0.0/475f19aed5f80dea1d48deab705f11928fe27493/dataset_info.json\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 478, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 478, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 478, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 478, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition_id:partition_id: 1\n",
      " 0\n",
      "partition_id: 0\n",
      "partition_id: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=7808a3678f11f291ffb7abdc01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A269F0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=7808a3678f11f291ffb7abdc01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A269F0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 478, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=7808a3678f11f291ffb7abdc01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A269F0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=7808a3678f11f291ffb7abdc01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A269F0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=7808a3678f11f291ffb7abdc01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A269F0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=7808a3678f11f291ffb7abdc01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A269F0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 478, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=7808a3678f11f291ffb7abdc01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A269F0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=7808a3678f11f291ffb7abdc01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A269F0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SERVIDOR] 🌲 Generando SuperTree - Ronda 1\n",
      "[SERVIDOR] ⚠️ No se recibieron árboles. Se omite SuperTree.\n",
      "partition_id: 0\n",
      "partition_id: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 478, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 478, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16296\\3921816318.py\", line 548, in client_fn\n",
      "    (X_train, y_train, X_test, y_test, dataset, feature_names, label_encoder, scaler, numeric_features, encoder, preprocessor) = load_data_general(flower_dataset_name=dataset_name,class_col=class_col,partition_id=partition_id,num_partitions=num_partitions)\n",
      "                                                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=16296, ip=127.0.0.1, actor_id=c2678289c86a2d620cf4a23b01000000, repr=<flwr.simulation.ray_transport.ray_actor._modify_class.<locals>.Class object at 0x000002E6A2A267B0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pablo\\anaconda3\\Lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: load_data_general() got an unexpected keyword argument 'partition_id'\n",
      "\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 2 round(s) in 0.94s\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition_id: 0\n",
      "partition_id: 1\n",
      "\n",
      "[SERVIDOR] 🌲 Generando SuperTree - Ronda 2\n",
      "[SERVIDOR] ⚠️ No se recibieron árboles. Se omite SuperTree.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n"
     ]
    }
   ],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "import logging\n",
    "import warnings\n",
    "import ray\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger(\"filelock\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"ray\").setLevel(logging.WARNING)\n",
    "logging.getLogger('graphviz').setLevel(logging.WARNING)\n",
    "# logging.getLogger(\"flwr\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()  # Apagar cualquier sesión previa de Ray\n",
    "ray.init(local_mode=True)  # Desactiva multiprocessing, usa un solo proceso principal\n",
    "\n",
    "backend_config = {\"num_cpus\": 1}\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
