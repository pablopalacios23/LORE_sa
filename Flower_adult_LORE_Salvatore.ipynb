{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:26:42,612 urllib3.connectionpool DEBUG    Resetting dropped connection: huggingface.co\n",
      "2025-05-20 13:26:42,811 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/main/README.md HTTP/11\" 404 0\n",
      "2025-05-20 13:26:42,965 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small HTTP/11\" 200 560\n",
      "2025-05-20 13:26:43,114 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/ff696447ef64f9056a891aeecefec2473b03f7d4/adult_small.py HTTP/11\" 404 0\n",
      "2025-05-20 13:26:43,118 urllib3.connectionpool DEBUG    Resetting dropped connection: s3.amazonaws.com\n",
      "2025-05-20 13:26:43,411 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/pablopalacios23/adult_small/pablopalacios23/adult_small.py HTTP/11\" 404 0\n",
      "2025-05-20 13:26:43,528 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/ff696447ef64f9056a891aeecefec2473b03f7d4/README.md HTTP/11\" 404 0\n",
      "2025-05-20 13:26:43,660 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/ff696447ef64f9056a891aeecefec2473b03f7d4/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-05-20 13:26:43,661 urllib3.connectionpool DEBUG    Resetting dropped connection: datasets-server.huggingface.co\n",
      "2025-05-20 13:26:43,844 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=pablopalacios23/adult_small HTTP/11\" 200 None\n",
      "2025-05-20 13:26:45,463 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/tree/ff696447ef64f9056a891aeecefec2473b03f7d4/data?recursive=False&expand=False HTTP/11\" 404 79\n",
      "2025-05-20 13:26:45,545 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-20 13:26:45,746 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/pablopalacios23/adult_small/revision/ff696447ef64f9056a891aeecefec2473b03f7d4 HTTP/11\" 200 611\n",
      "2025-05-20 13:26:45,864 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/pablopalacios23/adult_small/resolve/ff696447ef64f9056a891aeecefec2473b03f7d4/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-05-20 13:26:45,864 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___adult_small/default/0.0.0/ff696447ef64f9056a891aeecefec2473b03f7d4/dataset_info.json\n",
      "2025-05-20 13:26:45,880 fsspec.local DEBUG    open file: C:/Users/pablo/.cache/huggingface/datasets/pablopalacios23___adult_small/default/0.0.0/ff696447ef64f9056a891aeecefec2473b03f7d4/dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE_LABELS: [' <=50K', ' >50K']\n",
      "FEATURES: ['age', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
      "   age          workclass      education       marital-status  \\\n",
      "0   41        Federal-gov      Bachelors   Married-civ-spouse   \n",
      "1   50        Federal-gov   Some-college             Divorced   \n",
      "2   39        Federal-gov    Prof-school   Married-civ-spouse   \n",
      "3   33          Local-gov        HS-grad             Divorced   \n",
      "4   64   Self-emp-not-inc   Some-college              Widowed   \n",
      "\n",
      "         occupation    relationship                 race      sex  \\\n",
      "0      Adm-clerical            Wife   Asian-Pac-Islander   Female   \n",
      "1      Adm-clerical       Unmarried                White   Female   \n",
      "2    Prof-specialty         Husband                White     Male   \n",
      "3   Protective-serv       Unmarried                White     Male   \n",
      "4      Craft-repair   Not-in-family                White   Female   \n",
      "\n",
      "   hours-per-week  native-country   class  \n",
      "0              40     Philippines    >50K  \n",
      "1              40   United-States   <=50K  \n",
      "2              50   United-States    >50K  \n",
      "3              40   United-States   <=50K  \n",
      "4               8   United-States   <=50K  \n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# üì¶ IMPORTACIONES\n",
    "# =======================\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score, \n",
    "    f1_score, confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "from flwr.client import ClientApp, NumPyClient\n",
    "from flwr.common import Context, NDArrays, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.encoder_decoder.tabular_enc import ColumnTransformerEnc\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =======================\n",
    "# ‚öôÔ∏è VARIABLES GLOBALES\n",
    "# =======================\n",
    "UNIQUE_LABELS = []\n",
    "FEATURES = []\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "NUM_CLIENTS = 2\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "fds = None  # Cache del FederatedDataset\n",
    "CAT_ENCODINGS = {}\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_dim = max(8, input_dim * 2)  # algo proporcional\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# =======================\n",
    "# üîß UTILIDADES MODELO\n",
    "# =======================\n",
    "\n",
    "def get_model_parameters(tree_model, nn_model):\n",
    "    tree_params = [\n",
    "        int(tree_model.get_params()[\"max_depth\"] or -1),\n",
    "        int(tree_model.get_params()[\"min_samples_split\"]),\n",
    "        int(tree_model.get_params()[\"min_samples_leaf\"]),\n",
    "    ]\n",
    "    nn_weights = [v.cpu().detach().numpy() for v in nn_model.state_dict().values()]\n",
    "    return {\n",
    "        \"tree\": tree_params,\n",
    "        \"nn\": nn_weights,\n",
    "    }\n",
    "\n",
    "\n",
    "def set_model_params(tree_model, nn_model, params):\n",
    "    tree_params = params[\"tree\"]\n",
    "    nn_weights = params[\"nn\"]\n",
    "\n",
    "    # Solo si tree_model no es None y tiene set_params\n",
    "    if tree_model is not None and hasattr(tree_model, \"set_params\"):\n",
    "        max_depth = tree_params[0] if tree_params[0] > 0 else None\n",
    "        tree_model.set_params(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=tree_params[1],\n",
    "            min_samples_leaf=tree_params[2],\n",
    "        )\n",
    "\n",
    "    # Actualizar pesos de la red neuronal\n",
    "    state_dict = nn_model.state_dict()\n",
    "    for (key, _), val in zip(state_dict.items(), nn_weights):\n",
    "        state_dict[key] = torch.tensor(val)\n",
    "    nn_model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# =======================\n",
    "# üì• CARGAR DATOS\n",
    "# =======================\n",
    "\n",
    "def load_data(partition_id: int, num_partitions: int):\n",
    "    global fds, UNIQUE_LABELS, FEATURES, CAT_ENCODINGS\n",
    "    \n",
    "    if fds is None:\n",
    "        partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "        fds = FederatedDataset(dataset=\"pablopalacios23/adult_small\", partitioners={\"train\": partitioner})\n",
    "\n",
    "    # Cargar y preparar dataset\n",
    "    dataset = fds.load_partition(partition_id, \"train\").with_format(\"pandas\")[:]\n",
    "    # dataset = dataset.applymap(lambda x: np.nan if isinstance(x, str) and x.strip() == \"?\" else x)\n",
    "    # dataset.dropna(inplace=True)\n",
    "    target_column = dataset.columns[-1]\n",
    "\n",
    "    # Codificar clases\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(dataset[target_column])\n",
    "    dataset[target_column] = label_encoder.inverse_transform(y_encoded)\n",
    "    dataset.rename(columns={target_column: \"class\"}, inplace=True)\n",
    "\n",
    "    # Guardar etiquetas √∫nicas\n",
    "    if not UNIQUE_LABELS:\n",
    "        UNIQUE_LABELS[:] = label_encoder.classes_.tolist()\n",
    "        print(\"UNIQUE_LABELS:\", UNIQUE_LABELS)\n",
    "\n",
    "    # Eliminar columnas no √∫tiles\n",
    "    dataset.drop(['fnlwgt', 'education-num', 'capital-gain', 'capital-loss'], axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "    # TabularDataset con clases legibles\n",
    "    tabular_dataset = TabularDataset(dataset.copy(), class_name=\"class\")\n",
    "    descriptor = tabular_dataset.descriptor\n",
    "\n",
    "    numeric_features = list(descriptor[\"numeric\"].keys())\n",
    "    categorical_features = list(descriptor[\"categorical\"].keys())\n",
    "\n",
    "    # Guardar nombres de features\n",
    "    if not FEATURES:\n",
    "        FEATURES[:] = numeric_features + categorical_features\n",
    "        print(\"FEATURES:\", FEATURES)\n",
    "\n",
    "    # Codificar X con ColumnTransformer\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", scaler, numeric_features),\n",
    "            (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    X = dataset[FEATURES]\n",
    "    scaler.fit(X[numeric_features])  # Ajustar antes de guardar\n",
    "    X_encoded = preprocessor.fit_transform(X)\n",
    "\n",
    "    encoder = ColumnTransformerEnc(tabular_dataset.descriptor)\n",
    "    feature_names = list(encoder.encoded_features.values())\n",
    "\n",
    "    # Volver a codificar la clase a enteros\n",
    "    dataset[\"class\"] = y_encoded\n",
    "    y = y_encoded\n",
    "\n",
    "    # Separar train/test\n",
    "    split_idx = int(0.8 * len(X_encoded))\n",
    "    X_train, X_test = X_encoded[:split_idx], X_encoded[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, tabular_dataset, feature_names, scaler, numeric_features, label_encoder, encoder\n",
    "\n",
    "\n",
    "# =======================\n",
    "# üß™ PRUEBA DE CARGA LOCAL (solo en ejecuci√≥n directa)\n",
    "# =======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, y_train, X_test, y_test, dataset, feature_names, scaler, numeric_features, label_encoder, encoder = load_data(partition_id=0, num_partitions=NUM_CLIENTS)\n",
    "\n",
    "\n",
    "print(dataset.df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir el cliente federado con Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# üåº CLIENTE FLOWER (ADULT)\n",
    "# ==========================\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    log_loss, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from flwr.client import NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.common import parameters_to_ndarrays\n",
    "\n",
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.bbox import sklearn_classifier_bbox\n",
    "from lore_sa.lore import TabularGeneticGeneratorLore\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "class TorchNNWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            outputs = self.model(X_tensor)\n",
    "            return outputs.argmax(dim=1).numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            outputs = self.model(X_tensor)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            return probs.numpy()\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, tree_model, nn_model, X_train, y_train, X_test, y_test, dataset, client_id, feature_names, scaler, numeric_features, label_encoder, encoder):\n",
    "        self.tree_model = tree_model\n",
    "        self.nn_model = nn_model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.dataset = dataset\n",
    "        self.label_encoder = label_encoder\n",
    "        self.unique_labels = UNIQUE_LABELS\n",
    "        self.y_train_nn = y_train.astype(np.int64)\n",
    "        self.client_id = client_id\n",
    "        self.received_supertree = None\n",
    "        self.feature_names = feature_names\n",
    "        self.scaler = scaler\n",
    "        self.numeric_features = numeric_features\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def _train_nn(self, epochs=10, lr=0.01):\n",
    "        self.nn_model.train()\n",
    "        optimizer = torch.optim.Adam(self.nn_model.parameters(), lr=lr)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        X_tensor = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(self.y_train_nn, dtype=torch.long)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.nn_model(X_tensor)\n",
    "            loss = loss_fn(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"[CLIENTE {self.client_id}] ‚úÖ Red neuronal entrenada\")\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_model_params(self.tree_model, self.nn_model, {\"tree\": [-1, 2, 1], \"nn\": parameters})\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "            self._train_nn()\n",
    "        nn_weights = get_model_parameters(self.tree_model, self.nn_model)[\"nn\"]\n",
    "        return nn_weights, len(self.X_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_model_params(self.tree_model, self.nn_model, {\"tree\": [-1, 2, 1], \"nn\": parameters})\n",
    "\n",
    "        if \"supertree\" in config:\n",
    "            try:\n",
    "                supertree_dict = json.loads(config[\"supertree\"])\n",
    "                self.received_supertree = SuperTree.convert_SuperNode_to_Node(SuperTree.SuperNode.from_dict(supertree_dict))\n",
    "            except Exception as e:\n",
    "                print(f\"[CLIENTE {self.client_id}] ‚ùå Error al recibir SuperTree: {e}\")\n",
    "\n",
    "        try:\n",
    "            _ = self.tree_model.predict(self.X_test)\n",
    "        except NotFittedError:\n",
    "            self.tree_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        y_pred = self.tree_model.predict(self.X_test)\n",
    "        y_proba = self.tree_model.predict_proba(self.X_test)\n",
    "\n",
    "        supertree = SuperTree()\n",
    "        root_node = supertree.rec_buildTree(self.tree_model, list(range(self.X_train.shape[1])), len(self.unique_labels))\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        self._save_local_tree(root_node, round_number)\n",
    "        tree_json = json.dumps([root_node.to_dict()])\n",
    "\n",
    "        if self.received_supertree is not None:\n",
    "            self._explain_local_and_global(config)\n",
    "\n",
    "        return float(log_loss(self.y_test, y_proba)), len(self.X_test), {\n",
    "            \"Accuracy\": accuracy_score(self.y_test, y_pred),\n",
    "            \"Precision\": precision_score(self.y_test, y_pred, average=\"weighted\", zero_division=1),\n",
    "            \"Recall\": recall_score(self.y_test, y_pred, average=\"weighted\"),\n",
    "            \"F1_Score\": f1_score(self.y_test, y_pred, average=\"weighted\"),\n",
    "            \"AUC\": roc_auc_score(self.y_test, y_proba[:, 1]),\n",
    "            \"tree_ensemble\": tree_json,\n",
    "            \"scaler_mean\": json.dumps(self.scaler.mean_.tolist()),\n",
    "            \"scaler_std\": json.dumps(self.scaler.scale_.tolist()),\n",
    "            \"encoded_feature_names\": json.dumps(self.feature_names)\n",
    "        }\n",
    "    \n",
    "    def _explain_local_and_global(self, config): \n",
    "        num_row = 5\n",
    "\n",
    "        local_df = pd.DataFrame(self.X_train, columns=self.dataset.df.columns[:-1]).astype(np.float32)\n",
    "        local_df[\"target\"] = self.label_encoder.inverse_transform(self.y_train_nn)\n",
    "\n",
    "        local_tabular_dataset = TabularDataset(local_df, class_name=\"target\")\n",
    "        descriptor = local_tabular_dataset.get_descriptor()\n",
    "\n",
    "        encoder = ColumnTransformerEnc(descriptor)\n",
    "        encoder.set_classes(self.unique_labels)\n",
    "        self.encoder = encoder  # guardar por si quieres usar fuera\n",
    "\n",
    "        # Local explicabilidad (LORE)\n",
    "        nn_wrapper = TorchNNWrapper(self.nn_model)\n",
    "        bbox = sklearn_classifier_bbox.sklearnBBox(nn_wrapper)\n",
    "        lore = TabularGeneticGeneratorLore(bbox, local_tabular_dataset)\n",
    "\n",
    "        instance = local_tabular_dataset.df.iloc[num_row][:-1]\n",
    "        target = local_tabular_dataset.df.iloc[num_row][-1]\n",
    "\n",
    "        instance_array = instance.values.reshape(1, -1).astype(np.float32)\n",
    "        pred_idx = self.nn_model(torch.tensor(instance_array)).argmax(dim=1).item()\n",
    "        pred_label = self.label_encoder.inverse_transform([pred_idx])[0]\n",
    "        print(f\"[CLIENTE {self.client_id}] ü§ñ Predicci√≥n de la red neuronal: {pred_label}\")\n",
    "\n",
    "        explanation = lore.explain_instance(instance.astype(np.float32), merge=True)\n",
    "        lore_tree = explanation[\"merged_tree\"]\n",
    "        round_number = config.get(\"server_round\", 1)\n",
    "        self._save_lore_tree(lore_tree.root, round_number)\n",
    "\n",
    "        # Fusionar con supertree\n",
    "        merged_tree = SuperTree()\n",
    "        node_LORE_Tree = SuperTree.convert_SuperNode_to_Node(lore_tree.root)\n",
    "        merged_root = merged_tree.mergeDecisionTrees(\n",
    "            roots=[node_LORE_Tree, self.received_supertree],\n",
    "            num_classes=len(self.unique_labels),\n",
    "            feature_names=self.dataset.df.columns[:-1].tolist()\n",
    "        )\n",
    "        merged_tree.root = merged_root\n",
    "        merged_tree.prune_redundant_leaves_full()\n",
    "        merged_tree.merge_equal_class_leaves()\n",
    "        self._save_merged_tree(merged_tree.root, round_number)\n",
    "\n",
    "        z_encoded = encoder.encode([instance.values])[0]\n",
    "        z_encoded = np.array([z_encoded], dtype=np.float32)\n",
    "        decoded_instance = encoder.decode(z_encoded)[0]\n",
    "\n",
    "        rule = merged_tree.get_rule(z=z_encoded[0], encoder=encoder)\n",
    "        crules, _ = merged_tree.get_counterfactual_rules_merged(z_encoded[0], encoder)\n",
    "\n",
    "        print(f\"\\n[CLIENTE {self.client_id}] üß™ Instancia a explicar:\")\n",
    "        print(pd.Series(decoded_instance, index=self.dataset.df.columns[:-1]))\n",
    "\n",
    "        print(f\" [CLIENTE {self.client_id}] üß™ Clase real: {target}\")\n",
    "\n",
    "        print(f\"\\n [CLIENTE {self.client_id}] üìú Regla de explicaci√≥n del √°rbol fusionado:\")\n",
    "        for p in rule.premises:\n",
    "            op = p.operator.__name__.replace(\"le\", \"‚â§\").replace(\"lt\", \"<\").replace(\"ge\", \"‚â•\").replace(\"gt\", \">\").replace(\"eq\", \"=\")\n",
    "            value = p.value\n",
    "            if isinstance(value, str):\n",
    "                print(f\"   - {p.variable} {op} {value}\")\n",
    "            else:\n",
    "                print(f\"   - {p.variable} {op} {value:.3f}\")\n",
    "        print(f\" ‚áí {rule.consequences.variable} = {rule.consequences.value}\")\n",
    "\n",
    "        actual_class = rule.consequences.value\n",
    "\n",
    "        print(f\"\\nüß¨ [CLIENTE {self.client_id}] Contrafactuales sugeridos:\")\n",
    "        idx = 1\n",
    "        for cf in crules:\n",
    "            if cf.consequences.value == actual_class:\n",
    "                continue\n",
    "            print(f\"\\n  ‚ö° Contrafactual #{idx}:\")\n",
    "            for p in cf.premises:\n",
    "                op = p.operator.__name__.replace(\"le\", \"‚â§\").replace(\"lt\", \"<\").replace(\"ge\", \"‚â•\").replace(\"gt\", \">\").replace(\"eq\", \"=\")\n",
    "                value = p.value\n",
    "                if isinstance(value, str):\n",
    "                    print(f\"   - {p.variable} {op} {value}\")\n",
    "                else:\n",
    "                    print(f\"   - {p.variable} {op} {value:.3f}\")\n",
    "            print(f\"   ‚áí {cf.consequences.variable} = {cf.consequences.value}\")\n",
    "            idx += 1\n",
    "\n",
    "        \n",
    "\n",
    "    def _save_local_tree(self, root_node, round_number):\n",
    "        dot = Digraph()\n",
    "        node_id = [0]\n",
    "\n",
    "        def base_name(feat):\n",
    "            return feat.split('=')[0] if '=' in feat else feat\n",
    "\n",
    "        def add_node(node, parent_id=None, edge_label=\"\"):\n",
    "            curr_id = str(node_id[0])\n",
    "            node_id[0] += 1\n",
    "\n",
    "            if node.is_leaf:\n",
    "                class_index = np.argmax(node.labels)\n",
    "                class_label = str(self.unique_labels[class_index])\n",
    "                label = f\"class: {class_label}\\n{node.labels}\"\n",
    "            else:\n",
    "                try:\n",
    "                    fname = self.feature_names[node.feat]\n",
    "                    label = base_name(fname)\n",
    "                except:\n",
    "                    fname = f\"X_{node.feat}\"\n",
    "                    label = fname\n",
    "\n",
    "            dot.node(curr_id, label)\n",
    "\n",
    "            if parent_id:\n",
    "                dot.edge(parent_id, curr_id, label=edge_label)\n",
    "\n",
    "            if not node.is_leaf:\n",
    "                if hasattr(node, \"intervals\"):  # SuperNode con m√∫ltiples hijos\n",
    "                    for i, child in enumerate(node.children):\n",
    "                        try:\n",
    "                            fname = self.feature_names[node.feat]\n",
    "                        except:\n",
    "                            fname = f\"X_{node.feat}\"\n",
    "\n",
    "                        if '=' in fname:\n",
    "                            attr, val = fname.split('=')\n",
    "                            edge = f\"= {val}\" if i == 1 else f\"‚â† {val}\"\n",
    "                        else:\n",
    "                            # Desescalar valores num√©ricos\n",
    "                            original_feat = base_name(fname)\n",
    "                            if hasattr(self, \"scaler\") and original_feat in self.numeric_features:\n",
    "                                idx = self.numeric_features.index(original_feat)\n",
    "                                mean = self.scaler.mean_[idx]\n",
    "                                std = self.scaler.scale_[idx]\n",
    "                                if i == 0:\n",
    "                                    edge_val = node.intervals[i] * std + mean\n",
    "                                    edge = f\"<= {edge_val:.2f}\"\n",
    "                                else:\n",
    "                                    edge_val = node.intervals[i - 1] * std + mean\n",
    "                                    edge = f\"> {edge_val:.2f}\"\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    edge = f\"<= {node.intervals[i]:.2f}\"\n",
    "                                else:\n",
    "                                    edge = f\"> {node.intervals[i - 1]:.2f}\"\n",
    "\n",
    "                        add_node(child, curr_id, edge)\n",
    "                else:  # Binario (√°rbol sklearn puro)\n",
    "                    try:\n",
    "                        fname = self.feature_names[node.feat]\n",
    "                    except:\n",
    "                        fname = f\"X_{node.feat}\"\n",
    "\n",
    "                    if '=' in fname:\n",
    "                        attr, val = fname.split('=')\n",
    "                        left_label = f\"‚â† {val}\"\n",
    "                        right_label = f\"= {val}\"\n",
    "                    else:\n",
    "                        original_feat = base_name(fname)\n",
    "                        if hasattr(self, \"scaler\") and original_feat in self.numeric_features:\n",
    "                            idx = self.numeric_features.index(original_feat)\n",
    "                            mean = self.scaler.mean_[idx]\n",
    "                            std = self.scaler.scale_[idx]\n",
    "                            thresh = node.thresh * std + mean\n",
    "                            left_label = f\"<= {thresh:.2f}\"\n",
    "                            right_label = f\"> {thresh:.2f}\"\n",
    "                        else:\n",
    "                            left_label = f\"<= {node.thresh:.2f}\"\n",
    "                            right_label = f\"> {node.thresh:.2f}\"\n",
    "\n",
    "                    if node._left_child:\n",
    "                        add_node(node._left_child, curr_id, left_label)\n",
    "                    if node._right_child:\n",
    "                        add_node(node._right_child, curr_id, right_label)\n",
    "\n",
    "        add_node(root_node)\n",
    "        folder = f\"Ronda_{round_number}/Arbol_Local_Cliente_{self.client_id}\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        dot.render(f\"{folder}/arbol_local_cliente_{self.client_id}_ronda_{round_number}\", format=\"png\", cleanup=True)\n",
    "\n",
    "    def _save_lore_tree(self, root_node, round_number):\n",
    "        self._save_generic_tree(\n",
    "            root_node, \n",
    "            round_number, \n",
    "            tree_type=\"LoreTree\"\n",
    "        )\n",
    "\n",
    "    def _save_merged_tree(self, root_node, round_number):\n",
    "        self._save_generic_tree(\n",
    "            root_node, \n",
    "            round_number, \n",
    "            tree_type=\"MergedTree\"\n",
    "        )\n",
    "\n",
    "    def _save_generic_tree(self, root_node, round_number, tree_type):\n",
    "        dot = Digraph()\n",
    "        node_id = [0]\n",
    "\n",
    "        def base_name(feat):\n",
    "            return feat.split('=')[0] if '=' in feat else feat\n",
    "\n",
    "        def add_node(node, parent=None, edge_label=\"\"):\n",
    "            curr = str(node_id[0])\n",
    "            node_id[0] += 1\n",
    "\n",
    "            if node.is_leaf:\n",
    "                class_index = np.argmax(node.labels)\n",
    "                class_label = self.unique_labels[class_index]\n",
    "                label = f\"class: {class_label}\\n{node.labels}\"\n",
    "            else:\n",
    "                try:\n",
    "                    fname = self.feature_names[node.feat]\n",
    "                    label = base_name(fname)\n",
    "                except:\n",
    "                    label = f\"X_{node.feat}\"\n",
    "\n",
    "            dot.node(curr, label)\n",
    "            if parent:\n",
    "                dot.edge(parent, curr, label=edge_label)\n",
    "\n",
    "            if not node.is_leaf:\n",
    "                for i, child in enumerate(node.children):\n",
    "                    try:\n",
    "                        fname = self.feature_names[node.feat]\n",
    "                    except:\n",
    "                        fname = f\"X_{node.feat}\"\n",
    "\n",
    "                    if '=' in fname:\n",
    "                        attr, val = fname.split('=')\n",
    "                        edge = f\"= {val}\" if i == 1 else f\"‚â† {val}\"\n",
    "                    else:\n",
    "                        original_feat = base_name(fname)\n",
    "                        if original_feat in self.numeric_features:\n",
    "                            idx = self.numeric_features.index(original_feat)\n",
    "                            mean = self.scaler.mean_[idx]\n",
    "                            std = self.scaler.scale_[idx]\n",
    "                            val = node.intervals[i] if i == 0 else node.intervals[i - 1]\n",
    "                            val = val * std + mean\n",
    "                            edge = f\"<= {val:.2f}\" if i == 0 else f\"> {val:.2f}\"\n",
    "                        else:\n",
    "                            val = node.intervals[i] if i == 0 else node.intervals[i - 1]\n",
    "                            edge = f\"<= {val:.2f}\" if i == 0 else f\"> {val:.2f}\"\n",
    "\n",
    "                    add_node(child, curr, edge)\n",
    "\n",
    "        add_node(root_node)\n",
    "        folder = f\"Ronda_{round_number}/{tree_type}_Cliente_{self.client_id}\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        filepath = f\"{folder}/{tree_type.lower()}_cliente_{self.client_id}_ronda_{round_number}\"\n",
    "        dot.render(filepath, format=\"png\", cleanup=True)\n",
    "\n",
    "\n",
    "def create_tree_model():\n",
    "    return DecisionTreeClassifier(max_depth=5, min_samples_split=2, random_state=42)\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    X_train, y_train, X_test, y_test, dataset, feature_names, scaler, numeric_features, label_encoder, encoder = load_data(partition_id, num_partitions)\n",
    "    tree_model = create_tree_model()\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(np.unique(y_train))\n",
    "    nn_model = Net(input_dim, output_dim)\n",
    "    return FlowerClient(tree_model, nn_model, X_train, y_train, X_test, y_test, dataset, client_id=partition_id + 1, feature_names=feature_names, scaler=scaler, numeric_features=numeric_features, label_encoder=label_encoder, encoder = encoder).to_client()\n",
    "\n",
    "client_app = ClientApp(client_fn=client_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurar el Servidor de Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üì¶ IMPORTACIONES NECESARIAS\n",
    "# ============================\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from flwr.common import Context, Metrics, Scalar, ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "from graphviz import Digraph\n",
    "from lore_sa.surrogate.decision_tree import SuperTree\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ‚öñÔ∏è CONFIGURACI√ìN GLOBAL\n",
    "# ============================\n",
    "MIN_AVAILABLE_CLIENTS = 2\n",
    "NUM_SERVER_ROUNDS = 2\n",
    "FEATURES = ['age', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "UNIQUE_LABELS = [' <=50K', ' >50K']\n",
    "LATEST_SUPERTREE_JSON = None  # üå≤ Guardar √°rbol generado\n",
    "\n",
    "# ============================\n",
    "# üßê MODELO Y UTILIDADES\n",
    "# ============================\n",
    "\n",
    "def create_model():\n",
    "    input_dim = len(FEATURES)\n",
    "    output_dim = len(UNIQUE_LABELS)\n",
    "    return Net(input_dim, output_dim)\n",
    "\n",
    "def get_model_parameters(tree_model, nn_model):\n",
    "    tree_params = [ -1, 2, 1 ]  # Valores por defecto para el servidor\n",
    "    nn_weights = [v.cpu().detach().numpy() for v in nn_model.state_dict().values()]\n",
    "    return {\n",
    "        \"tree\": tree_params,\n",
    "        \"nn\": nn_weights,\n",
    "    }\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Dict[str, Scalar]:\n",
    "    total = sum(n for n, _ in metrics)\n",
    "    avg: Dict[str, List[float]] = {}\n",
    "    for n, met in metrics:\n",
    "        for k, v in met.items():\n",
    "            if isinstance(v, (float, int)):\n",
    "                avg.setdefault(k, []).append(n * float(v))\n",
    "    return {k: sum(vs) / total for k, vs in avg.items()}\n",
    "\n",
    "# ============================\n",
    "# üöÄ SERVIDOR FLOWER\n",
    "# ============================\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    model = create_model()\n",
    "    initial_params = ndarrays_to_parameters(get_model_parameters(None, model)[\"nn\"])\n",
    "\n",
    "\n",
    "    strategy = FedAvg(\n",
    "        min_available_clients=MIN_AVAILABLE_CLIENTS,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        initial_parameters=initial_params,\n",
    "    )\n",
    "\n",
    "    strategy.configure_fit = _inject_round(strategy.configure_fit)\n",
    "    strategy.configure_evaluate = _inject_round(strategy.configure_evaluate)\n",
    "\n",
    "    original_aggregate = strategy.aggregate_evaluate\n",
    "\n",
    "    def custom_aggregate_evaluate(server_round, results, failures):\n",
    "        global LATEST_SUPERTREE_JSON\n",
    "        scaler_means = None\n",
    "        scaler_stds = None\n",
    "        aggregated_metrics = original_aggregate(server_round, results, failures)\n",
    "\n",
    "        try:\n",
    "            print(f\"\\n[SERVIDOR] üå≤ Generando SuperTree - Ronda {server_round}\")\n",
    "            tree_dicts = []\n",
    "            total_arboles = 0\n",
    "\n",
    "            for client_idx, (_, evaluate_res) in enumerate(results):\n",
    "                metrics = evaluate_res.metrics\n",
    "                trees_json = metrics.get(\"tree_ensemble\", None)\n",
    "                if metrics.get(\"scaler_mean\") and metrics.get(\"scaler_std\"):\n",
    "                    scaler_means = json.loads(metrics[\"scaler_mean\"])\n",
    "                    scaler_stds = json.loads(metrics[\"scaler_std\"])\n",
    "\n",
    "                if \"encoded_feature_names\" in metrics:\n",
    "                    feature_names = json.loads(metrics[\"encoded_feature_names\"])\n",
    "\n",
    "                if trees_json:\n",
    "                    try:\n",
    "                        trees_list = json.loads(trees_json)\n",
    "                        for tdict in trees_list:\n",
    "                            root = SuperTree.Node.from_dict(tdict)\n",
    "                            if root:\n",
    "                                tree_dicts.append(root)\n",
    "                                total_arboles += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"[CLIENTE {client_idx+1}] ‚ùå Error al parsear √°rbol: {e}\")\n",
    "\n",
    "            # print(f\"[SERVIDOR] üìä Total de √°rboles: {total_arboles}\")\n",
    "\n",
    "            if not tree_dicts:\n",
    "                print(\"[SERVIDOR] ‚ö†Ô∏è No se recibieron √°rboles. Se omite SuperTree.\")\n",
    "                return aggregated_metrics\n",
    "\n",
    "            supertree = SuperTree()\n",
    "            supertree.mergeDecisionTrees(tree_dicts, num_classes=len(UNIQUE_LABELS), feature_names=feature_names)\n",
    "            supertree.prune_redundant_leaves_full()\n",
    "            supertree.merge_equal_class_leaves()\n",
    "\n",
    "            _save_supertree_plot(supertree.root, server_round, feature_names=feature_names, class_names=UNIQUE_LABELS, scaler_means=scaler_means, scaler_stds=scaler_stds)\n",
    "            LATEST_SUPERTREE_JSON = json.dumps(supertree.root.to_dict())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SERVIDOR] ‚ùå Error en SuperTree: {e}\")\n",
    "\n",
    "        time.sleep(10)\n",
    "        return aggregated_metrics\n",
    "\n",
    "    strategy.aggregate_evaluate = custom_aggregate_evaluate\n",
    "    config = ServerConfig(num_rounds=NUM_SERVER_ROUNDS)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# ============================\n",
    "# üìÇ HELPERS\n",
    "# ============================\n",
    "\n",
    "def _inject_round(original_fn):\n",
    "    def wrapper(server_round, parameters, client_manager):\n",
    "        global LATEST_SUPERTREE_JSON\n",
    "        instructions = original_fn(server_round, parameters, client_manager)\n",
    "        for _, ins in instructions:\n",
    "            ins.config[\"server_round\"] = server_round\n",
    "            if LATEST_SUPERTREE_JSON:\n",
    "                ins.config[\"supertree\"] = LATEST_SUPERTREE_JSON\n",
    "        return instructions\n",
    "    return wrapper\n",
    "\n",
    "def _save_supertree_plot(root_node, round_number, feature_names=None, class_names=None, scaler_means=None, scaler_stds=None):\n",
    "    round_folder = f\"Ronda_{round_number}\"\n",
    "    os.makedirs(round_folder, exist_ok=True)\n",
    "\n",
    "    supertree_folder = f\"{round_folder}/Supertree\"\n",
    "    os.makedirs(supertree_folder, exist_ok=True)\n",
    "\n",
    "    dot = Digraph()\n",
    "    node_id = [0]\n",
    "\n",
    "    def base_name(feat):\n",
    "        return feat.split('=')[0] if '=' in feat else feat\n",
    "\n",
    "    def add_node(node, parent=None, label=\"\"):\n",
    "        curr = str(node_id[0])\n",
    "        node_id[0] += 1\n",
    "\n",
    "        if node.is_leaf:\n",
    "            class_index = np.argmax(node.labels)\n",
    "            class_label = class_names[class_index] if class_names else f\"Clase {class_index}\"\n",
    "            label_text = f\"Clase: {class_label}\\n{node.labels}\"\n",
    "        else:\n",
    "            try:\n",
    "                fname = feature_names[node.feat]\n",
    "                label_text = base_name(fname)\n",
    "            except:\n",
    "                label_text = f\"X_{node.feat}\"\n",
    "\n",
    "        dot.node(curr, label_text)\n",
    "\n",
    "        if parent:\n",
    "            dot.edge(parent, curr, label=label)\n",
    "\n",
    "        if not node.is_leaf:\n",
    "            for i, child in enumerate(node.children):\n",
    "                try:\n",
    "                    feat_val = feature_names[node.feat]\n",
    "                except:\n",
    "                    feat_val = f\"X_{node.feat}\"\n",
    "\n",
    "                # Si categ√≥rico\n",
    "                if '=' in feat_val:\n",
    "                    attr, val = feat_val.split('=')\n",
    "                    edge_label = f\"= {val}\" if i == 1 else f\"‚â† {val}\"\n",
    "                else:\n",
    "                    if scaler_means and scaler_stds:\n",
    "                        idx = feature_names.index(feat_val)\n",
    "                        val = node.intervals[i] if i == 0 else node.intervals[i - 1]\n",
    "                        val = val * scaler_stds[idx] + scaler_means[idx]\n",
    "                    else:\n",
    "                        val = node.intervals[i] if i == 0 else node.intervals[i - 1]\n",
    "\n",
    "                    edge_label = f\"<= {val:.2f}\" if i == 0 else f\"> {val:.2f}\"\n",
    "\n",
    "                add_node(child, curr, edge_label)\n",
    "\n",
    "    add_node(root_node)\n",
    "    filename = f\"{supertree_folder}/supertree_ronda_{round_number}\"\n",
    "    dot.render(filename, format=\"png\", cleanup=True)\n",
    "    # print(f\"[SERVIDOR] ‚úÖ SuperTree guardado como '{filename}.png'\")\n",
    "\n",
    "# ============================\n",
    "# üîß INICIALIZAR SERVER APP\n",
    "# ============================\n",
    "server_app = ServerApp(server_fn=server_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pasos que se realizan en el notebook:**\n",
    "\n",
    "1. El servidor inicializa el modelo y lo env√≠a a cada uno de los clientes.\n",
    "\n",
    "2. Cada cliente entrena un RandomForest con su respectivo subconjunto de datos o partici√≥n que hemos realizado al principio.\n",
    "\n",
    "3. Los clientes entrenan, y mandan sus hiperpar√°metros (N¬∫ de √°rboles, profundidad, etc.) al servidor.\n",
    "\n",
    "4. El servidor combina los par√°metros y actualiza el modelo global.\n",
    "\n",
    "5. Se mide el rendimiento del modelo sobre cada cliente, obteniendo tambi√©n sus contrafactuales y se repite el proceso las rondas que deseemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutar la Simulaci√≥n Federada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:26:50,254\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      ":actor_name:ClientAppActor\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n",
      ":actor_name:ClientAppActor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 1] ‚úÖ Red neuronal entrenada[CLIENTE 2] ‚úÖ Red neuronal entrenada\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SERVIDOR] üå≤ Generando SuperTree - Ronda 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIENTE 2] ‚úÖ Red neuronal entrenada\n",
      "[CLIENTE 1] ‚úÖ Red neuronal entrenada\n",
      "[CLIENTE 1] ü§ñ Predicci√≥n de la red neuronal:  <=50K\n",
      "[CLIENTE 2] ü§ñ Predicci√≥n de la red neuronal:  >50K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CLIENTE 2] üß™ Instancia a explicar:\n",
      "age               1.153944\n",
      "workclass         1.351558\n",
      "education         4.000000\n",
      "marital-status    6.000000\n",
      "occupation        1.000000\n",
      "relationship      8.000000\n",
      "race              4.000000\n",
      "sex               1.000000\n",
      "hours-per-week    0.000000\n",
      "native-country    0.000000\n",
      "dtype: float32\n",
      " [CLIENTE 2] üß™ Clase real:  >50K\n",
      "\n",
      " [CLIENTE 2] üìú Regla de explicaci√≥n del √°rbol fusionado:\n",
      "   - education > 2.500\n",
      "   - workclass > 0.436\n",
      "   - age > 0.933\n",
      "   - occupation ‚â§ 1.660\n",
      "   - occupation > 0.500\n",
      " ‚áí target =  >50K\n",
      "\n",
      "üß¨ [CLIENTE 2] Contrafactuales sugeridos:\n",
      "\n",
      "  ‚ö° Contrafactual #1:\n",
      "   - education ‚â§ 1.375\n",
      "   - occupation ‚â§ 1.660\n",
      "   - occupation > 0.500\n",
      "   - age > -0.940\n",
      "   ‚áí target =  <=50K\n",
      "\n",
      "[CLIENTE 1] üß™ Instancia a explicar:\n",
      "age               0.163048\n",
      "workclass        -0.998351\n",
      "education         3.000000\n",
      "marital-status    4.000000\n",
      "occupation        1.000000\n",
      "relationship      3.000000\n",
      "race              4.000000\n",
      "sex               2.000000\n",
      "hours-per-week    0.000000\n",
      "native-country    1.000000\n",
      "dtype: float32\n",
      " [CLIENTE 1] üß™ Clase real:  >50K\n",
      "\n",
      " [CLIENTE 1] üìú Regla de explicaci√≥n del √°rbol fusionado:\n",
      "   - education > 2.500\n",
      "   - workclass ‚â§ 0.436\n",
      " ‚áí target =  <=50K\n",
      "\n",
      "üß¨ [CLIENTE 1] Contrafactuales sugeridos:\n",
      "\n",
      "  ‚ö° Contrafactual #1:\n",
      "   - education ‚â§ 1.790\n",
      "   - education > 0.791\n",
      "   - occupation ‚â§ 2.500\n",
      "   - occupation > 0.500\n",
      "   - age > -0.940\n",
      "   - relationship ‚â§ 3.032\n",
      "   - race > 0.421\n",
      "   ‚áí target =  >50K\n",
      "\n",
      "[SERVIDOR] üå≤ Generando SuperTree - Ronda 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 2 round(s) in 82.12s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 18.021826694558577\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 18.021826694558577\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'AUC': [(1, 0.5), (2, 0.5)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Accuracy': [(1, 0.5), (2, 0.5)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'F1_Score': [(1, 0.5333333333333334), (2, 0.5333333333333334)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Precision': [(1, 0.625), (2, 0.625)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'Recall': [(1, 0.5), (2, 0.5)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n",
      "\u001b[93mWARNING \u001b[0m:   Manually terminating ClientAppActor\n"
     ]
    }
   ],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "import logging\n",
    "import warnings\n",
    "import ray\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logging.getLogger(\"filelock\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"ray\").setLevel(logging.WARNING)\n",
    "logging.getLogger('graphviz').setLevel(logging.WARNING)\n",
    "# logging.getLogger(\"flwr\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()  # Apagar cualquier sesi√≥n previa de Ray\n",
    "ray.init(local_mode=True)  # Desactiva multiprocessing, usa un solo proceso principal\n",
    "\n",
    "backend_config = {\"num_cpus\": 1}\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
